{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "df_train = pd.read_csv(\"./fine_tuning.csv\")\n",
    "\n",
    "train_data_domain = df_train.domain.values\n",
    "train_data_label = df_train.label.values\n",
    "train_data_label = train_data_label.tolist()\n",
    "train_data_label = [0 if item == 2 else 1 for item in train_data_label]\n",
    "train_data_label = np.array(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"./bert_tokenizer/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "\n",
    "for sent in train_data_domain:\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = 64,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,   # Construct attn. masks.\n",
    "        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "labels_train = torch.tensor(train_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111,998 training samples\n",
      "48,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train) # 打包处理，所以数据第一维必须相等\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.7 * len(dataset_train))\n",
    "test_size = len(dataset_train) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_train, [train_size, test_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "构造MyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "EmbeddingPath = \"./FedBert/FedTransformer.pt\"\n",
    "TransformerPath = \"./FedBert/FedEmbedding.pt\"\n",
    "num_users = 10\n",
    "frac = 0.5\n",
    "local_epochs = 5\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"./bert-base-uncased-model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.2,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.34.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 1000\n",
      "}\n",
      "\n",
      "BertPooler(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (activation): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,DataCollatorForLanguageModeling,HfArgumentParser,Trainer,TrainingArguments,set_seed,\n",
    ")\n",
    "# 自己修改部分配置参数\n",
    "config_kwargs = {\n",
    "    \"cache_dir\": None,\n",
    "    \"revision\": 'main',\n",
    "    \"use_auth_token\": None,\n",
    "    #      \"hidden_size\": 512,\n",
    "    #     \"num_attention_heads\": 4,\n",
    "    \"hidden_dropout_prob\": 0.2,\n",
    "    \"vocab_size\": 1000 # 自己设置词汇大小\n",
    "}\n",
    "# 将模型的配置参数载入\n",
    "config = AutoConfig.from_pretrained('./bert-base-uncased-model/', **config_kwargs)\n",
    "print(config)\n",
    "# 载入预训练模型\n",
    "model = AutoModelForMaskedLM.from_config(\n",
    "    config=config,\n",
    ")\n",
    "model.resize_token_embeddings(config_kwargs[\"vocab_size\"])\n",
    "\n",
    "embedding = model.bert.embeddings\n",
    "\n",
    "class Bert_Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Embedding, self).__init__()\n",
    "        self.embeddings = copy.deepcopy(embedding)\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_output = self.embeddings(input_ids, attn_mask)\n",
    "        return embedding_output\n",
    "\n",
    "embedding_model = Bert_Embedding()\n",
    "embedding_model.load_state_dict(torch.load(EmbeddingPath))\n",
    "\n",
    "encoder = model.bert.encoder\n",
    "cls = model.cls\n",
    "\n",
    "class Bert_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bert_Encoder, self).__init__()\n",
    "        self.encoder = copy.deepcopy(encoder)\n",
    "        self.cls = copy.deepcopy(cls)\n",
    "\n",
    "    def forward(self, embedding_output):\n",
    "        output_encoder = self.encoder(embedding_output).last_hidden_state\n",
    "        return output_encoder\n",
    "encoder_model = Bert_Encoder()\n",
    "encoder_model.load_state_dict(torch.load(TransformerPath))\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPooler\n",
    "class Pooler_Config:\n",
    "    def __init__(self, entries: dict={}):\n",
    "        for k, v in entries.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.__dict__[k] = Pooler_Config(v)\n",
    "            else:\n",
    "                self.__dict__[k] = v\n",
    "\n",
    "config_pooler = {\"hidden_size\": 768}\n",
    "config_pooler = Pooler_Config(config_pooler)\n",
    "pooler = BertPooler(config_pooler)\n",
    "print(pooler)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=2, freeze_bert=False):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = Bert_Embedding()\n",
    "        self.encoder = Bert_Encoder()\n",
    "        self.pooler = copy.deepcopy(pooler)\n",
    "        if freeze_bert:\n",
    "            for p in self.embedding.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(hidden_size, num_classes, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        embedding_outputs = self.embedding(input_ids, attn_mask)\n",
    "        encoder_outputs = self.encoder(embedding_outputs)\n",
    "        pooler_outputs = self.pooler(encoder_outputs)\n",
    "        #它代表了一句话的embedding\n",
    "        logits = self.fc(pooler_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "iid数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n",
    "\n",
    "# train_dataset[:][:][1]\n",
    "def dirichlet_split_noniid(train_labels, num_users):\n",
    "    '''\n",
    "    按照参数为alpha的Dirichlet分布将样本索引集合划分为n_clients个子集\n",
    "    '''\n",
    "    alpha = 0.7\n",
    "    n_classes = 2\n",
    "    # (K, N) 类别标签分布矩阵X，记录每个类别划分到每个client去的比例\n",
    "    label_distribution = np.random.dirichlet([alpha]*num_users, n_classes)\n",
    "    # (K, ...) 记录K个类别对应的样本索引集合\n",
    "    class_idcs = [np.argwhere(train_labels == y).flatten()\n",
    "                  for y in range(n_classes)]\n",
    "\n",
    "    # 记录N个client分别对应的样本索引集合\n",
    "    client_idcs = [[] for _ in range(num_users)]\n",
    "    for k_idcs, fracs in zip(class_idcs, label_distribution):\n",
    "        # np.split按照比例fracs将类别为k的样本索引k_idcs划分为了N个子集\n",
    "        # i表示第i个client，idcs表示其对应的样本索引集合idcs\n",
    "        for i, idcs in enumerate(np.split(k_idcs,\n",
    "                                          (np.cumsum(fracs)[:-1]*len(k_idcs)).\n",
    "                                                  astype(int))):\n",
    "            client_idcs[i] += [idcs]\n",
    "\n",
    "    dict_users = [np.concatenate(idcs) for idcs in client_idcs]\n",
    "\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "dict_user_train = dirichlet_split_noniid(train_dataset[:][:][:][2], num_users)\n",
    "dict_user_test = dataset_iid(test_dataset, num_users)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
    "# size of 16 or 32.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (embedding): Bert_Embedding(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(1000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder): Bert_Encoder(\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): Sequential()\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net_glob = MyModel()\n",
    "net_glob.encoder.cls = nn.Sequential()\n",
    "print(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 训练loss记录\n",
    "loss_train_collect = {}\n",
    "# 训练acc记录\n",
    "acc_train_collect = {}\n",
    "loss_test_collect = {}\n",
    "# 测试acc记录\n",
    "acc_test_collect = {}\n",
    "# 训练TPR记录\n",
    "TPR_train_collect = {}\n",
    "# 测试TPR记录\n",
    "TPR_test_collect = {}\n",
    "# 训练FPR记录\n",
    "FPR_train_collect = {}\n",
    "# 测试FPR记录\n",
    "FPR_test_collect = {}\n",
    "# 训练测试F1-score记录\n",
    "f1_train_collect = {}\n",
    "f1_test_collect = {}\n",
    "# 训练测试AUC记录\n",
    "AUC_train_collect = {}\n",
    "AUC_test_collect = {}\n",
    "# 训练测试ROC曲线记录\n",
    "ROC_train_collect = {}\n",
    "ROC_test_collect = {}\n",
    "\n",
    "local_test = {}\n",
    "local_testing = {}\n",
    "\n",
    "loss_collect = []\n",
    "acc_collect = []\n",
    "TPR_collect = []\n",
    "FPR_collect = []\n",
    "F1_collect = []\n",
    "AUC_collect = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "# Initialization of net_model_server and net_server (server-side model)\n",
    "net_model = [net_glob for i in range(num_users)]\n",
    "net_server = copy.deepcopy(net_model[0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        domain, mask, label = self.dataset[self.idxs[item]]\n",
    "        return domain, mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    return np.sum(preds == labels) / len(labels)\n",
    "\n",
    "def tpr_calculate(preds, labels):\n",
    "    return recall_score(labels, preds,zero_division=1)\n",
    "\n",
    "def fpr_calculate(preds, labels):\n",
    "    conf_matrix = confusion_matrix(labels, preds)\n",
    "    #print(conf_matrix)\n",
    "    fp = conf_matrix[0, 1]  # 0 表示负类别，1 表示正类别\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "    return fpr\n",
    "\n",
    "def f1_score_calculate(preds, labels):\n",
    "    return f1_score(labels, preds, zero_division=1)\n",
    "\n",
    "def AUC_calculate(preds, labels):\n",
    "    return roc_auc_score(labels, preds)\n",
    "\n",
    "def roc_curve_calculate(preds, labels):\n",
    "    return roc_curve(labels, preds)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client(object):\n",
    "    def __init__(self, device, idx, lr, local_epochs, batch_size, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.idx = idx\n",
    "        self.local_ep = local_epochs\n",
    "        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = batch_size, shuffle = True)\n",
    "        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = batch_size, shuffle= True)\n",
    "        self.ala = ALA(idx, idxs, criterion, dataset_train, batch_size, 20, 0, lr*4, self.device, 0.1, 10)\n",
    "\n",
    "    def local_initialization(self, net):\n",
    "        print(\"local_initialization!\")\n",
    "        local_model = net_local[self.idx].to(self.device)\n",
    "        self.ala.adaptive_local_aggregation(net, local_model)\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n",
    "\n",
    "        TPR_train_collect[self.idx] = []\n",
    "        FPR_train_collect[self.idx] = []\n",
    "        f1_train_collect[self.idx] = []\n",
    "        AUC_train_collect[self.idx] = []\n",
    "        loss_train_collect[self.idx] = []\n",
    "        acc_train_collect[self.idx] = []\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "        for iter in range(self.local_ep):\n",
    "            tmp_t0 = time.time()\n",
    "            batch_loss_train = []\n",
    "            batch_acc_train = []\n",
    "            batch_tpr_train = []\n",
    "            batch_fpr_train = []\n",
    "            batch_f1_train = []\n",
    "            batch_auc_train = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_train):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                BCEloss.backward()\n",
    "                optimizer_client.step()\n",
    "                batch_loss_train.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_train.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_train.append(auc)\n",
    "                batch_acc_train.append(accuracy)\n",
    "                batch_tpr_train.append(tpr)\n",
    "                batch_f1_train.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            epoch_avg_loss = sum(batch_loss_train)/len(batch_loss_train)\n",
    "            epoch_avg_acc = sum(batch_acc_train)/len(batch_acc_train)\n",
    "            epoch_avg_tpr = sum(batch_tpr_train)/len(batch_tpr_train)\n",
    "            epoch_avg_fpr = sum(batch_fpr_train)/len(batch_fpr_train)\n",
    "            epoch_avg_f1 = sum(batch_f1_train)/len(batch_f1_train)\n",
    "            epoch_avg_auc = sum(batch_auc_train)/len(batch_auc_train)\n",
    "            epoch_loss.append(sum(batch_loss_train)/len(batch_loss_train))\n",
    "            epoch_accuracy.append(sum(batch_acc_train)/len(batch_acc_train))\n",
    "            loss_train_collect[self.idx].append(epoch_avg_loss)\n",
    "            acc_train_collect[self.idx].append(epoch_avg_acc)\n",
    "            TPR_train_collect[self.idx].append(epoch_avg_tpr)\n",
    "            FPR_train_collect[self.idx].append(epoch_avg_fpr)\n",
    "            f1_train_collect[self.idx].append(epoch_avg_f1)\n",
    "            AUC_train_collect[self.idx].append(epoch_avg_auc)\n",
    "            loss_collect.append(epoch_avg_loss)\n",
    "            acc_collect.append(epoch_avg_acc)\n",
    "            TPR_collect.append(epoch_avg_tpr)\n",
    "            FPR_collect.append(epoch_avg_fpr)\n",
    "            F1_collect.append(epoch_avg_f1)\n",
    "            AUC_collect.append(epoch_avg_auc)\n",
    "\n",
    "            print('Client{} Local Train => Local Epoch: {} \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\t AUC:{:.10f}\\tTrain cost: {:}'.format(self.idx, iter, epoch_avg_loss, \\\n",
    "                                                                                                                                                                           epoch_avg_acc, epoch_avg_tpr, epoch_avg_fpr, epoch_avg_f1, epoch_avg_auc, elapsed))\n",
    "        net_glob.load_state_dict(net.state_dict())\n",
    "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_accuracy) / len(epoch_accuracy)\n",
    "\n",
    "    def evaluate(self, net, ell):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_t0 = time.time()\n",
    "            len_batch = len(self.ldr_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_tpr_test = []\n",
    "            batch_fpr_test = []\n",
    "            batch_f1_test = []\n",
    "            batch_auc_test = []\n",
    "            for batch_idx, (ids, attn_mask, b_labels) in enumerate(self.ldr_test):\n",
    "                ids, attn_mask, b_labels = ids.to(self.device), attn_mask.to(self.device), b_labels.to(self.device)\n",
    "                b_labels = b_labels.unsqueeze(1)\n",
    "                b_labels = b_labels.repeat(1,2)\n",
    "                for i in range(len(b_labels)):\n",
    "                    b_labels[i][1] = 1-b_labels[i][0]\n",
    "                logits = net(ids, attn_mask)\n",
    "                BCEloss = criterion(logits, b_labels.float())\n",
    "                batch_loss_test.append(BCEloss.item())\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                logits = np.argmax(logits, axis=1).flatten()\n",
    "                label_ids = np.argmax(label_ids,axis=1).flatten()\n",
    "                accuracy = flat_accuracy(logits, label_ids)\n",
    "                tpr = tpr_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    fpr = fpr_calculate(logits, label_ids)\n",
    "                    batch_fpr_test.append(fpr)\n",
    "                f1 = f1_score_calculate(logits, label_ids)\n",
    "                if len(set(label_ids)) == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    auc = AUC_calculate(logits, label_ids)\n",
    "                    batch_auc_test.append(auc)\n",
    "                batch_acc_test.append(accuracy)\n",
    "                batch_tpr_test.append(tpr)\n",
    "                batch_f1_test.append(f1)\n",
    "            elapsed = format_time(time.time()-tmp_t0)\n",
    "            test_avg_loss = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            test_avg_acc = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            test_avg_tpr = sum(batch_tpr_test)/len(batch_tpr_test)\n",
    "            test_avg_fpr = sum(batch_fpr_test) / len(batch_fpr_test)\n",
    "            test_avg_f1 = sum(batch_f1_test)/len(batch_f1_test)\n",
    "            test_avg_auc = sum(batch_auc_test)/len(batch_auc_test)\n",
    "            local_test[\"loss\"].append(test_avg_loss)\n",
    "            local_test[\"acc\"].append(test_avg_acc)\n",
    "            local_test[\"tpr\"].append(test_avg_tpr)\n",
    "            local_test[\"fpr\"].append(test_avg_fpr)\n",
    "            local_test[\"f1\"].append(test_avg_f1)\n",
    "            local_test[\"auc\"].append(test_avg_auc)\n",
    "            print('Client{} Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f} \\ttest cost: {:}'.format(self.idx, test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc, elapsed))\n",
    "\n",
    "        return test_avg_loss, test_avg_acc, test_avg_tpr, test_avg_fpr, test_avg_f1, test_avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ALA:\n",
    "    def __init__(self,\n",
    "                 cid: int,\n",
    "                 idxs,\n",
    "                 loss,\n",
    "                 train_data: TensorDataset,\n",
    "                 batch_size: int,\n",
    "                 rand_percent: int,\n",
    "                 layer_idx: int = 0,\n",
    "                 eta: float = 1.0,\n",
    "                 device: str = 'cpu',\n",
    "                 threshold: float = 0.1,\n",
    "                 num_pre_loss: int = 10) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ALA module\n",
    "\n",
    "        Args:\n",
    "            cid: Client ID.\n",
    "            loss: The loss function.\n",
    "            train_data: The reference of the local training data.\n",
    "            batch_size: Weight learning batch size.\n",
    "            rand_percent: The percent of the local training data to sample.\n",
    "            layer_idx: Control the weight range. By default, all the layers are selected. Default: 0\n",
    "            eta: Weight learning rate. Default: 1.0\n",
    "            device: Using cuda or cpu. Default: 'cpu'\n",
    "            threshold: Train the weight until the standard deviation of the recorded losses is less than a given threshold. Default: 0.1\n",
    "            num_pre_loss: The number of the recorded losses to be considered to calculate the standard deviation. Default: 10\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.cid = cid\n",
    "        self.idxs = idxs\n",
    "        self.loss = loss\n",
    "        self.train_data = train_data\n",
    "        self.batch_size = batch_size\n",
    "        self.rand_percent = rand_percent\n",
    "        self.layer_idx = layer_idx\n",
    "        self.eta = eta\n",
    "        self.threshold = threshold\n",
    "        self.num_pre_loss = num_pre_loss\n",
    "        self.device = device\n",
    "\n",
    "        self.weights = None # Learnable local aggregation weights.\n",
    "        self.start_phase = True\n",
    "\n",
    "\n",
    "    def adaptive_local_aggregation(self,\n",
    "                                   global_model: nn.Module,\n",
    "                                   local_model: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Generates the Dataloader for the randomly sampled local training data and\n",
    "        preserves the lower layers of the update.\n",
    "\n",
    "        Args:\n",
    "            global_model: The received global/aggregated model.\n",
    "            local_model: The trained local model.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # randomly sample partial local training data\n",
    "        rand_ratio = self.rand_percent / 100\n",
    "        rand_loader = DataLoader(DatasetSplit(self.train_data, self.idxs), self.batch_size, drop_last=True, shuffle=True)\n",
    "        rand_num = int(rand_ratio*len(rand_loader))\n",
    "\n",
    "\n",
    "        # obtain the references of the parameters\n",
    "        params_g = list(global_model.parameters())\n",
    "        params = list(local_model.parameters())\n",
    "\n",
    "        # deactivate ALA at the 1st communication iteration\n",
    "        if torch.sum(params_g[-1] - params[-1]) == 0:\n",
    "            print(\"deactivate ALA\")\n",
    "            return\n",
    "\n",
    "        # preserve all the updates in the lower layers\n",
    "        for param, param_g in zip(params[:-self.layer_idx], params_g[:-self.layer_idx]):\n",
    "            param.data = param_g.data.clone()\n",
    "\n",
    "\n",
    "        # temp local model only for weight learning\n",
    "        model_t = copy.deepcopy(local_model)\n",
    "        params_t = list(model_t.parameters())\n",
    "        params_t[-1].requires_grad_()\n",
    "\n",
    "        # only consider higher layers\n",
    "        params_p = params[-self.layer_idx:]\n",
    "        params_gp = params_g[-self.layer_idx:]\n",
    "        params_tp = params_t[-self.layer_idx:]\n",
    "\n",
    "\n",
    "        # used to obtain the gradient of higher layers\n",
    "        # no need to use optimizer.step(), so lr=0\n",
    "        optimizer = torch.optim.Adam(params_tp, lr = lr)\n",
    "\n",
    "        # initialize the weight to all ones in the beginning\n",
    "        if self.weights == None:\n",
    "            self.weights = [torch.ones_like(param.data).to(self.device) for param in params_p]\n",
    "\n",
    "        # initialize the higher layers in the temp local model\n",
    "        for param_t, param, param_g, weight in zip(params_tp, params_p, params_gp,\n",
    "                                                   self.weights):\n",
    "            param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "        # weight learning\n",
    "        losses = []  # record losses\n",
    "        losses_round = []\n",
    "        cnt = 0  # weight training iteration counter\n",
    "        while True:\n",
    "            for batch_idx, (x, m , y) in enumerate(rand_loader):\n",
    "                if batch_idx >= rand_num:\n",
    "                    break\n",
    "                x = x.to(self.device)\n",
    "                m = m.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                y = y.unsqueeze(1)\n",
    "                y = y.repeat(1,2)\n",
    "                for i in range(len(y)):\n",
    "                    y[i][1] = 1-y[i][0]\n",
    "                optimizer.zero_grad()\n",
    "                output = model_t(x, m)\n",
    "                loss_value = self.loss(output, y.float()) # modify according to the local objective\n",
    "                losses.append(loss_value.item())\n",
    "                loss_value.backward()\n",
    "\n",
    "                # update weight in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    #print(\"param_t.grad:\",param_t.requires_grad)\n",
    "                    #print(\"param_g - param:\",type(param_g - param))\n",
    "                    weight.data = torch.clamp(weight - self.eta * (param_t.grad * (param_g - param)), 0, 1)\n",
    "\n",
    "                # update temp local model in this batch\n",
    "                for param_t, param, param_g, weight in zip(params_tp, params_p,\n",
    "                                                           params_gp, self.weights):\n",
    "                    param_t.data = param + (param_g - param) * weight\n",
    "\n",
    "            losses_round.append(sum(losses) / len(losses))\n",
    "            cnt += 1\n",
    "\n",
    "            # only train one epoch in the subsequent iterations\n",
    "            if not self.start_phase:\n",
    "                break\n",
    "\n",
    "            # train the weight until convergence\n",
    "            if len(losses_round) > self.num_pre_loss or np.std(losses[-self.num_pre_loss:]) < self.threshold:\n",
    "                print('Client:', self.cid, '\\tStd:', np.std(losses[-self.num_pre_loss:]),\n",
    "                      '\\tALA epochs:', cnt)\n",
    "                break\n",
    "\n",
    "        self.start_phase = False\n",
    "\n",
    "        # obtain initialized local model\n",
    "        for param, param_t in zip(params_p, params_tp):\n",
    "            param.data = param_t.data.clone()\n",
    "        print(\"Client {}: Local Initial ALA epochs: {} Loss: {:.20f}\".format(self.cid, cnt, losses_round[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Evaluate Begin!\n",
      "============== Round 0:  =============\n",
      "local_initialization!\n",
      "deactivate ALA\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.4946514991 \tAcc: 0.7845784024 \tTPR:0.9554121697 \tFPR:0.7764274251 \tF1:0.8689496695 \t AUC:0.5893596704\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.4707483567 \tAcc: 0.8028846154 \tTPR:0.9532991431 \tFPR:0.7089138277 \tF1:0.8795974830 \t AUC:0.6221233686\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.4134785714 \tAcc: 0.8381102071 \tTPR:0.9658915116 \tFPR:0.5922620782 \tF1:0.9000396764 \t AUC:0.6867597063\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.3652202329 \tAcc: 0.8578032544 \tTPR:0.9597872379 \tFPR:0.4843348959 \tF1:0.9104992223 \t AUC:0.7377261710\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.3129755084 \tAcc: 0.8798076923 \tTPR:0.9617996245 \tFPR:0.3984608616 \tF1:0.9233734644 \t AUC:0.7816127044\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.3871209038 \tAcc: 0.8304166667 \tTPR:0.8959629931 \tFPR:0.2333625660 \tF1:0.8328517191 \tAUC:0.8313002136 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08288231224270032 \tALA epochs: 8\n",
      "Client 3: Local Initial ALA epochs: 8 Loss: 0.42271099705249071121\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.3979624912 \tAcc: 0.8169762383 \tTPR:0.8185724919 \tFPR:0.1816849165 \tF1:0.7926894210 \t AUC:0.8184437877\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.3959713673 \tAcc: 0.8132530120 \tTPR:0.8024364199 \tFPR:0.1810986142 \tF1:0.7843515744 \t AUC:0.8106689029\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.3748397123 \tAcc: 0.8278530790 \tTPR:0.8340018724 \tFPR:0.1732918513 \tF1:0.8033043674 \t AUC:0.8303550106\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.3719796468 \tAcc: 0.8307396252 \tTPR:0.8231622747 \tFPR:0.1608126100 \tF1:0.8054924297 \t AUC:0.8311748324\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.3511645099 \tAcc: 0.8454233601 \tTPR:0.8508842566 \tFPR:0.1557062404 \tF1:0.8221893133 \t AUC:0.8475890081\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.3879234445 \tAcc: 0.8214583333 \tTPR:0.7225129663 \tFPR:0.0825977371 \tF1:0.7929584752 \tAUC:0.8199576146 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.04091866327240478 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.27560455275370793204\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.2098776543 \tAcc: 0.9176169591 \tTPR:0.4460992549 \tFPR:0.0223062338 \tF1:0.4725249937 \t AUC:0.7044113653\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1980149885 \tAcc: 0.9194353070 \tTPR:0.4811351295 \tFPR:0.0248011585 \tF1:0.5068988151 \t AUC:0.7235342634\tTrain cost: 0:01:15\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1856646775 \tAcc: 0.9261604532 \tTPR:0.5262696409 \tFPR:0.0241635154 \tF1:0.5498596192 \t AUC:0.7442854862\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1780010294 \tAcc: 0.9274945175 \tTPR:0.5474734289 \tFPR:0.0249439143 \tF1:0.5684005742 \t AUC:0.7554979270\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1704427413 \tAcc: 0.9317342836 \tTPR:0.5849802326 \tFPR:0.0241469474 \tF1:0.5956505974 \t AUC:0.7757639546\tTrain cost: 0:01:10\n",
      "Client1 Test =>                 \tLoss: 0.6878346639 \tAcc: 0.7445833333 \tTPR:0.4878818324 \tFPR:0.0107374393 \tF1:0.6398782593 \tAUC:0.7385721966 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.19166936029630682 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.98920336636629968563\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.3391215799 \tAcc: 0.8740152311 \tTPR:0.9481061399 \tFPR:0.3973884251 \tF1:0.9200249482 \t AUC:0.7753588574\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2744473671 \tAcc: 0.9020483193 \tTPR:0.9669752338 \tFPR:0.3443516801 \tF1:0.9389704676 \t AUC:0.8113117768\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2732276986 \tAcc: 0.8910189076 \tTPR:0.9670921585 \tFPR:0.3636801690 \tF1:0.9325302082 \t AUC:0.8017059947\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2563571831 \tAcc: 0.9030330882 \tTPR:0.9781904406 \tFPR:0.3667375283 \tF1:0.9397882467 \t AUC:0.8057264561\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.2640555770 \tAcc: 0.9032956933 \tTPR:0.9744922406 \tFPR:0.3490697794 \tF1:0.9398401758 \t AUC:0.8127112306\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.3563643114 \tAcc: 0.8481250000 \tTPR:0.9790745663 \tFPR:0.2883706656 \tF1:0.8619804432 \tAUC:0.8453519503 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08912009750349886 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.29246513172984123230\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2803947730 \tAcc: 0.8859126984 \tTPR:0.9460674989 \tFPR:0.2446789322 \tF1:0.9167678762 \t AUC:0.8506942834\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2637083796 \tAcc: 0.8981894841 \tTPR:0.9543759214 \tFPR:0.2202733405 \tF1:0.9256075913 \t AUC:0.8670512904\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2701971986 \tAcc: 0.8892609127 \tTPR:0.9435178592 \tFPR:0.2240755111 \tF1:0.9187621580 \t AUC:0.8597211740\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2612647427 \tAcc: 0.8990575397 \tTPR:0.9523460173 \tFPR:0.2086349002 \tF1:0.9260897346 \t AUC:0.8718555586\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.2628855190 \tAcc: 0.8957093254 \tTPR:0.9492772900 \tFPR:0.2223459741 \tF1:0.9234734843 \t AUC:0.8634656579\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2760419258 \tAcc: 0.8891666667 \tTPR:0.9344056809 \tFPR:0.1587277617 \tF1:0.8917920449 \tAUC:0.8878389596 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.4190570499 \tAcc: 0.8267500000 \tTPR:0.8039676078 \tFPR:0.1547592339 \tF1:0.8038921883 \tAUC:0.8246041869\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 1:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.09693322495691804 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.29882399039342999458\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.3142668185 \tAcc: 0.8572205489 \tTPR:0.8671630405 \tFPR:0.1553873300 \tF1:0.8417310180 \t AUC:0.8558878552\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.3038614256 \tAcc: 0.8746234940 \tTPR:0.8813231517 \tFPR:0.1302597708 \tF1:0.8568284668 \t AUC:0.8755316904\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2932707176 \tAcc: 0.8725317938 \tTPR:0.8616413531 \tFPR:0.1206597807 \tF1:0.8504025059 \t AUC:0.8704907862\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2875618692 \tAcc: 0.8811914324 \tTPR:0.8791830896 \tFPR:0.1196272059 \tF1:0.8656540371 \t AUC:0.8797779419\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2917390174 \tAcc: 0.8765060241 \tTPR:0.8783760198 \tFPR:0.1226968949 \tF1:0.8583604172 \t AUC:0.8778395625\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2714651014 \tAcc: 0.8904166667 \tTPR:0.9159203073 \tFPR:0.1367437495 \tF1:0.8879036239 \tAUC:0.8895882789 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0745433078674565 \tALA epochs: 5\n",
      "Client 5: Local Initial ALA epochs: 5 Loss: 0.36582682486091339102\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.2179502132 \tAcc: 0.9049081921 \tTPR:0.6115793732 \tFPR:0.0426797359 \tF1:0.6210611907 \t AUC:0.7827899014\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.2101470131 \tAcc: 0.9079978814 \tTPR:0.6156510627 \tFPR:0.0412070000 \tF1:0.6255977985 \t AUC:0.7866776278\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.2046790378 \tAcc: 0.9121998588 \tTPR:0.6642302769 \tFPR:0.0419285416 \tF1:0.6673358580 \t AUC:0.8111508677\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1945031812 \tAcc: 0.9189442090 \tTPR:0.6762524356 \tFPR:0.0375215953 \tF1:0.6846463150 \t AUC:0.8193654201\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1853320314 \tAcc: 0.9209039548 \tTPR:0.6911727240 \tFPR:0.0384410527 \tF1:0.6888315953 \t AUC:0.8254884854\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.6847952482 \tAcc: 0.7575000000 \tTPR:0.5194720446 \tFPR:0.0084410781 \tF1:0.6697628882 \tAUC:0.7555154832 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.043462395616722875 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.16750770929159924938\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1570612792 \tAcc: 0.9358552632 \tTPR:0.6420385454 \tFPR:0.0256254495 \tF1:0.6384428262 \t AUC:0.8028155622\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1462402219 \tAcc: 0.9433022661 \tTPR:0.6736111111 \tFPR:0.0229521011 \tF1:0.6812870299 \t AUC:0.8231535791\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1419272133 \tAcc: 0.9426991959 \tTPR:0.6663539636 \tFPR:0.0228941250 \tF1:0.6676227558 \t AUC:0.8197556824\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1353174452 \tAcc: 0.9473135965 \tTPR:0.6924980275 \tFPR:0.0213264901 \tF1:0.6946762784 \t AUC:0.8314303366\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1307556053 \tAcc: 0.9471856725 \tTPR:0.7010628423 \tFPR:0.0226059194 \tF1:0.6991263657 \t AUC:0.8356483757\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.8081204919 \tAcc: 0.7366666667 \tTPR:0.4668353155 \tFPR:0.0040901626 \tF1:0.6258868757 \tAUC:0.7313725765 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.2045214407804846 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 1.02676163749261339930\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.3782731557 \tAcc: 0.8595063025 \tTPR:0.9376566917 \tFPR:0.3711592971 \tF1:0.9074943320 \t AUC:0.7832486973\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.2268549028 \tAcc: 0.9153098739 \tTPR:0.9691600959 \tFPR:0.3033652855 \tF1:0.9466855343 \t AUC:0.8328974052\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.2109445371 \tAcc: 0.9274553571 \tTPR:0.9751233607 \tFPR:0.2213021106 \tF1:0.9539092319 \t AUC:0.8769106251\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.2242831181 \tAcc: 0.9164259454 \tTPR:0.9732629117 \tFPR:0.3016362606 \tF1:0.9479765245 \t AUC:0.8358133256\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1970646679 \tAcc: 0.9229910714 \tTPR:0.9683360319 \tFPR:0.2642290249 \tF1:0.9516065112 \t AUC:0.8520535035\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2473132550 \tAcc: 0.8979166667 \tTPR:0.9595712518 \tFPR:0.1660247171 \tF1:0.9027595478 \tAUC:0.8967732673 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04976956737918087 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.23128487239591777325\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.2284417135 \tAcc: 0.9150545635 \tTPR:0.9589078826 \tFPR:0.1771473236 \tF1:0.9376967037 \t AUC:0.8908802795\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.2175108211 \tAcc: 0.9123263889 \tTPR:0.9540655227 \tFPR:0.1710261960 \tF1:0.9356543793 \t AUC:0.8915196633\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.2124026596 \tAcc: 0.9190228175 \tTPR:0.9581028484 \tFPR:0.1617897480 \tF1:0.9392269116 \t AUC:0.8981565502\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.2052397697 \tAcc: 0.9205109127 \tTPR:0.9584199006 \tFPR:0.1619121289 \tF1:0.9409262731 \t AUC:0.8982538858\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1988411795 \tAcc: 0.9270833333 \tTPR:0.9610548551 \tFPR:0.1449088279 \tF1:0.9460154957 \t AUC:0.9080730136\tTrain cost: 0:00:10\n",
      "Client7 Test =>                 \tLoss: 0.2389655306 \tAcc: 0.9077083333 \tTPR:0.8835452606 \tFPR:0.0689741427 \tF1:0.9029385217 \tAUC:0.9072855590 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.4501319254 \tAcc: 0.8380416667 \tTPR:0.7490688359 \tFPR:0.0768547700 \tF1:0.7978502914 \tAUC:0.8361070330\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 2:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06002979374029929 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.21211835555732250214\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.2398811574 \tAcc: 0.9079233601 \tTPR:0.9046560840 \tFPR:0.0863231694 \tF1:0.8933957819 \t AUC:0.9091664573\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.2281302235 \tAcc: 0.9039909639 \tTPR:0.9093216194 \tFPR:0.1024666061 \tF1:0.8895300005 \t AUC:0.9034275067\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.2196669994 \tAcc: 0.9039491299 \tTPR:0.9020914585 \tFPR:0.0938895312 \tF1:0.8900579081 \t AUC:0.9041009636\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.2086621983 \tAcc: 0.9162064926 \tTPR:0.9168050975 \tFPR:0.0844792654 \tF1:0.9040684253 \t AUC:0.9161629160\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.2078004386 \tAcc: 0.9143239625 \tTPR:0.9161390132 \tFPR:0.0846331094 \tF1:0.9030800100 \t AUC:0.9157529519\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2503727513 \tAcc: 0.9008333333 \tTPR:0.8556373503 \tFPR:0.0577112098 \tF1:0.8906634815 \tAUC:0.8989630702 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07643525801114948 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.24518868038025887213\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.2289900658 \tAcc: 0.9102848787 \tTPR:0.9494916537 \tFPR:0.1608000969 \tF1:0.9303270491 \t AUC:0.8943457784\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.2124410626 \tAcc: 0.9174485069 \tTPR:0.9527940846 \tFPR:0.1473615757 \tF1:0.9357524476 \t AUC:0.9027162545\tTrain cost: 0:02:06\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.2043287780 \tAcc: 0.9216062858 \tTPR:0.9536372065 \tFPR:0.1360024616 \tF1:0.9385768097 \t AUC:0.9088173725\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1949424753 \tAcc: 0.9252599653 \tTPR:0.9577213138 \tFPR:0.1337776649 \tF1:0.9414352818 \t AUC:0.9119718244\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1872864448 \tAcc: 0.9268035095 \tTPR:0.9580873694 \tFPR:0.1317008237 \tF1:0.9427916488 \t AUC:0.9131932728\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.2334790662 \tAcc: 0.9139583333 \tTPR:0.9156471937 \tFPR:0.0854742366 \tF1:0.9114068515 \tAUC:0.9150864786 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.06993725716421634 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.16205712735875330011\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1637447981 \tAcc: 0.9399963018 \tTPR:0.9745635093 \tFPR:0.1725849919 \tF1:0.9605988351 \t AUC:0.9009135549\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1595990717 \tAcc: 0.9432322485 \tTPR:0.9761536119 \tFPR:0.1676637383 \tF1:0.9631496904 \t AUC:0.9042449368\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1559048554 \tAcc: 0.9412906805 \tTPR:0.9759313869 \tFPR:0.1757315904 \tF1:0.9618083487 \t AUC:0.9000998982\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1531438949 \tAcc: 0.9424926036 \tTPR:0.9744188087 \tFPR:0.1651391223 \tF1:0.9622920565 \t AUC:0.9046018889\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1494175174 \tAcc: 0.9443417160 \tTPR:0.9756619447 \tFPR:0.1571580085 \tF1:0.9635340820 \t AUC:0.9092158582\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2106941016 \tAcc: 0.9233333333 \tTPR:0.9432920595 \tFPR:0.0960203670 \tF1:0.9208380382 \tAUC:0.9236358462 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.066295084234358 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.19680842943489551544\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1867171077 \tAcc: 0.9284474206 \tTPR:0.9609402495 \tFPR:0.1441160196 \tF1:0.9463736078 \t AUC:0.9084121150\tTrain cost: 0:00:10\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1728183085 \tAcc: 0.9341517857 \tTPR:0.9645626937 \tFPR:0.1246814198 \tF1:0.9509265417 \t AUC:0.9199406370\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1665230708 \tAcc: 0.9367559524 \tTPR:0.9680526630 \tFPR:0.1334684539 \tF1:0.9532513587 \t AUC:0.9172921046\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1686825397 \tAcc: 0.9365079365 \tTPR:0.9664448329 \tFPR:0.1239781315 \tF1:0.9529746977 \t AUC:0.9212333507\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1588017995 \tAcc: 0.9394841270 \tTPR:0.9679204852 \tFPR:0.1193488866 \tF1:0.9540759517 \t AUC:0.9242857993\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2157206254 \tAcc: 0.9185416667 \tTPR:0.9197234092 \tFPR:0.0842920693 \tF1:0.9158469124 \tAUC:0.9177156699 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.0883394062361204 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.24556007683760933125\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2108102411 \tAcc: 0.9135625889 \tTPR:0.9264551008 \tFPR:0.0990351894 \tF1:0.9076900608 \t AUC:0.9137099557\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2051473423 \tAcc: 0.9166064922 \tTPR:0.9258978073 \tFPR:0.0929206762 \tF1:0.9100224600 \t AUC:0.9164885656\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.2027737488 \tAcc: 0.9165092872 \tTPR:0.9286145154 \tFPR:0.0931624393 \tF1:0.9107693684 \t AUC:0.9177260381\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1972590517 \tAcc: 0.9195309723 \tTPR:0.9316768230 \tFPR:0.0917634812 \tF1:0.9137998247 \t AUC:0.9199566709\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1900145313 \tAcc: 0.9225582119 \tTPR:0.9325231562 \tFPR:0.0858580012 \tF1:0.9165430509 \t AUC:0.9233325775\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.1872395808 \tAcc: 0.9281250000 \tTPR:0.9127676519 \tFPR:0.0590109216 \tF1:0.9235041169 \tAUC:0.9268783652 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2195012251 \tAcc: 0.9169583333 \tTPR:0.9094135329 \tFPR:0.0765017609 \tF1:0.9124518801 \tAUC:0.9164558860\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 3:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.06053547176314792 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.09923777627674015833\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0890680127 \tAcc: 0.9675595238 \tTPR:0.9905226541 \tFPR:0.2939393939 \tF1:0.9824510478 \t AUC:0.8481449326\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0860783774 \tAcc: 0.9659970238 \tTPR:0.9878459915 \tFPR:0.3206060606 \tF1:0.9814336362 \t AUC:0.8333516014\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0773994278 \tAcc: 0.9739583333 \tTPR:0.9928130437 \tFPR:0.2983660131 \tF1:0.9859459846 \t AUC:0.8472021172\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0688061420 \tAcc: 0.9739583333 \tTPR:0.9912684115 \tFPR:0.2428104575 \tF1:0.9856376877 \t AUC:0.8740712878\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0717788524 \tAcc: 0.9744791667 \tTPR:0.9910473277 \tFPR:0.2580357143 \tF1:0.9861353838 \t AUC:0.8661860684\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2653052753 \tAcc: 0.9135416667 \tTPR:0.9758070479 \tFPR:0.1497153954 \tF1:0.9177674777 \tAUC:0.9130458263 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09654157017238789 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.12714147999544034295\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1395429536 \tAcc: 0.9521837349 \tTPR:0.9814807267 \tFPR:0.1750940575 \tF1:0.9701328908 \t AUC:0.9031933346\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1335130830 \tAcc: 0.9526543675 \tTPR:0.9809745342 \tFPR:0.1598647241 \tF1:0.9703028914 \t AUC:0.9105261657\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.1289131285 \tAcc: 0.9541603916 \tTPR:0.9817758629 \tFPR:0.1539201762 \tF1:0.9710776240 \t AUC:0.9139278433\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.1234101587 \tAcc: 0.9566076807 \tTPR:0.9812630201 \tFPR:0.1535113314 \tF1:0.9728692099 \t AUC:0.9138758444\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.1284005132 \tAcc: 0.9537838855 \tTPR:0.9802536271 \tFPR:0.1516314843 \tF1:0.9709616606 \t AUC:0.9143110714\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1835288834 \tAcc: 0.9289583333 \tTPR:0.9438610408 \tFPR:0.0887104083 \tF1:0.9294251446 \tAUC:0.9275753163 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0726113119152451 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.14396382998953113908\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1562544891 \tAcc: 0.9430473373 \tTPR:0.9753571380 \tFPR:0.1665721684 \tF1:0.9628389595 \t AUC:0.9043559227\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1460056477 \tAcc: 0.9448964497 \tTPR:0.9740101075 \tFPR:0.1576955425 \tF1:0.9635669956 \t AUC:0.9081572825\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1544777668 \tAcc: 0.9460983728 \tTPR:0.9794146077 \tFPR:0.1622760950 \tF1:0.9647839930 \t AUC:0.9085692563\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1432004806 \tAcc: 0.9481323964 \tTPR:0.9783065140 \tFPR:0.1516447614 \tF1:0.9659735849 \t AUC:0.9132986901\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1371494931 \tAcc: 0.9487795858 \tTPR:0.9785352601 \tFPR:0.1507741681 \tF1:0.9664279690 \t AUC:0.9138486992\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.2100003552 \tAcc: 0.9243750000 \tTPR:0.9416629824 \tFPR:0.0915184723 \tF1:0.9209669256 \tAUC:0.9250722550 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08034758876786266 \tALA epochs: 6\n",
      "Client 6: Local Initial ALA epochs: 6 Loss: 0.26769097023583077188\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.2110212393 \tAcc: 0.9111380199 \tTPR:0.9208541550 \tFPR:0.0983542545 \tF1:0.9052317570 \t AUC:0.9112499502\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.2003111836 \tAcc: 0.9195865180 \tTPR:0.9320692481 \tFPR:0.0926770477 \tF1:0.9140332512 \t AUC:0.9196961002\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1929513146 \tAcc: 0.9206418859 \tTPR:0.9326754657 \tFPR:0.0906955336 \tF1:0.9166565302 \t AUC:0.9209899661\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1912942827 \tAcc: 0.9238885309 \tTPR:0.9362118033 \tFPR:0.0866205309 \tF1:0.9181606199 \t AUC:0.9247956362\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1859176058 \tAcc: 0.9242745734 \tTPR:0.9341183710 \tFPR:0.0855485629 \tF1:0.9197217262 \t AUC:0.9242849040\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2003578419 \tAcc: 0.9233333333 \tTPR:0.8900662535 \tFPR:0.0433202922 \tF1:0.9178083736 \tAUC:0.9233729807 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05133242667375528 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.20425580907613039017\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1732154721 \tAcc: 0.9336557540 \tTPR:0.9639260872 \tFPR:0.1308815737 \tF1:0.9509199049 \t AUC:0.9165222567\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1563350773 \tAcc: 0.9484126984 \tTPR:0.9770420248 \tFPR:0.1140530105 \tF1:0.9616959068 \t AUC:0.9314945072\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1560509827 \tAcc: 0.9432043651 \tTPR:0.9748084563 \tFPR:0.1209831670 \tF1:0.9580646923 \t AUC:0.9269126447\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1498844331 \tAcc: 0.9468005952 \tTPR:0.9729414166 \tFPR:0.1098913963 \tF1:0.9598569810 \t AUC:0.9315250101\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1504303544 \tAcc: 0.9469246032 \tTPR:0.9727919256 \tFPR:0.1124232745 \tF1:0.9605862005 \t AUC:0.9301843256\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2228144416 \tAcc: 0.9187500000 \tTPR:0.8924937315 \tFPR:0.0565213009 \tF1:0.9125942702 \tAUC:0.9179862153 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2164013595 \tAcc: 0.9217916667 \tTPR:0.9287782112 \tFPR:0.0859571738 \tF1:0.9197124383 \tAUC:0.9214105187\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 4:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09485072495947237 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.31131134920424835544\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1186765399 \tAcc: 0.9525310673 \tTPR:0.7348527569 \tFPR:0.0206799099 \tF1:0.7307542756 \t AUC:0.8547190374\tTrain cost: 0:01:17\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1142090419 \tAcc: 0.9528965643 \tTPR:0.7418743618 \tFPR:0.0205834255 \tF1:0.7348068884 \t AUC:0.8575541432\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.1099960341 \tAcc: 0.9553362573 \tTPR:0.7534681611 \tFPR:0.0190042979 \tF1:0.7385250960 \t AUC:0.8644681218\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.1083272072 \tAcc: 0.9566885965 \tTPR:0.7641888286 \tFPR:0.0182642594 \tF1:0.7573124447 \t AUC:0.8694109115\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.1076463744 \tAcc: 0.9565515351 \tTPR:0.7724785448 \tFPR:0.0186765898 \tF1:0.7548422338 \t AUC:0.8713176289\tTrain cost: 0:01:13\n",
      "Client1 Test =>                 \tLoss: 0.4204690385 \tAcc: 0.8531250000 \tTPR:0.7096360523 \tFPR:0.0123675487 \tF1:0.8179379384 \tAUC:0.8486342518 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0650412349826932 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.22651262045837938786\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1747734034 \tAcc: 0.9359939759 \tTPR:0.9376259632 \tFPR:0.0676070858 \tF1:0.9260303609 \t AUC:0.9350094387\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1629251339 \tAcc: 0.9363704819 \tTPR:0.9403902145 \tFPR:0.0672145124 \tF1:0.9264329412 \t AUC:0.9365878511\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1548765362 \tAcc: 0.9395498661 \tTPR:0.9497549885 \tFPR:0.0718161877 \tF1:0.9323786786 \t AUC:0.9389694004\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1601223789 \tAcc: 0.9341114458 \tTPR:0.9358398817 \tFPR:0.0687634589 \tF1:0.9247269629 \t AUC:0.9335382114\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1503534286 \tAcc: 0.9423945783 \tTPR:0.9538236495 \tFPR:0.0652922522 \tF1:0.9364224006 \t AUC:0.9442656987\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.3081621423 \tAcc: 0.8908333333 \tTPR:0.8078863153 \tFPR:0.0252537764 \tF1:0.8772230044 \tAUC:0.8913162694 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05786271252368935 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.21209882361838569564\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1932618423 \tAcc: 0.9218750000 \tTPR:0.9297782397 \tFPR:0.0858885099 \tF1:0.9161290832 \t AUC:0.9219448649\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1905964090 \tAcc: 0.9239357448 \tTPR:0.9310485788 \tFPR:0.0818921240 \tF1:0.9171187894 \t AUC:0.9245782274\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1852679706 \tAcc: 0.9238885309 \tTPR:0.9317654267 \tFPR:0.0848873527 \tF1:0.9192850573 \t AUC:0.9234390370\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1808880525 \tAcc: 0.9249189033 \tTPR:0.9339456420 \tFPR:0.0827152993 \tF1:0.9198663874 \t AUC:0.9256151714\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1730850513 \tAcc: 0.9315954941 \tTPR:0.9407232101 \tFPR:0.0772988910 \tF1:0.9264209482 \t AUC:0.9317121596\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2702841407 \tAcc: 0.9016666667 \tTPR:0.8249251166 \tFPR:0.0250465843 \tF1:0.8871896738 \tAUC:0.8999392661 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04388412820144108 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.23669961839914321899\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0828051913 \tAcc: 0.9703125000 \tTPR:0.9882466679 \tFPR:0.2617724868 \tF1:0.9837325115 \t AUC:0.8637415351\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0680481893 \tAcc: 0.9748511905 \tTPR:0.9901605199 \tFPR:0.2197454844 \tF1:0.9861872961 \t AUC:0.8850378715\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0671381993 \tAcc: 0.9812500000 \tTPR:0.9964359784 \tFPR:0.2352201258 \tF1:0.9897236132 \t AUC:0.8803725664\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0602778323 \tAcc: 0.9786458333 \tTPR:0.9916746837 \tFPR:0.1747835498 \tF1:0.9882827605 \t AUC:0.9083512344\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0583991006 \tAcc: 0.9791666667 \tTPR:0.9920587966 \tFPR:0.1775757576 \tF1:0.9885935423 \t AUC:0.9071646466\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2959590849 \tAcc: 0.9070833333 \tTPR:0.9808262863 \tFPR:0.1696395482 \tF1:0.9125054663 \tAUC:0.9055933691 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.18972506604847136 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.76209615832799437740\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1416748582 \tAcc: 0.9397775424 \tTPR:0.7788671623 \tFPR:0.0323232686 \tF1:0.7760258606 \t AUC:0.8729587275\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1284298070 \tAcc: 0.9469456215 \tTPR:0.8003309936 \tFPR:0.0276376571 \tF1:0.7974245890 \t AUC:0.8863466682\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1292387763 \tAcc: 0.9463276836 \tTPR:0.7955423970 \tFPR:0.0275871823 \tF1:0.7959128899 \t AUC:0.8839776074\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1237594329 \tAcc: 0.9491525424 \tTPR:0.8164248495 \tFPR:0.0263151114 \tF1:0.8002258508 \t AUC:0.8934723246\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1220649523 \tAcc: 0.9492408192 \tTPR:0.8064568200 \tFPR:0.0260360076 \tF1:0.8062841773 \t AUC:0.8896605676\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.3651987559 \tAcc: 0.8675000000 \tTPR:0.7508393312 \tFPR:0.0179267475 \tF1:0.8430520782 \tAUC:0.8664562919 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3320146325 \tAcc: 0.8840416667 \tTPR:0.8148226203 \tFPR:0.0500468410 \tF1:0.8675816322 \tAUC:0.8823878897\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 5:  =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06584208098924013 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.24853572249412536621\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1812590566 \tAcc: 0.9320509454 \tTPR:0.9667201790 \tFPR:0.1991664090 \tF1:0.9546629190 \t AUC:0.8837768850\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1731728198 \tAcc: 0.9408482143 \tTPR:0.9758011367 \tFPR:0.1911564626 \tF1:0.9623959875 \t AUC:0.8923223371\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1643781814 \tAcc: 0.9367778361 \tTPR:0.9837834579 \tFPR:0.2209428468 \tF1:0.9591736279 \t AUC:0.8814203055\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1622350342 \tAcc: 0.9411108193 \tTPR:0.9771950927 \tFPR:0.1857477840 \tF1:0.9622855510 \t AUC:0.8957236543\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1577106418 \tAcc: 0.9366465336 \tTPR:0.9770785536 \tFPR:0.2158485364 \tF1:0.9594579955 \t AUC:0.8806150086\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1823317067 \tAcc: 0.9297916667 \tTPR:0.9527516280 \tFPR:0.0927319629 \tF1:0.9290238921 \tAUC:0.9300098326 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07435374184869488 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.19334587607046832547\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1711757658 \tAcc: 0.9342775130 \tTPR:0.9641879383 \tFPR:0.1207130032 \tF1:0.9488187522 \t AUC:0.9217374676\tTrain cost: 0:02:09\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1652863519 \tAcc: 0.9357814791 \tTPR:0.9651353250 \tFPR:0.1171945949 \tF1:0.9499863000 \t AUC:0.9239703651\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1612155934 \tAcc: 0.9372562825 \tTPR:0.9652777123 \tFPR:0.1136875863 \tF1:0.9505092908 \t AUC:0.9257950630\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1564364408 \tAcc: 0.9400871550 \tTPR:0.9674930859 \tFPR:0.1090440750 \tF1:0.9531260599 \t AUC:0.9292245055\tTrain cost: 0:02:07\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1526818925 \tAcc: 0.9414140615 \tTPR:0.9682717665 \tFPR:0.1067847159 \tF1:0.9541573105 \t AUC:0.9307435253\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.2030338351 \tAcc: 0.9247916667 \tTPR:0.9308796301 \tFPR:0.0828983668 \tF1:0.9225873911 \tAUC:0.9239906317 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08347443532038513 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.20235566303811289290\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1798925803 \tAcc: 0.9268602248 \tTPR:0.9384645940 \tFPR:0.0829852478 \tF1:0.9217539539 \t AUC:0.9277396731\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1731664233 \tAcc: 0.9294292126 \tTPR:0.9404666168 \tFPR:0.0810615473 \tF1:0.9241435534 \t AUC:0.9297025348\tTrain cost: 0:00:45\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1729654454 \tAcc: 0.9308956186 \tTPR:0.9424578084 \tFPR:0.0792054497 \tF1:0.9260480857 \t AUC:0.9316261793\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1683510025 \tAcc: 0.9335451475 \tTPR:0.9429755747 \tFPR:0.0754191650 \tF1:0.9282644344 \t AUC:0.9337782048\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1615607796 \tAcc: 0.9357114291 \tTPR:0.9438276919 \tFPR:0.0708268611 \tF1:0.9311012770 \t AUC:0.9365004154\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2046388713 \tAcc: 0.9283333333 \tTPR:0.8927258689 \tFPR:0.0367223345 \tF1:0.9224327890 \tAUC:0.9280017672 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06748336935936476 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.16863920450594058198\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.1057172977 \tAcc: 0.9563961988 \tTPR:0.7561009004 \tFPR:0.0195103402 \tF1:0.7491568294 \t AUC:0.8663020482\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.1013336294 \tAcc: 0.9591831140 \tTPR:0.7842000835 \tFPR:0.0180936709 \tF1:0.7742494742 \t AUC:0.8796355606\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0960629811 \tAcc: 0.9609283626 \tTPR:0.7920379653 \tFPR:0.0177018411 \tF1:0.7810635192 \t AUC:0.8849953244\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0956428114 \tAcc: 0.9619426170 \tTPR:0.7824770259 \tFPR:0.0161811047 \tF1:0.7859107579 \t AUC:0.8807093622\tTrain cost: 0:01:16\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0904467763 \tAcc: 0.9636695906 \tTPR:0.8081766917 \tFPR:0.0173703427 \tF1:0.7995578049 \t AUC:0.8926628416\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.4562295970 \tAcc: 0.8512500000 \tTPR:0.7097552255 \tFPR:0.0106188228 \tF1:0.8194843859 \tAUC:0.8495682014 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06653222366390196 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.13503479295011078243\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1275280602 \tAcc: 0.9469103107 \tTPR:0.8087050896 \tFPR:0.0273008500 \tF1:0.7970929454 \t AUC:0.8887726322\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1189036133 \tAcc: 0.9515713277 \tTPR:0.8134916323 \tFPR:0.0237864411 \tF1:0.8083622941 \t AUC:0.8943227423\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1160886488 \tAcc: 0.9525953390 \tTPR:0.8268436993 \tFPR:0.0245128610 \tF1:0.8235953299 \t AUC:0.9009201553\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1113878646 \tAcc: 0.9559322034 \tTPR:0.8365527755 \tFPR:0.0233551572 \tF1:0.8337764857 \t AUC:0.9059003167\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1072791971 \tAcc: 0.9567443503 \tTPR:0.8431784553 \tFPR:0.0227177126 \tF1:0.8393453034 \t AUC:0.9097848556\tTrain cost: 0:00:38\n",
      "Client5 Test =>                 \tLoss: 0.3421975381 \tAcc: 0.8822916667 \tTPR:0.7786520973 \tFPR:0.0149451416 \tF1:0.8632315855 \tAUC:0.8818534779 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2776863096 \tAcc: 0.9032916667 \tTPR:0.8529528900 \tFPR:0.0475833257 \tF1:0.8913520087 \tAUC:0.9026847821\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 6:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.056946443726623115 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.18538517591112585459\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1413328214 \tAcc: 0.9497041420 \tTPR:0.9795380505 \tFPR:0.1458463299 \tF1:0.9671803084 \t AUC:0.9168458603\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1347393898 \tAcc: 0.9525702663 \tTPR:0.9801500402 \tFPR:0.1396500079 \tF1:0.9688072036 \t AUC:0.9202205652\tTrain cost: 0:00:42\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1286313611 \tAcc: 0.9535872781 \tTPR:0.9806447692 \tFPR:0.1380436712 \tF1:0.9694474230 \t AUC:0.9212718320\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1229921301 \tAcc: 0.9559911243 \tTPR:0.9825648022 \tFPR:0.1355331653 \tF1:0.9710287558 \t AUC:0.9234899502\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1218924288 \tAcc: 0.9554363905 \tTPR:0.9816679641 \tFPR:0.1327830043 \tF1:0.9708558084 \t AUC:0.9244424799\tTrain cost: 0:00:36\n",
      "Client8 Test =>                 \tLoss: 0.2062812298 \tAcc: 0.9256250000 \tTPR:0.9410881594 \tFPR:0.0892567319 \tF1:0.9245348144 \tAUC:0.9259157137 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08856632126423192 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.15790414291069559960\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1546872060 \tAcc: 0.9399913345 \tTPR:0.9679918378 \tFPR:0.1104270633 \tF1:0.9529611425 \t AUC:0.9287823873\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1490970079 \tAcc: 0.9430117651 \tTPR:0.9694922559 \tFPR:0.1046717017 \tF1:0.9551788057 \t AUC:0.9324102771\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1447210765 \tAcc: 0.9447177876 \tTPR:0.9711400218 \tFPR:0.1021025110 \tF1:0.9566856796 \t AUC:0.9345187554\tTrain cost: 0:02:05\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1426720855 \tAcc: 0.9450427443 \tTPR:0.9711359729 \tFPR:0.1013965805 \tF1:0.9570367534 \t AUC:0.9348696962\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1381649735 \tAcc: 0.9480340121 \tTPR:0.9723232843 \tFPR:0.0966830154 \tF1:0.9592757315 \t AUC:0.9378201344\tTrain cost: 0:02:02\n",
      "Client4 Test =>                 \tLoss: 0.2067831547 \tAcc: 0.9275000000 \tTPR:0.9168981656 \tFPR:0.0639656968 \tF1:0.9240757607 \tAUC:0.9264662344 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09014003191265539 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.21878606227359601033\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1219686825 \tAcc: 0.9496822034 \tTPR:0.8232878625 \tFPR:0.0277831707 \tF1:0.8069481529 \t AUC:0.8967425622\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1182287296 \tAcc: 0.9516066384 \tTPR:0.8236185503 \tFPR:0.0269821487 \tF1:0.8171139977 \t AUC:0.8980683687\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1110536019 \tAcc: 0.9542196328 \tTPR:0.8334608188 \tFPR:0.0233620611 \tF1:0.8272662836 \t AUC:0.9050493789\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.1097322642 \tAcc: 0.9539194915 \tTPR:0.8375285339 \tFPR:0.0246390598 \tF1:0.8260563607 \t AUC:0.9057504145\tTrain cost: 0:00:40\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.1034805799 \tAcc: 0.9579802260 \tTPR:0.8517773579 \tFPR:0.0221228510 \tF1:0.8443081712 \t AUC:0.9141938234\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.3960017112 \tAcc: 0.8764583333 \tTPR:0.7666170662 \tFPR:0.0178149485 \tF1:0.8556781129 \tAUC:0.8744010589 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07376285294032443 \tALA epochs: 9\n",
      "Client 7: Local Initial ALA epochs: 9 Loss: 0.33038790363611447720\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1575479855 \tAcc: 0.9375000000 \tTPR:0.9645973768 \tFPR:0.1190993861 \tF1:0.9525333604 \t AUC:0.9227489954\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1499760326 \tAcc: 0.9433283730 \tTPR:0.9758688878 \tFPR:0.1246386550 \tF1:0.9582522582 \t AUC:0.9256151164\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1414500667 \tAcc: 0.9471726190 \tTPR:0.9721085882 \tFPR:0.1032089273 \tF1:0.9605407283 \t AUC:0.9344498305\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1353991960 \tAcc: 0.9506448413 \tTPR:0.9761808041 \tFPR:0.1057650828 \tF1:0.9635256805 \t AUC:0.9352078606\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1362323221 \tAcc: 0.9495287698 \tTPR:0.9721295611 \tFPR:0.1007536445 \tF1:0.9628604769 \t AUC:0.9356879583\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2040043760 \tAcc: 0.9256250000 \tTPR:0.9527348635 \tFPR:0.1023190829 \tF1:0.9268912147 \tAUC:0.9252078903 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07078988310227224 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.11077868228665355144\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1148056626 \tAcc: 0.9582078313 \tTPR:0.9832789405 \tFPR:0.1411074200 \tF1:0.9737747121 \t AUC:0.9210857603\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1100284251 \tAcc: 0.9602786145 \tTPR:0.9851441797 \tFPR:0.1415527197 \tF1:0.9748728038 \t AUC:0.9218204946\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0992381151 \tAcc: 0.9644201807 \tTPR:0.9864773435 \tFPR:0.1294114771 \tF1:0.9776787797 \t AUC:0.9285329332\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0985953294 \tAcc: 0.9643260542 \tTPR:0.9859424928 \tFPR:0.1268458730 \tF1:0.9775507752 \t AUC:0.9295057114\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0975229287 \tAcc: 0.9633847892 \tTPR:0.9855700535 \tFPR:0.1303332711 \tF1:0.9768884389 \t AUC:0.9276183912\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1669030579 \tAcc: 0.9404166667 \tTPR:0.9696043897 \tFPR:0.0890971333 \tF1:0.9412584093 \tAUC:0.9402536282 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2359947059 \tAcc: 0.9191250000 \tTPR:0.9093885289 \tFPR:0.0724907187 \tF1:0.9144876624 \tAUC:0.9184489051\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 7:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07469979421258241 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.13774182190308753571\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1391220946 \tAcc: 0.9460842721 \tTPR:0.9698218710 \tFPR:0.0971911266 \tF1:0.9578282141 \t AUC:0.9363153722\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1389458836 \tAcc: 0.9456259999 \tTPR:0.9712165581 \tFPR:0.1005029005 \tF1:0.9574173354 \t AUC:0.9353568288\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1337626181 \tAcc: 0.9491984402 \tTPR:0.9723226860 \tFPR:0.0930681022 \tF1:0.9600139700 \t AUC:0.9396272919\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1297300827 \tAcc: 0.9501462305 \tTPR:0.9728111076 \tFPR:0.0916762461 \tF1:0.9607753631 \t AUC:0.9405674308\tTrain cost: 0:02:06\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1304639284 \tAcc: 0.9509857019 \tTPR:0.9737278608 \tFPR:0.0901801952 \tF1:0.9617409081 \t AUC:0.9417738328\tTrain cost: 0:02:05\n",
      "Client4 Test =>                 \tLoss: 0.2142979571 \tAcc: 0.9250000000 \tTPR:0.8993940394 \tFPR:0.0513587029 \tF1:0.9192242059 \tAUC:0.9240176682 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09019485942022491 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.13654138776473701000\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1459969254 \tAcc: 0.9456845238 \tTPR:0.9753345710 \tFPR:0.1215640785 \tF1:0.9599368757 \t AUC:0.9267366593\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1382187413 \tAcc: 0.9456845238 \tTPR:0.9760217266 \tFPR:0.1191754178 \tF1:0.9598020529 \t AUC:0.9284231544\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1327121891 \tAcc: 0.9505208333 \tTPR:0.9769107052 \tFPR:0.1039769093 \tF1:0.9633747683 \t AUC:0.9364668979\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1241147888 \tAcc: 0.9569692460 \tTPR:0.9800147378 \tFPR:0.0964491031 \tF1:0.9688129073 \t AUC:0.9417828173\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1272287324 \tAcc: 0.9517609127 \tTPR:0.9795702315 \tFPR:0.1083220681 \tF1:0.9647720535 \t AUC:0.9356240817\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2353560529 \tAcc: 0.9212500000 \tTPR:0.8871521913 \tFPR:0.0440609639 \tF1:0.9165226482 \tAUC:0.9215456137 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06800302208055521 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.15143710537813603878\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1467527023 \tAcc: 0.9461596386 \tTPR:0.9544571393 \tFPR:0.0621331364 \tF1:0.9388234018 \t AUC:0.9461620014\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1411859013 \tAcc: 0.9476656627 \tTPR:0.9520800700 \tFPR:0.0540108371 \tF1:0.9395421732 \t AUC:0.9490346165\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1390832773 \tAcc: 0.9497155288 \tTPR:0.9502524043 \tFPR:0.0533685623 \tF1:0.9418001295 \t AUC:0.9484419210\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1331195375 \tAcc: 0.9510123829 \tTPR:0.9562028670 \tFPR:0.0494621382 \tF1:0.9341746254 \t AUC:0.9531033087\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1217448225 \tAcc: 0.9555722892 \tTPR:0.9587008029 \tFPR:0.0480185972 \tF1:0.9486803708 \t AUC:0.9553411029\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1966003219 \tAcc: 0.9356250000 \tTPR:0.9082815378 \tFPR:0.0374947811 \tF1:0.9306037072 \tAUC:0.9353933784 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.05771742208870943 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.15241261602226477412\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1274871453 \tAcc: 0.9532174556 \tTPR:0.9808193300 \tFPR:0.1384802389 \tF1:0.9691806721 \t AUC:0.9211410876\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1224845456 \tAcc: 0.9565458580 \tTPR:0.9823989920 \tFPR:0.1289275100 \tF1:0.9714927545 \t AUC:0.9267096268\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1156055197 \tAcc: 0.9583025148 \tTPR:0.9834594831 \tFPR:0.1286364851 \tF1:0.9726059511 \t AUC:0.9274114990\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1096840007 \tAcc: 0.9597818047 \tTPR:0.9832020631 \tFPR:0.1133725495 \tF1:0.9737193704 \t AUC:0.9349147568\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1098513778 \tAcc: 0.9599667160 \tTPR:0.9834240711 \tFPR:0.1202554617 \tF1:0.9738004584 \t AUC:0.9315597114\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1980833247 \tAcc: 0.9339583333 \tTPR:0.9543991065 \tFPR:0.0848465327 \tF1:0.9320244456 \tAUC:0.9347762869 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07297366309772324 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.22132149416130858510\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1684902834 \tAcc: 0.9320870734 \tTPR:0.9437698034 \tFPR:0.0770895196 \tF1:0.9271484006 \t AUC:0.9333401419\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1606569681 \tAcc: 0.9336173569 \tTPR:0.9456223182 \tFPR:0.0768517656 \tF1:0.9291883919 \t AUC:0.9343852763\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1553122542 \tAcc: 0.9366057145 \tTPR:0.9468951093 \tFPR:0.0724067888 \tF1:0.9317823158 \t AUC:0.9372441603\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1467398243 \tAcc: 0.9417603537 \tTPR:0.9518897484 \tFPR:0.0666699567 \tF1:0.9377479595 \t AUC:0.9426098958\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1438895696 \tAcc: 0.9435155972 \tTPR:0.9525074133 \tFPR:0.0648009038 \tF1:0.9397376509 \t AUC:0.9438532548\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2016360718 \tAcc: 0.9306250000 \tTPR:0.8986394578 \tFPR:0.0381128064 \tF1:0.9250293741 \tAUC:0.9302633257 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2091947457 \tAcc: 0.9292916667 \tTPR:0.9095732666 \tFPR:0.0511747574 \tF1:0.9246808762 \tAUC:0.9291992546\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 8:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07990350094344063 \tALA epochs: 4\n",
      "Client 5: Local Initial ALA epochs: 4 Loss: 0.18931229779762881460\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1152408716 \tAcc: 0.9525953390 \tTPR:0.8292548161 \tFPR:0.0257600260 \tF1:0.8191711648 \t AUC:0.9010177148\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.1080216311 \tAcc: 0.9552436441 \tTPR:0.8475908194 \tFPR:0.0237876842 \tF1:0.8238390992 \t AUC:0.9108098113\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.1036921889 \tAcc: 0.9563912429 \tTPR:0.8362545960 \tFPR:0.0225211887 \tF1:0.8367379134 \t AUC:0.9068667036\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0983478427 \tAcc: 0.9580155367 \tTPR:0.8514387997 \tFPR:0.0221518945 \tF1:0.8382548283 \t AUC:0.9140085757\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0953135532 \tAcc: 0.9604872881 \tTPR:0.8642997774 \tFPR:0.0215410929 \tF1:0.8537829786 \t AUC:0.9213793423\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.3335571661 \tAcc: 0.8970833333 \tTPR:0.8100207174 \tFPR:0.0199240695 \tF1:0.8824125340 \tAUC:0.8950483240 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08518573895081757 \tALA epochs: 2\n",
      "Client 2: Local Initial ALA epochs: 2 Loss: 0.30774190750989044441\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1094795974 \tAcc: 0.9599021084 \tTPR:0.9839660763 \tFPR:0.1432365827 \tF1:0.9748415380 \t AUC:0.9203647468\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.1011252976 \tAcc: 0.9637612952 \tTPR:0.9856829627 \tFPR:0.1308738868 \tF1:0.9773226025 \t AUC:0.9274045379\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0990721928 \tAcc: 0.9633847892 \tTPR:0.9854244006 \tFPR:0.1236275522 \tF1:0.9770060163 \t AUC:0.9308984242\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0943774230 \tAcc: 0.9647966867 \tTPR:0.9861275697 \tFPR:0.1221703439 \tF1:0.9778673104 \t AUC:0.9319576576\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0915584614 \tAcc: 0.9665850904 \tTPR:0.9884625329 \tFPR:0.1185534680 \tF1:0.9790297574 \t AUC:0.9349545325\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1768116065 \tAcc: 0.9389583333 \tTPR:0.9569718188 \tFPR:0.0805566180 \tF1:0.9393540650 \tAUC:0.9382076004 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0952139719667336 \tALA epochs: 2\n",
      "Client 3: Local Initial ALA epochs: 2 Loss: 0.21232958376640453935\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1461916444 \tAcc: 0.9451974565 \tTPR:0.9432804818 \tFPR:0.0551057555 \tF1:0.9342328952 \t AUC:0.9440873631\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1335620165 \tAcc: 0.9469126506 \tTPR:0.9450390741 \tFPR:0.0536594508 \tF1:0.9379168663 \t AUC:0.9456898116\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1297252732 \tAcc: 0.9487951807 \tTPR:0.9549846431 \tFPR:0.0535911710 \tF1:0.9416792043 \t AUC:0.9506967360\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1223276224 \tAcc: 0.9517653949 \tTPR:0.9525977643 \tFPR:0.0490931359 \tF1:0.9462966065 \t AUC:0.9517523142\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1179890857 \tAcc: 0.9527275770 \tTPR:0.9557291454 \tFPR:0.0517234116 \tF1:0.9424044818 \t AUC:0.9520028669\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1906916101 \tAcc: 0.9327083333 \tTPR:0.9014079274 \tFPR:0.0386312765 \tF1:0.9268380021 \tAUC:0.9313883255 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.06623567402988086 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.17926123074721544981\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0960487802 \tAcc: 0.9612573099 \tTPR:0.7995323958 \tFPR:0.0176035621 \tF1:0.7869988652 \t AUC:0.8873195513\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0917752560 \tAcc: 0.9609740497 \tTPR:0.7983825304 \tFPR:0.0177854726 \tF1:0.7868288565 \t AUC:0.8875739685\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0874057526 \tAcc: 0.9637701023 \tTPR:0.8101074445 \tFPR:0.0162733284 \tF1:0.7948558078 \t AUC:0.8946428957\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0856561591 \tAcc: 0.9649579678 \tTPR:0.8174376915 \tFPR:0.0165452709 \tF1:0.8082021472 \t AUC:0.8986777229\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0823785664 \tAcc: 0.9666027047 \tTPR:0.8216803583 \tFPR:0.0145417180 \tF1:0.8147013456 \t AUC:0.9018419316\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.3347147359 \tAcc: 0.8750000000 \tTPR:0.7611734157 \tFPR:0.0176323559 \tF1:0.8503345275 \tAUC:0.8717705299 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.0867490893051715 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.35575622097769782348\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1226513563 \tAcc: 0.9543269231 \tTPR:0.9780141884 \tFPR:0.1277857744 \tF1:0.9699895239 \t AUC:0.9251142070\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1149643909 \tAcc: 0.9577477811 \tTPR:0.9821047233 \tFPR:0.1259535911 \tF1:0.9721653482 \t AUC:0.9280755661\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1073459269 \tAcc: 0.9595968935 \tTPR:0.9815575154 \tFPR:0.1162727887 \tF1:0.9736927735 \t AUC:0.9326423634\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.1030978589 \tAcc: 0.9620007396 \tTPR:0.9843377669 \tFPR:0.1136404026 \tF1:0.9748453950 \t AUC:0.9353254444\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.1032936422 \tAcc: 0.9607063609 \tTPR:0.9845651072 \tFPR:0.1145570406 \tF1:0.9741479528 \t AUC:0.9350040333\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1988318153 \tAcc: 0.9339583333 \tTPR:0.9307752335 \tFPR:0.0615260776 \tF1:0.9306166392 \tAUC:0.9346245779 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2469213868 \tAcc: 0.9155416667 \tTPR:0.8720698226 \tFPR:0.0436540795 \tF1:0.9059111536 \tAUC:0.9142078715\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 9:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.05211923438763196 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.10390598769299685955\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1236881541 \tAcc: 0.9521837349 \tTPR:0.9516146200 \tFPR:0.0479816304 \tF1:0.9450549460 \t AUC:0.9518164948\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1189287042 \tAcc: 0.9531040830 \tTPR:0.9575108614 \tFPR:0.0482284592 \tF1:0.9449196255 \t AUC:0.9546412011\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1161276872 \tAcc: 0.9534805890 \tTPR:0.9581841734 \tFPR:0.0494482093 \tF1:0.9465399699 \t AUC:0.9543679820\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1103925153 \tAcc: 0.9559069612 \tTPR:0.9583773150 \tFPR:0.0449720465 \tF1:0.9483015718 \t AUC:0.9567026343\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1039409148 \tAcc: 0.9612198795 \tTPR:0.9616064777 \tFPR:0.0394252564 \tF1:0.9560528505 \t AUC:0.9610906106\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2306589416 \tAcc: 0.9260416667 \tTPR:0.8793349176 \tFPR:0.0304974953 \tF1:0.9180240072 \tAUC:0.9244187112 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.0406835530398248 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13773406353252737322\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1298442993 \tAcc: 0.9496192174 \tTPR:0.9733214797 \tFPR:0.0921489594 \tF1:0.9605292040 \t AUC:0.9405862602\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1236226905 \tAcc: 0.9520834722 \tTPR:0.9748666166 \tFPR:0.0896208392 \tF1:0.9623366890 \t AUC:0.9426228887\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1194125098 \tAcc: 0.9528271231 \tTPR:0.9743487224 \tFPR:0.0864925568 \tF1:0.9628343173 \t AUC:0.9439280828\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1175179363 \tAcc: 0.9545206472 \tTPR:0.9765192273 \tFPR:0.0852867188 \tF1:0.9643592581 \t AUC:0.9456162542\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1157441884 \tAcc: 0.9556434142 \tTPR:0.9767753709 \tFPR:0.0822132597 \tF1:0.9650670164 \t AUC:0.9472810556\tTrain cost: 0:02:03\n",
      "Client4 Test =>                 \tLoss: 0.2335653593 \tAcc: 0.9237500000 \tTPR:0.8909716159 \tFPR:0.0448087448 \tF1:0.9174996393 \tAUC:0.9230814355 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05198268770024626 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.16093224045131113153\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1592068968 \tAcc: 0.9366945876 \tTPR:0.9466499530 \tFPR:0.0733533682 \tF1:0.9316973804 \t AUC:0.9366482924\tTrain cost: 0:00:42\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1552859294 \tAcc: 0.9377805057 \tTPR:0.9484308250 \tFPR:0.0720162034 \tF1:0.9340107705 \t AUC:0.9382073108\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1443697170 \tAcc: 0.9431212229 \tTPR:0.9527093754 \tFPR:0.0667982002 \tF1:0.9389531811 \t AUC:0.9429555876\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1410978999 \tAcc: 0.9427185167 \tTPR:0.9504936315 \tFPR:0.0650937383 \tF1:0.9382268550 \t AUC:0.9426999466\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1379546226 \tAcc: 0.9447320476 \tTPR:0.9542610431 \tFPR:0.0637747314 \tF1:0.9410908976 \t AUC:0.9452431558\tTrain cost: 0:00:44\n",
      "Client6 Test =>                 \tLoss: 0.1870389217 \tAcc: 0.9395833333 \tTPR:0.9281256400 \tFPR:0.0496091798 \tF1:0.9360395593 \tAUC:0.9392582301 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0709070548177891 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.12713619542773813009\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1378208217 \tAcc: 0.9480406746 \tTPR:0.9749583018 \tFPR:0.1155135374 \tF1:0.9612228671 \t AUC:0.9297223822\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1258483214 \tAcc: 0.9501488095 \tTPR:0.9739953542 \tFPR:0.0998635624 \tF1:0.9628436716 \t AUC:0.9370658959\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1194402741 \tAcc: 0.9536210317 \tTPR:0.9778222329 \tFPR:0.0972202731 \tF1:0.9654509599 \t AUC:0.9403009799\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1168916258 \tAcc: 0.9532490079 \tTPR:0.9770174236 \tFPR:0.0912027651 \tF1:0.9647644473 \t AUC:0.9429073292\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1103789667 \tAcc: 0.9606894841 \tTPR:0.9842411651 \tFPR:0.0850655132 \tF1:0.9703498027 \t AUC:0.9495878260\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2194591562 \tAcc: 0.9297916667 \tTPR:0.9248552369 \tFPR:0.0678490657 \tF1:0.9267317682 \tAUC:0.9285030856 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.04393000624153906 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05988983572884039319\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0543424016 \tAcc: 0.9807291667 \tTPR:0.9926807476 \tFPR:0.1730158730 \tF1:0.9894182794 \t AUC:0.9096398254\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0550341886 \tAcc: 0.9812500000 \tTPR:0.9943726795 \tFPR:0.2021604938 \tF1:0.9898165430 \t AUC:0.8960828158\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0431189114 \tAcc: 0.9848958333 \tTPR:0.9956943286 \tFPR:0.1654545455 \tF1:0.9919011554 \t AUC:0.9157764519\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0384676724 \tAcc: 0.9859375000 \tTPR:0.9960960897 \tFPR:0.1304761905 \tF1:0.9922807335 \t AUC:0.9326324991\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0360827387 \tAcc: 0.9869791667 \tTPR:0.9943790082 \tFPR:0.1224242424 \tF1:0.9929256878 \t AUC:0.9357218833\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2581275991 \tAcc: 0.9308333333 \tTPR:0.9820604427 \tFPR:0.1186317158 \tF1:0.9330239130 \tAUC:0.9317143634 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2257699956 \tAcc: 0.9300000000 \tTPR:0.9210695706 \tFPR:0.0622792403 \tF1:0.9262637774 \tAUC:0.9293951652\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 10:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.05303878036391454 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10015385073016989936\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0575818017 \tAcc: 0.9833333333 \tTPR:0.9939749027 \tFPR:0.1789308176 \tF1:0.9910205562 \t AUC:0.9074189701\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0452828548 \tAcc: 0.9796875000 \tTPR:0.9938917886 \tFPR:0.1963636364 \tF1:0.9889200428 \t AUC:0.8984864301\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0422653727 \tAcc: 0.9861607143 \tTPR:0.9966796275 \tFPR:0.1003267974 \tF1:0.9923783828 \t AUC:0.9481898136\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0352316639 \tAcc: 0.9864583333 \tTPR:0.9965214485 \tFPR:0.1339622642 \tF1:0.9925103367 \t AUC:0.9310498765\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0330879761 \tAcc: 0.9899553571 \tTPR:0.9954168657 \tFPR:0.0580128205 \tF1:0.9944121111 \t AUC:0.9686499546\tTrain cost: 0:00:07\n",
      "Client9 Test =>                 \tLoss: 0.2597575720 \tAcc: 0.9345833333 \tTPR:0.9706651280 \tFPR:0.1046873415 \tF1:0.9364795338 \tAUC:0.9329888933 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07177338656510328 \tALA epochs: 5\n",
      "Client 0: Local Initial ALA epochs: 5 Loss: 0.16112576235085726561\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1629373824 \tAcc: 0.9464285714 \tTPR:0.9753527596 \tFPR:0.1556422744 \tF1:0.9660833577 \t AUC:0.9098552426\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1426177406 \tAcc: 0.9487920168 \tTPR:0.9712733720 \tFPR:0.1322991493 \tF1:0.9667431620 \t AUC:0.9194871114\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1425377806 \tAcc: 0.9568671218 \tTPR:0.9863409937 \tFPR:0.1447137188 \tF1:0.9710758641 \t AUC:0.9208136374\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1241471074 \tAcc: 0.9510241597 \tTPR:0.9811147847 \tFPR:0.1687074830 \tF1:0.9688665425 \t AUC:0.9062036508\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1201628502 \tAcc: 0.9546349790 \tTPR:0.9817591411 \tFPR:0.1423933210 \tF1:0.9708546241 \t AUC:0.9196829101\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1797562527 \tAcc: 0.9370833333 \tTPR:0.9444313955 \tFPR:0.0718738851 \tF1:0.9378816028 \tAUC:0.9362787552 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.041104591555147195 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.11137200882241352073\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1138508327 \tAcc: 0.9587647929 \tTPR:0.9838541676 \tFPR:0.1330290190 \tF1:0.9729839836 \t AUC:0.9254125743\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1106734006 \tAcc: 0.9590421598 \tTPR:0.9819626916 \tFPR:0.1137497517 \tF1:0.9731132359 \t AUC:0.9340797084\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.1038592303 \tAcc: 0.9629252959 \tTPR:0.9858015976 \tFPR:0.1160059854 \tF1:0.9758252330 \t AUC:0.9348767402\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0990778967 \tAcc: 0.9634800296 \tTPR:0.9841145974 \tFPR:0.1040297474 \tF1:0.9760773205 \t AUC:0.9400424250\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0996712411 \tAcc: 0.9628328402 \tTPR:0.9841740857 \tFPR:0.1133337652 \tF1:0.9758361115 \t AUC:0.9354201603\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1995952074 \tAcc: 0.9339583333 \tTPR:0.9305238073 \tFPR:0.0636163494 \tF1:0.9299992430 \tAUC:0.9334537290 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08073054398733717 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.12697139545343816280\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1232330123 \tAcc: 0.9523809524 \tTPR:0.9767989920 \tFPR:0.0994105101 \tF1:0.9644244999 \t AUC:0.9386942410\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1196602233 \tAcc: 0.9549851190 \tTPR:0.9778266526 \tFPR:0.0903113421 \tF1:0.9666717962 \t AUC:0.9437576552\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1130971305 \tAcc: 0.9580853175 \tTPR:0.9786868836 \tFPR:0.0823891318 \tF1:0.9683758837 \t AUC:0.9481488759\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1047926742 \tAcc: 0.9614335317 \tTPR:0.9786872907 \tFPR:0.0763844951 \tF1:0.9710820931 \t AUC:0.9511513978\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0965029182 \tAcc: 0.9657738095 \tTPR:0.9839796386 \tFPR:0.0750440367 \tF1:0.9743865646 \t AUC:0.9544678010\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2348145094 \tAcc: 0.9266666667 \tTPR:0.9225285085 \tFPR:0.0680833518 \tF1:0.9245172734 \tAUC:0.9272225784 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08358542535923491 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.13157715192064642351\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1193596098 \tAcc: 0.9533957972 \tTPR:0.9742691160 \tFPR:0.0854919246 \tF1:0.9632156778 \t AUC:0.9443885957\tTrain cost: 0:02:04\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1141564137 \tAcc: 0.9558600520 \tTPR:0.9762161559 \tFPR:0.0816657416 \tF1:0.9652712530 \t AUC:0.9472752071\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1113211016 \tAcc: 0.9568349220 \tTPR:0.9772403349 \tFPR:0.0785302741 \tF1:0.9661295053 \t AUC:0.9493550304\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1092121424 \tAcc: 0.9581889081 \tTPR:0.9779136309 \tFPR:0.0777404031 \tF1:0.9670839479 \t AUC:0.9500866139\tTrain cost: 0:02:03\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1063184549 \tAcc: 0.9579597720 \tTPR:0.9771001716 \tFPR:0.0768940914 \tF1:0.9668104786 \t AUC:0.9501030401\tTrain cost: 0:02:04\n",
      "Client4 Test =>                 \tLoss: 0.2318162449 \tAcc: 0.9245833333 \tTPR:0.9069213224 \tFPR:0.0578612035 \tF1:0.9215162447 \tAUC:0.9245300594 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2211479573 \tAcc: 0.9313750000 \tTPR:0.9350140323 \tFPR:0.0732244263 \tF1:0.9300787795 \tAUC:0.9308948030\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 11:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08688730599014685 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.27148955586765494141\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.1007004064 \tAcc: 0.9596574859 \tTPR:0.8665559958 \tFPR:0.0229987857 \tF1:0.8468734047 \t AUC:0.9213995028\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0959674657 \tAcc: 0.9598340395 \tTPR:0.8561270493 \tFPR:0.0212015550 \tF1:0.8451654533 \t AUC:0.9170540172\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0894712316 \tAcc: 0.9643714689 \tTPR:0.8704956139 \tFPR:0.0192250626 \tF1:0.8636993276 \t AUC:0.9256352757\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0833892702 \tAcc: 0.9656603107 \tTPR:0.8776768900 \tFPR:0.0188970693 \tF1:0.8698459406 \t AUC:0.9290424015\tTrain cost: 0:00:45\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0811027799 \tAcc: 0.9667196328 \tTPR:0.8845761897 \tFPR:0.0176661054 \tF1:0.8754310028 \t AUC:0.9331271336\tTrain cost: 0:00:44\n",
      "Client5 Test =>                 \tLoss: 0.3679947475 \tAcc: 0.8935416667 \tTPR:0.7999847036 \tFPR:0.0143260535 \tF1:0.8756549489 \tAUC:0.8928293250 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07247879539236682 \tALA epochs: 3\n",
      "Client 7: Local Initial ALA epochs: 3 Loss: 0.27670572993035119636\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1300032592 \tAcc: 0.9508928571 \tTPR:0.9729173017 \tFPR:0.0914440601 \tF1:0.9631087200 \t AUC:0.9407366208\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1184224531 \tAcc: 0.9562251984 \tTPR:0.9765337667 \tFPR:0.0866730025 \tF1:0.9674008562 \t AUC:0.9449303821\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1109165185 \tAcc: 0.9580853175 \tTPR:0.9775726342 \tFPR:0.0836434773 \tF1:0.9686882349 \t AUC:0.9469645785\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1049152845 \tAcc: 0.9605654762 \tTPR:0.9792339107 \tFPR:0.0789689030 \tF1:0.9710162710 \t AUC:0.9501325038\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.1075104226 \tAcc: 0.9598214286 \tTPR:0.9794089000 \tFPR:0.0877655083 \tF1:0.9696531622 \t AUC:0.9458216958\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2070428958 \tAcc: 0.9310416667 \tTPR:0.9280656816 \tFPR:0.0648126476 \tF1:0.9290288982 \tAUC:0.9316265170 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.06133398768758653 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.14989125099964439869\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1232695777 \tAcc: 0.9503012048 \tTPR:0.9531972824 \tFPR:0.0501856437 \tF1:0.9438128305 \t AUC:0.9515058194\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1114603480 \tAcc: 0.9563253012 \tTPR:0.9580632932 \tFPR:0.0455961683 \tF1:0.9484970724 \t AUC:0.9562335625\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1087990419 \tAcc: 0.9563253012 \tTPR:0.9617770459 \tFPR:0.0467943333 \tF1:0.9504552082 \t AUC:0.9574913563\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.1084277347 \tAcc: 0.9591281794 \tTPR:0.9672858996 \tFPR:0.0477822409 \tF1:0.9529632910 \t AUC:0.9597518294\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.1033027922 \tAcc: 0.9557396252 \tTPR:0.9583692569 \tFPR:0.0458492248 \tF1:0.9491785525 \t AUC:0.9562600161\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2402673646 \tAcc: 0.9229166667 \tTPR:0.8698573140 \tFPR:0.0258595469 \tF1:0.9143615527 \tAUC:0.9219988835 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07205946428152867 \tALA epochs: 5\n",
      "Client 1: Local Initial ALA epochs: 5 Loss: 0.13070422270992659852\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0904747155 \tAcc: 0.9632035819 \tTPR:0.8096235960 \tFPR:0.0178953480 \tF1:0.7969085285 \t AUC:0.8932914699\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0845820084 \tAcc: 0.9648209064 \tTPR:0.8140664160 \tFPR:0.0154559739 \tF1:0.8022167774 \t AUC:0.8965050165\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0801224466 \tAcc: 0.9682017544 \tTPR:0.8318707649 \tFPR:0.0143141232 \tF1:0.8251980638 \t AUC:0.9066357444\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0774453599 \tAcc: 0.9671509503 \tTPR:0.8233709273 \tFPR:0.0150981217 \tF1:0.8142897133 \t AUC:0.9024253909\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0748534929 \tAcc: 0.9701206140 \tTPR:0.8354967279 \tFPR:0.0136151456 \tF1:0.8303865322 \t AUC:0.9090965841\tTrain cost: 0:01:12\n",
      "Client1 Test =>                 \tLoss: 0.4641411000 \tAcc: 0.8591666667 \tTPR:0.7247515523 \tFPR:0.0110783092 \tF1:0.8305209762 \tAUC:0.8568366216 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08157630014105535 \tALA epochs: 11\n",
      "Client 2: Local Initial ALA epochs: 11 Loss: 0.43120759832300759040\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.1022126578 \tAcc: 0.9638554217 \tTPR:0.9848341310 \tFPR:0.1288919078 \tF1:0.9772583604 \t AUC:0.9279725029\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0916685017 \tAcc: 0.9672439759 \tTPR:0.9873564337 \tFPR:0.1119808237 \tF1:0.9794484030 \t AUC:0.9376878050\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0878118111 \tAcc: 0.9680911145 \tTPR:0.9881848305 \tFPR:0.1186280838 \tF1:0.9799201732 \t AUC:0.9347783734\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0860035200 \tAcc: 0.9687500000 \tTPR:0.9889591860 \tFPR:0.1150425271 \tF1:0.9803887164 \t AUC:0.9369416515\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0801805046 \tAcc: 0.9697853916 \tTPR:0.9883328460 \tFPR:0.1083098925 \tF1:0.9809886284 \t AUC:0.9399938526\tTrain cost: 0:00:37\n",
      "Client2 Test =>                 \tLoss: 0.1785516493 \tAcc: 0.9416666667 \tTPR:0.9743780261 \tFPR:0.0930739119 \tF1:0.9433169847 \tAUC:0.9406520571 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2915995514 \tAcc: 0.9096666667 \tTPR:0.8594074555 \tFPR:0.0418300938 \tF1:0.8985766722 \tAUC:0.9087886808\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 12:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07497245355256263 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.13544575312270729084\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0829903742 \tAcc: 0.9671052632 \tTPR:0.8281599938 \tFPR:0.0156382827 \tF1:0.8174025214 \t AUC:0.9047265698\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0793421231 \tAcc: 0.9679733187 \tTPR:0.8244331895 \tFPR:0.0144219814 \tF1:0.8168766171 \t AUC:0.9033048823\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0742694052 \tAcc: 0.9700749269 \tTPR:0.8466583124 \tFPR:0.0146039253 \tF1:0.8353875552 \t AUC:0.9145417674\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0729878232 \tAcc: 0.9708059211 \tTPR:0.8469609419 \tFPR:0.0134330937 \tF1:0.8381089594 \t AUC:0.9142209791\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0702365002 \tAcc: 0.9720303363 \tTPR:0.8589320524 \tFPR:0.0130682935 \tF1:0.8410779295 \t AUC:0.9201448227\tTrain cost: 0:01:22\n",
      "Client1 Test =>                 \tLoss: 0.4847032481 \tAcc: 0.8612500000 \tTPR:0.7295822416 \tFPR:0.0127457121 \tF1:0.8325376731 \tAUC:0.8584182648 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.05910055454340503 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.08189769628058586604\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0879768787 \tAcc: 0.9641066384 \tTPR:0.8715483120 \tFPR:0.0198633221 \tF1:0.8619981512 \t AUC:0.9256605520\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0797520942 \tAcc: 0.9666137006 \tTPR:0.8847891750 \tFPR:0.0184511028 \tF1:0.8756178544 \t AUC:0.9330058480\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0776033538 \tAcc: 0.9698446328 \tTPR:0.8878262039 \tFPR:0.0150440517 \tF1:0.8863818318 \t AUC:0.9360724005\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0738595404 \tAcc: 0.9691031073 \tTPR:0.8963674273 \tFPR:0.0172098117 \tF1:0.8841854751 \t AUC:0.9389866217\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0685090447 \tAcc: 0.9721398305 \tTPR:0.9109137880 \tFPR:0.0158530485 \tF1:0.9004001452 \t AUC:0.9470213057\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.5227394547 \tAcc: 0.8631250000 \tTPR:0.7353511942 \tFPR:0.0104305974 \tF1:0.8366472329 \tAUC:0.8624602984 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.1632372909368343 \tALA epochs: 11\n",
      "Client 6: Local Initial ALA epochs: 11 Loss: 0.32837965766599108708\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1533897762 \tAcc: 0.9369362113 \tTPR:0.9466145182 \tFPR:0.0718830119 \tF1:0.9324899522 \t AUC:0.9373657532\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1424107137 \tAcc: 0.9419853137 \tTPR:0.9482711892 \tFPR:0.0642534225 \tF1:0.9377888711 \t AUC:0.9420088833\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1374472972 \tAcc: 0.9465039549 \tTPR:0.9557904076 \tFPR:0.0623446618 \tF1:0.9424935488 \t AUC:0.9467228729\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1294084576 \tAcc: 0.9475593228 \tTPR:0.9531555377 \tFPR:0.0581104087 \tF1:0.9437044572 \t AUC:0.9475225645\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1306640430 \tAcc: 0.9477120734 \tTPR:0.9531032997 \tFPR:0.0583622268 \tF1:0.9427423895 \t AUC:0.9473705364\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2184327532 \tAcc: 0.9310416667 \tTPR:0.8958315567 \tFPR:0.0323947769 \tF1:0.9258128104 \tAUC:0.9317183899 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.041577607623045035 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.12897931578666416153\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1135594761 \tAcc: 0.9553439349 \tTPR:0.9815095069 \tFPR:0.1342450859 \tF1:0.9706826312 \t AUC:0.9236322105\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.1048717970 \tAcc: 0.9615384615 \tTPR:0.9840466029 \tFPR:0.1119114777 \tF1:0.9747425513 \t AUC:0.9360675626\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0964165382 \tAcc: 0.9636649408 \tTPR:0.9835929004 \tFPR:0.1036983562 \tF1:0.9762665827 \t AUC:0.9399472721\tTrain cost: 0:00:36\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0943110790 \tAcc: 0.9656065089 \tTPR:0.9862506580 \tFPR:0.1013103309 \tF1:0.9775933674 \t AUC:0.9424701636\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0899068660 \tAcc: 0.9672707101 \tTPR:0.9858655650 \tFPR:0.0966002922 \tF1:0.9784752930 \t AUC:0.9446116654\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1985287694 \tAcc: 0.9352083333 \tTPR:0.9523581504 \tFPR:0.0827639728 \tF1:0.9339480980 \tAUC:0.9347970888 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07159645842358353 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09196264049828503651\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0947903205 \tAcc: 0.9643260542 \tTPR:0.9861838114 \tFPR:0.1227855478 \tF1:0.9774490992 \t AUC:0.9316991318\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0885995153 \tAcc: 0.9663027108 \tTPR:0.9862495776 \tFPR:0.1119906445 \tF1:0.9788228435 \t AUC:0.9371086956\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0817080072 \tAcc: 0.9704442771 \tTPR:0.9891766463 \tFPR:0.1066031820 \tF1:0.9812636989 \t AUC:0.9412703827\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0784599376 \tAcc: 0.9706325301 \tTPR:0.9882468357 \tFPR:0.1025607742 \tF1:0.9814772961 \t AUC:0.9428252767\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0749393501 \tAcc: 0.9729856928 \tTPR:0.9898479666 \tFPR:0.0985124225 \tF1:0.9829726154 \t AUC:0.9456524367\tTrain cost: 0:00:35\n",
      "Client2 Test =>                 \tLoss: 0.1797006779 \tAcc: 0.9427083333 \tTPR:0.9603748662 \tFPR:0.0742861952 \tF1:0.9418593467 \tAUC:0.9430443355 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3208209807 \tAcc: 0.9066666667 \tTPR:0.8546996018 \tFPR:0.0425242509 \tF1:0.8941610322 \tAUC:0.9060876755\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 13:  =============\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07159453511055754 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.14728938991373236034\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0452026173 \tAcc: 0.9828125000 \tTPR:0.9927265383 \tFPR:0.1278735632 \tF1:0.9906141146 \t AUC:0.9325704796\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0398332143 \tAcc: 0.9857886905 \tTPR:0.9966807476 \tFPR:0.1558479532 \tF1:0.9923085477 \t AUC:0.9203290484\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0318528061 \tAcc: 0.9869791667 \tTPR:0.9955864375 \tFPR:0.1125000000 \tF1:0.9928950088 \t AUC:0.9416646094\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0311693721 \tAcc: 0.9890625000 \tTPR:0.9961648746 \tFPR:0.0841346154 \tF1:0.9939833452 \t AUC:0.9557201199\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0253309967 \tAcc: 0.9927083333 \tTPR:0.9983074472 \tFPR:0.0730994152 \tF1:0.9960165524 \t AUC:0.9625594752\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2596000122 \tAcc: 0.9350000000 \tTPR:0.9721013625 \tFPR:0.1030123898 \tF1:0.9364109101 \tAUC:0.9345444863 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.23449215780211388 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.54715799743720849868\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0843092790 \tAcc: 0.9670197740 \tTPR:0.8891357466 \tFPR:0.0197837629 \tF1:0.8766798477 \t AUC:0.9345189603\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0712986729 \tAcc: 0.9698093220 \tTPR:0.9002443727 \tFPR:0.0173204281 \tF1:0.8902639236 \t AUC:0.9411785756\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0664008970 \tAcc: 0.9751412429 \tTPR:0.9191681749 \tFPR:0.0147756521 \tF1:0.9070926210 \t AUC:0.9520817687\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0632823562 \tAcc: 0.9750882768 \tTPR:0.9198386203 \tFPR:0.0148532430 \tF1:0.9082633121 \t AUC:0.9523791456\tTrain cost: 0:00:40\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0582464138 \tAcc: 0.9765183616 \tTPR:0.9147854656 \tFPR:0.0120630386 \tF1:0.9148079418 \t AUC:0.9509970489\tTrain cost: 0:00:40\n",
      "Client5 Test =>                 \tLoss: 0.4558374477 \tAcc: 0.8935416667 \tTPR:0.7989781248 \tFPR:0.0124014506 \tF1:0.8786261055 \tAUC:0.8932883371 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.08574404247397499 \tALA epochs: 6\n",
      "Client 2: Local Initial ALA epochs: 6 Loss: 0.35089943162871128912\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0973164134 \tAcc: 0.9639495482 \tTPR:0.9860737374 \tFPR:0.1245234183 \tF1:0.9773579794 \t AUC:0.9307751595\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0846250824 \tAcc: 0.9686558735 \tTPR:0.9889420424 \tFPR:0.1141468471 \tF1:0.9804170054 \t AUC:0.9373975976\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0817411247 \tAcc: 0.9697853916 \tTPR:0.9889541110 \tFPR:0.1096586145 \tF1:0.9809098001 \t AUC:0.9396477482\tTrain cost: 0:00:36\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0802323685 \tAcc: 0.9700677711 \tTPR:0.9893975540 \tFPR:0.1101645334 \tF1:0.9811714833 \t AUC:0.9396004945\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0725291545 \tAcc: 0.9728915663 \tTPR:0.9906009059 \tFPR:0.0984493167 \tF1:0.9829340118 \t AUC:0.9460757946\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1766533449 \tAcc: 0.9420833333 \tTPR:0.9447966645 \tFPR:0.0596684925 \tF1:0.9405185172 \tAUC:0.9425640860 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07706652435728388 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.18010146915912628174\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1647319254 \tAcc: 0.9420955882 \tTPR:0.9747314722 \tFPR:0.1825435477 \tF1:0.9627738535 \t AUC:0.8960939623\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1393583242 \tAcc: 0.9510241597 \tTPR:0.9858410618 \tFPR:0.1796737213 \tF1:0.9687157796 \t AUC:0.9039788751\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1242950448 \tAcc: 0.9575892857 \tTPR:0.9827442002 \tFPR:0.1262471655 \tF1:0.9723917246 \t AUC:0.9282485174\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1363616827 \tAcc: 0.9486607143 \tTPR:0.9836593117 \tFPR:0.1748041641 \tF1:0.9667471680 \t AUC:0.9044275738\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.1145057560 \tAcc: 0.9600840336 \tTPR:0.9861309649 \tFPR:0.1176445578 \tF1:0.9736333876 \t AUC:0.9342432035\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1747947622 \tAcc: 0.9362500000 \tTPR:0.9232900137 \tFPR:0.0522174361 \tF1:0.9343163951 \tAUC:0.9355362888 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.07696971403924854 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.10262198909185826778\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1147369171 \tAcc: 0.9521329365 \tTPR:0.9750085580 \tFPR:0.0897577349 \tF1:0.9637298538 \t AUC:0.9426254116\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1050198250 \tAcc: 0.9583333333 \tTPR:0.9781137303 \tFPR:0.0808088059 \tF1:0.9684853465 \t AUC:0.9486524622\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1033116089 \tAcc: 0.9623015873 \tTPR:0.9763086359 \tFPR:0.0632208215 \tF1:0.9715731413 \t AUC:0.9565439072\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0975322086 \tAcc: 0.9621775794 \tTPR:0.9827156512 \tFPR:0.0791159733 \tF1:0.9715032520 \t AUC:0.9517998390\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0922757651 \tAcc: 0.9619295635 \tTPR:0.9800402344 \tFPR:0.0717500899 \tF1:0.9713660409 \t AUC:0.9541450722\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2200597886 \tAcc: 0.9277083333 \tTPR:0.9040872449 \tFPR:0.0500644367 \tF1:0.9235543959 \tAUC:0.9270114041 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2573890711 \tAcc: 0.9269166667 \tTPR:0.9086506821 \tFPR:0.0554728411 \tF1:0.9226852648 \tAUC:0.9265889205\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 14:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07379082194686767 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.15383040872342013117\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1392762530 \tAcc: 0.9434350560 \tTPR:0.9493829977 \tFPR:0.0614085062 \tF1:0.9385768162 \t AUC:0.9439872457\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1308535448 \tAcc: 0.9448209207 \tTPR:0.9488143672 \tFPR:0.0600593506 \tF1:0.9403358845 \t AUC:0.9443775083\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1256250008 \tAcc: 0.9515141753 \tTPR:0.9601778887 \tFPR:0.0574355033 \tF1:0.9483476930 \t AUC:0.9513711927\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1229576312 \tAcc: 0.9514975116 \tTPR:0.9587667805 \tFPR:0.0567382853 \tF1:0.9481962710 \t AUC:0.9510142476\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1215740747 \tAcc: 0.9499588962 \tTPR:0.9566686580 \tFPR:0.0545160394 \tF1:0.9462489047 \t AUC:0.9510763093\tTrain cost: 0:00:41\n",
      "Client6 Test =>                 \tLoss: 0.2196821609 \tAcc: 0.9337500000 \tTPR:0.8961083815 \tFPR:0.0318632088 \tF1:0.9274672663 \tAUC:0.9321225864 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.07546669502769884 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11903756208983914955\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0720002351 \tAcc: 0.9707274011 \tTPR:0.9077369743 \tFPR:0.0172049873 \tF1:0.8959275484 \t AUC:0.9451353093\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0647046760 \tAcc: 0.9724929379 \tTPR:0.9057479557 \tFPR:0.0156823117 \tF1:0.8943392169 \t AUC:0.9446300355\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0568890053 \tAcc: 0.9762535311 \tTPR:0.9217961496 \tFPR:0.0139860010 \tF1:0.9166852294 \t AUC:0.9537943039\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0551966477 \tAcc: 0.9770833333 \tTPR:0.9198327606 \tFPR:0.0131086990 \tF1:0.9136386301 \t AUC:0.9533620308\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0506420282 \tAcc: 0.9796080508 \tTPR:0.9244774215 \tFPR:0.0116239414 \tF1:0.9140302509 \t AUC:0.9562121873\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.5811392870 \tAcc: 0.8762500000 \tTPR:0.7619828188 \tFPR:0.0114929373 \tF1:0.8546319474 \tAUC:0.8752449408 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.2804022898396347 \tALA epochs: 11\n",
      "Client 7: Local Initial ALA epochs: 11 Loss: 0.45362494968470523649\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1409823625 \tAcc: 0.9468005952 \tTPR:0.9686364654 \tFPR:0.1020541958 \tF1:0.9600367238 \t AUC:0.9332911348\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1120100078 \tAcc: 0.9582093254 \tTPR:0.9774270733 \tFPR:0.0851927999 \tF1:0.9688593043 \t AUC:0.9461171367\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.1037447206 \tAcc: 0.9605654762 \tTPR:0.9791678655 \tFPR:0.0760218765 \tF1:0.9702834883 \t AUC:0.9515729945\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.1018465024 \tAcc: 0.9629216270 \tTPR:0.9789119842 \tFPR:0.0701520371 \tF1:0.9726253167 \t AUC:0.9543799735\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0921381661 \tAcc: 0.9642857143 \tTPR:0.9805646444 \tFPR:0.0690904334 \tF1:0.9736183206 \t AUC:0.9557371055\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2167182546 \tAcc: 0.9285416667 \tTPR:0.9145179670 \tFPR:0.0549515502 \tF1:0.9247786447 \tAUC:0.9297832084 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.08459941227806589 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.12167699976176347965\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1199680078 \tAcc: 0.9530041828 \tTPR:0.9748672109 \tFPR:0.0863578549 \tF1:0.9631070795 \t AUC:0.9442546780\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1124558628 \tAcc: 0.9560100320 \tTPR:0.9759713088 \tFPR:0.0799246083 \tF1:0.9653681652 \t AUC:0.9480233502\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1083501587 \tAcc: 0.9579597720 \tTPR:0.9772947651 \tFPR:0.0776595466 \tF1:0.9668601425 \t AUC:0.9498176093\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.1052524169 \tAcc: 0.9593137582 \tTPR:0.9788145692 \tFPR:0.0762567910 \tF1:0.9681625529 \t AUC:0.9512788891\tTrain cost: 0:02:10\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.1002053366 \tAcc: 0.9619134115 \tTPR:0.9806417174 \tFPR:0.0718144848 \tF1:0.9701645523 \t AUC:0.9544136163\tTrain cost: 0:02:04\n",
      "Client4 Test =>                 \tLoss: 0.2094245956 \tAcc: 0.9343750000 \tTPR:0.9265170328 \tFPR:0.0591460995 \tF1:0.9299927508 \tAUC:0.9336854667 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.18788344635280796 \tALA epochs: 11\n",
      "Client 1: Local Initial ALA epochs: 11 Loss: 0.21701486334472366857\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0787195324 \tAcc: 0.9682474415 \tTPR:0.8409907872 \tFPR:0.0159280224 \tF1:0.8234711076 \t AUC:0.9109910547\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0711409245 \tAcc: 0.9711714181 \tTPR:0.8526762508 \tFPR:0.0138116849 \tF1:0.8458319296 \t AUC:0.9177806714\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0672368220 \tAcc: 0.9725877193 \tTPR:0.8621959993 \tFPR:0.0133017898 \tF1:0.8500770700 \t AUC:0.9217245333\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0650038429 \tAcc: 0.9732273392 \tTPR:0.8566067948 \tFPR:0.0124867978 \tF1:0.8435227760 \t AUC:0.9206709436\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0614041388 \tAcc: 0.9740405702 \tTPR:0.8673007751 \tFPR:0.0123683132 \tF1:0.8544152653 \t AUC:0.9260798211\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.4643267155 \tAcc: 0.8716666667 \tTPR:0.7542097911 \tFPR:0.0120425711 \tF1:0.8485564315 \tAUC:0.8710836100 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3382582027 \tAcc: 0.9089166667 \tTPR:0.8506671982 \tFPR:0.0338992734 \tF1:0.8970854081 \tAUC:0.9083839624\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 15:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09288247228055396 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.14743199697088288369\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.1091713909 \tAcc: 0.9583243068 \tTPR:0.9768947235 \tFPR:0.0758920415 \tF1:0.9671732709 \t AUC:0.9505013410\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.1055486937 \tAcc: 0.9591637782 \tTPR:0.9785740426 \tFPR:0.0770041699 \tF1:0.9680394816 \t AUC:0.9507849364\tTrain cost: 0:01:52\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.1014063260 \tAcc: 0.9607885615 \tTPR:0.9784829939 \tFPR:0.0700369036 \tF1:0.9690296825 \t AUC:0.9542230452\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0969710365 \tAcc: 0.9630090988 \tTPR:0.9807757569 \tFPR:0.0687133981 \tF1:0.9709802376 \t AUC:0.9560311794\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0939257536 \tAcc: 0.9637819124 \tTPR:0.9804646144 \tFPR:0.0665641840 \tF1:0.9713129706 \t AUC:0.9569502152\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.1904643039 \tAcc: 0.9370833333 \tTPR:0.9373661878 \tFPR:0.0651108697 \tF1:0.9336661473 \tAUC:0.9361276590 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.025044318774297844 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05661066858605905139\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0446679181 \tAcc: 0.9822916667 \tTPR:0.9954750870 \tFPR:0.2115646259 \tF1:0.9902560116 \t AUC:0.8914473322\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0338798611 \tAcc: 0.9880208333 \tTPR:0.9956081989 \tFPR:0.1228070175 \tF1:0.9935922088 \t AUC:0.9365591398\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0258609588 \tAcc: 0.9890625000 \tTPR:0.9971775794 \tFPR:0.1057575758 \tF1:0.9939982484 \t AUC:0.9458658009\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0221025691 \tAcc: 0.9932291667 \tTPR:0.9966271165 \tFPR:0.0393081761 \tF1:0.9962543969 \t AUC:0.9784367326\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0330341372 \tAcc: 0.9875000000 \tTPR:0.9961589266 \tFPR:0.1123456790 \tF1:0.9932486251 \t AUC:0.9422719345\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2293385928 \tAcc: 0.9397916667 \tTPR:0.9735182874 \tFPR:0.0930630384 \tF1:0.9404940664 \tAUC:0.9402276245 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08864896221742843 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.16720837663160637021\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1241921705 \tAcc: 0.9532490079 \tTPR:0.9761401993 \tFPR:0.0945640717 \tF1:0.9651863042 \t AUC:0.9407880638\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.1042234278 \tAcc: 0.9590773810 \tTPR:0.9818520814 \tFPR:0.0909290445 \tF1:0.9695491088 \t AUC:0.9454615184\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0982757169 \tAcc: 0.9635416667 \tTPR:0.9847098794 \tFPR:0.0854870658 \tF1:0.9739957002 \t AUC:0.9496114068\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0939040817 \tAcc: 0.9662698413 \tTPR:0.9841943307 \tFPR:0.0672749374 \tF1:0.9744527789 \t AUC:0.9584596967\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0902260573 \tAcc: 0.9655257937 \tTPR:0.9802781012 \tFPR:0.0691913245 \tF1:0.9739517774 \t AUC:0.9555433883\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2128788506 \tAcc: 0.9339583333 \tTPR:0.9243877758 \tFPR:0.0570851392 \tF1:0.9313372493 \tAUC:0.9336513183 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06561993907995854 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.15016738349547634201\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1271662373 \tAcc: 0.9502893930 \tTPR:0.9585224342 \tFPR:0.0564644327 \tF1:0.9459672835 \t AUC:0.9510290007\tTrain cost: 0:00:44\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1195754494 \tAcc: 0.9506198898 \tTPR:0.9556326375 \tFPR:0.0540226199 \tF1:0.9459920372 \t AUC:0.9508050088\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1146501299 \tAcc: 0.9540914948 \tTPR:0.9596882815 \tFPR:0.0507561024 \tF1:0.9510139239 \t AUC:0.9544660895\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1088520694 \tAcc: 0.9576186456 \tTPR:0.9637524217 \tFPR:0.0490949576 \tF1:0.9537702277 \t AUC:0.9573287320\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.1021624517 \tAcc: 0.9596405084 \tTPR:0.9656693534 \tFPR:0.0458333953 \tF1:0.9557117522 \t AUC:0.9599179791\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2197308321 \tAcc: 0.9385416667 \tTPR:0.9168865434 \tFPR:0.0386819231 \tF1:0.9343618595 \tAUC:0.9391023101 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09896023969921103 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.15931337956777391618\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0765421139 \tAcc: 0.9685215643 \tTPR:0.8467476562 \tFPR:0.0155564403 \tF1:0.8255706084 \t AUC:0.9134062887\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0680062386 \tAcc: 0.9723958333 \tTPR:0.8526408614 \tFPR:0.0123762176 \tF1:0.8402991936 \t AUC:0.9177985799\tTrain cost: 0:01:07\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0657844420 \tAcc: 0.9727704678 \tTPR:0.8609646486 \tFPR:0.0132110877 \tF1:0.8488530676 \t AUC:0.9213488650\tTrain cost: 0:01:06\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0619397585 \tAcc: 0.9743695175 \tTPR:0.8594054581 \tFPR:0.0119501120 \tF1:0.8477861768 \t AUC:0.9220439061\tTrain cost: 0:01:07\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0589711576 \tAcc: 0.9753746345 \tTPR:0.8719831987 \tFPR:0.0116258665 \tF1:0.8632205817 \t AUC:0.9289385630\tTrain cost: 0:01:08\n",
      "Client1 Test =>                 \tLoss: 0.4114297828 \tAcc: 0.8795833333 \tTPR:0.7718833880 \tFPR:0.0146445047 \tF1:0.8585876263 \tAUC:0.8786194417 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2527684724 \tAcc: 0.9257916667 \tTPR:0.9048084365 \tFPR:0.0537170950 \tF1:0.9196893898 \tAUC:0.9255456707\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 16:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.03776233246058743 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.08558101234534247481\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0840274083 \tAcc: 0.9687500000 \tTPR:0.9875559637 \tFPR:0.1060107647 \tF1:0.9802691548 \t AUC:0.9407725995\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0768643677 \tAcc: 0.9726091867 \tTPR:0.9893316914 \tFPR:0.0944503298 \tF1:0.9827464288 \t AUC:0.9474245655\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0741371398 \tAcc: 0.9732680723 \tTPR:0.9903280913 \tFPR:0.0955557077 \tF1:0.9832855749 \t AUC:0.9473861918\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0687186205 \tAcc: 0.9755271084 \tTPR:0.9896579508 \tFPR:0.0867202911 \tF1:0.9846272193 \t AUC:0.9514688299\tTrain cost: 0:00:32\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0657277618 \tAcc: 0.9759036145 \tTPR:0.9905460422 \tFPR:0.0859700958 \tF1:0.9847258331 \t AUC:0.9522879732\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1983593176 \tAcc: 0.9445833333 \tTPR:0.9659714117 \tFPR:0.0770994847 \tF1:0.9444883233 \tAUC:0.9444359635 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09749074702993454 \tALA epochs: 4\n",
      "Client 4: Local Initial ALA epochs: 4 Loss: 0.13549565969024907064\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0989348759 \tAcc: 0.9624945841 \tTPR:0.9786883418 \tFPR:0.0664797204 \tF1:0.9703462946 \t AUC:0.9561043107\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0902628248 \tAcc: 0.9666377816 \tTPR:0.9827339772 \tFPR:0.0622520990 \tF1:0.9735753252 \t AUC:0.9602409391\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0905620815 \tAcc: 0.9646609619 \tTPR:0.9813510612 \tFPR:0.0656926801 \tF1:0.9722509732 \t AUC:0.9578291905\tTrain cost: 0:01:52\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0854450478 \tAcc: 0.9667731802 \tTPR:0.9817244146 \tFPR:0.0599467926 \tF1:0.9737723818 \t AUC:0.9608888110\tTrain cost: 0:01:51\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0807195324 \tAcc: 0.9681959072 \tTPR:0.9833246395 \tFPR:0.0591608153 \tF1:0.9748583884 \t AUC:0.9620819121\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2278392198 \tAcc: 0.9312500000 \tTPR:0.9089495920 \tFPR:0.0490708124 \tF1:0.9260251154 \tAUC:0.9299393898 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07919569261965599 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.11089206556789577007\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1136299705 \tAcc: 0.9585843373 \tTPR:0.9637876868 \tFPR:0.0461729063 \tF1:0.9519023479 \t AUC:0.9588073903\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1093347063 \tAcc: 0.9562834672 \tTPR:0.9622894526 \tFPR:0.0490743941 \tF1:0.9494269407 \t AUC:0.9566075293\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.1001549209 \tAcc: 0.9623493976 \tTPR:0.9709516147 \tFPR:0.0441325503 \tF1:0.9558409889 \t AUC:0.9634095322\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0914756875 \tAcc: 0.9662817938 \tTPR:0.9742934585 \tFPR:0.0398714928 \tF1:0.9628662451 \t AUC:0.9672109828\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0842218168 \tAcc: 0.9674113119 \tTPR:0.9764644190 \tFPR:0.0398162011 \tF1:0.9642724835 \t AUC:0.9683241089\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2301034985 \tAcc: 0.9350000000 \tTPR:0.8994647978 \tFPR:0.0303122719 \tF1:0.9291323184 \tAUC:0.9345762630 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0549158666274244 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.11516289002528147523\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0772033847 \tAcc: 0.9698093220 \tTPR:0.9049186375 \tFPR:0.0182108846 \tF1:0.8900652539 \t AUC:0.9432192003\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0662361775 \tAcc: 0.9738700565 \tTPR:0.9070901713 \tFPR:0.0144236318 \tF1:0.8989116829 \t AUC:0.9459362192\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0576973253 \tAcc: 0.9766949153 \tTPR:0.9185991269 \tFPR:0.0127007903 \tF1:0.9096372644 \t AUC:0.9527179158\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0556715672 \tAcc: 0.9770833333 \tTPR:0.9303479712 \tFPR:0.0137484040 \tF1:0.9198550625 \t AUC:0.9579017720\tTrain cost: 0:00:38\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0452235642 \tAcc: 0.9822563559 \tTPR:0.9403763217 \tFPR:0.0106776197 \tF1:0.9271800364 \t AUC:0.9646799656\tTrain cost: 0:00:39\n",
      "Client5 Test =>                 \tLoss: 0.3928344779 \tAcc: 0.9131250000 \tTPR:0.8410143240 \tFPR:0.0174082912 \tF1:0.9024651864 \tAUC:0.9118030164 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09936704447704713 \tALA epochs: 6\n",
      "Client 6: Local Initial ALA epochs: 6 Loss: 0.21219502216319904853\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1252242374 \tAcc: 0.9498061456 \tTPR:0.9571517123 \tFPR:0.0574953711 \tF1:0.9450352131 \t AUC:0.9498281706\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1165376831 \tAcc: 0.9536082474 \tTPR:0.9612327739 \tFPR:0.0521476500 \tF1:0.9492458700 \t AUC:0.9545425619\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1091819002 \tAcc: 0.9570548569 \tTPR:0.9637553319 \tFPR:0.0503085263 \tF1:0.9533355525 \t AUC:0.9567234028\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1044035343 \tAcc: 0.9585212629 \tTPR:0.9650422487 \tFPR:0.0484464391 \tF1:0.9552139781 \t AUC:0.9582979048\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0984530620 \tAcc: 0.9607680857 \tTPR:0.9668827329 \tFPR:0.0462233329 \tF1:0.9577030233 \t AUC:0.9603297000\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2204847076 \tAcc: 0.9325000000 \tTPR:0.8983171330 \tFPR:0.0322739311 \tF1:0.9272350660 \tAUC:0.9330216009 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2539242443 \tAcc: 0.9312916667 \tTPR:0.9027434517 \tFPR:0.0412329582 \tF1:0.9258692019 \tAUC:0.9307552467\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 17:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.0416890186896471 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.10345353488145130061\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0591026436 \tAcc: 0.9761652542 \tTPR:0.9163144765 \tFPR:0.0133304160 \tF1:0.9093992208 \t AUC:0.9510138272\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0524847883 \tAcc: 0.9783192090 \tTPR:0.9233039638 \tFPR:0.0123765138 \tF1:0.9138373549 \t AUC:0.9553550904\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0473953168 \tAcc: 0.9811087571 \tTPR:0.9345574388 \tFPR:0.0104898383 \tF1:0.9259741226 \t AUC:0.9616598428\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0426407651 \tAcc: 0.9833509887 \tTPR:0.9504865035 \tFPR:0.0102887176 \tF1:0.9380514920 \t AUC:0.9699582296\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0432270352 \tAcc: 0.9822563559 \tTPR:0.9461370158 \tFPR:0.0113287942 \tF1:0.9349961449 \t AUC:0.9673278177\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4665488567 \tAcc: 0.8950000000 \tTPR:0.8022275231 \tFPR:0.0136905616 \tF1:0.8787171279 \tAUC:0.8942684808 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.21805958885905785 \tALA epochs: 11\n",
      "Client 8: Local Initial ALA epochs: 11 Loss: 0.41066376117451097727\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.1101692433 \tAcc: 0.9607988166 \tTPR:0.9832388611 \tFPR:0.1144952516 \tF1:0.9743023564 \t AUC:0.9343718048\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0998610295 \tAcc: 0.9644970414 \tTPR:0.9860033435 \tFPR:0.1093535792 \tF1:0.9767199065 \t AUC:0.9383041156\tTrain cost: 0:00:37\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0898748528 \tAcc: 0.9660687870 \tTPR:0.9861694360 \tFPR:0.0993100701 \tF1:0.9778794628 \t AUC:0.9434091628\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0845383585 \tAcc: 0.9681028107 \tTPR:0.9865594796 \tFPR:0.0902976104 \tF1:0.9788116378 \t AUC:0.9481309346\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0802537677 \tAcc: 0.9678254438 \tTPR:0.9864676382 \tFPR:0.0963950902 \tF1:0.9789388168 \t AUC:0.9450161963\tTrain cost: 0:00:37\n",
      "Client8 Test =>                 \tLoss: 0.2002865236 \tAcc: 0.9366666667 \tTPR:0.9322504645 \tFPR:0.0590629336 \tF1:0.9333487601 \tAUC:0.9365937654 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.08963377707341955 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.19537286363286993085\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0778359595 \tAcc: 0.9689692982 \tTPR:0.8352716281 \tFPR:0.0148393683 \tF1:0.8281324512 \t AUC:0.9074789515\tTrain cost: 0:01:16\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0681428332 \tAcc: 0.9711257310 \tTPR:0.8584057471 \tFPR:0.0139594522 \tF1:0.8460182675 \t AUC:0.9204187229\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0625491801 \tAcc: 0.9745522661 \tTPR:0.8649389678 \tFPR:0.0114625462 \tF1:0.8537363587 \t AUC:0.9253271254\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0576804993 \tAcc: 0.9769279971 \tTPR:0.8851033835 \tFPR:0.0109748799 \tF1:0.8754472854 \t AUC:0.9358638394\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0554761041 \tAcc: 0.9773848684 \tTPR:0.8885872088 \tFPR:0.0112491084 \tF1:0.8737546531 \t AUC:0.9369911467\tTrain cost: 0:01:08\n",
      "Client1 Test =>                 \tLoss: 0.3398271798 \tAcc: 0.9027083333 \tTPR:0.8243354626 \tFPR:0.0222617475 \tF1:0.8895729537 \tAUC:0.9010368576 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08189745879352048 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.21448986139148473740\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1237914835 \tAcc: 0.9520089286 \tTPR:0.9728629644 \tFPR:0.0912019858 \tF1:0.9637526181 \t AUC:0.9408304893\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0986673849 \tAcc: 0.9624255952 \tTPR:0.9823259491 \tFPR:0.0771524111 \tF1:0.9723955314 \t AUC:0.9525867690\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0848932325 \tAcc: 0.9691220238 \tTPR:0.9843439782 \tFPR:0.0675437492 \tF1:0.9774468087 \t AUC:0.9584001145\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0859754808 \tAcc: 0.9706101190 \tTPR:0.9857145346 \tFPR:0.0573833292 \tF1:0.9774234237 \t AUC:0.9641656027\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0770459116 \tAcc: 0.9694940476 \tTPR:0.9820291242 \tFPR:0.0580498468 \tF1:0.9766960531 \t AUC:0.9619896387\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2235362970 \tAcc: 0.9360416667 \tTPR:0.9349713288 \tFPR:0.0612908271 \tF1:0.9332110801 \tAUC:0.9368402508 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.06784287901674273 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09887483452489091718\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0794538133 \tAcc: 0.9716679217 \tTPR:0.9893827752 \tFPR:0.1007993011 \tF1:0.9822482318 \t AUC:0.9442917371\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0680921877 \tAcc: 0.9742093373 \tTPR:0.9890917088 \tFPR:0.0891552474 \tF1:0.9837699233 \t AUC:0.9499682307\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0643198215 \tAcc: 0.9757153614 \tTPR:0.9903864718 \tFPR:0.0828238278 \tF1:0.9847397394 \t AUC:0.9537813220\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0565219610 \tAcc: 0.9770331325 \tTPR:0.9898096097 \tFPR:0.0774229619 \tF1:0.9855513602 \t AUC:0.9561933239\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0553920689 \tAcc: 0.9801393072 \tTPR:0.9925753873 \tFPR:0.0733654314 \tF1:0.9876071929 \t AUC:0.9596049779\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1815615861 \tAcc: 0.9418750000 \tTPR:0.9422249510 \tFPR:0.0568055440 \tF1:0.9405799367 \tAUC:0.9427097035 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2823520887 \tAcc: 0.9224583333 \tTPR:0.8872019460 \tFPR:0.0426223227 \tF1:0.9150859717 \tAUC:0.9222898116\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 18:  =============\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07395729668420417 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.13512100528742215788\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0671641456 \tAcc: 0.9742093373 \tTPR:0.9892861976 \tFPR:0.0924881344 \tF1:0.9838177172 \t AUC:0.9483990316\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0595294184 \tAcc: 0.9788215361 \tTPR:0.9920605640 \tFPR:0.0773672529 \tF1:0.9866180044 \t AUC:0.9573466555\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0577950360 \tAcc: 0.9779743976 \tTPR:0.9914062406 \tFPR:0.0797750566 \tF1:0.9860904568 \t AUC:0.9557895503\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0519681744 \tAcc: 0.9797628012 \tTPR:0.9921015202 \tFPR:0.0709961391 \tF1:0.9873535876 \t AUC:0.9605526905\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0493338158 \tAcc: 0.9820218373 \tTPR:0.9918846554 \tFPR:0.0580323793 \tF1:0.9885932313 \t AUC:0.9669261381\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.1861397814 \tAcc: 0.9460416667 \tTPR:0.9550671367 \tFPR:0.0621787728 \tF1:0.9451716995 \tAUC:0.9464441819 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09560669004409826 \tALA epochs: 2\n",
      "Client 6: Local Initial ALA epochs: 2 Loss: 0.22002661184335201017\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1227989554 \tAcc: 0.9523834652 \tTPR:0.9604365786 \tFPR:0.0543966201 \tF1:0.9489876862 \t AUC:0.9530199793\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1137377308 \tAcc: 0.9548885754 \tTPR:0.9623613375 \tFPR:0.0520437897 \tF1:0.9509915190 \t AUC:0.9551587739\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.1019942454 \tAcc: 0.9593988846 \tTPR:0.9666757088 \tFPR:0.0467063954 \tF1:0.9569616907 \t AUC:0.9599846567\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.1036414650 \tAcc: 0.9579408105 \tTPR:0.9657097882 \tFPR:0.0489575093 \tF1:0.9548899830 \t AUC:0.9583761394\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0907209397 \tAcc: 0.9643757776 \tTPR:0.9705043855 \tFPR:0.0407630164 \tF1:0.9613596233 \t AUC:0.9648706845\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2635195331 \tAcc: 0.9333333333 \tTPR:0.8924348120 \tFPR:0.0244261212 \tF1:0.9279668734 \tAUC:0.9340043454 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.052111408687225996 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.11714428786174668762\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0661837715 \tAcc: 0.9738212719 \tTPR:0.8661020185 \tFPR:0.0130661217 \tF1:0.8483825578 \t AUC:0.9247085162\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0582209437 \tAcc: 0.9758315058 \tTPR:0.8702369349 \tFPR:0.0115300901 \tF1:0.8657725900 \t AUC:0.9283907884\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0563564121 \tAcc: 0.9766081871 \tTPR:0.8833170890 \tFPR:0.0118501429 \tF1:0.8728458678 \t AUC:0.9342465094\tTrain cost: 0:01:08\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0529243142 \tAcc: 0.9778874269 \tTPR:0.8915970482 \tFPR:0.0113799836 \tF1:0.8770090225 \t AUC:0.9385599187\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0492294391 \tAcc: 0.9803088450 \tTPR:0.9038307574 \tFPR:0.0100184631 \tF1:0.8952193632 \t AUC:0.9461927255\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.5168928420 \tAcc: 0.8566666667 \tTPR:0.7173625927 \tFPR:0.0100043653 \tF1:0.8253697850 \tAUC:0.8536791137 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.0958883412329234 \tALA epochs: 6\n",
      "Client 3: Local Initial ALA epochs: 6 Loss: 0.25694627962366212159\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1253335061 \tAcc: 0.9529367470 \tTPR:0.9488255364 \tFPR:0.0402692989 \tF1:0.9471259989 \t AUC:0.9542781188\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.1017583066 \tAcc: 0.9564926372 \tTPR:0.9556347757 \tFPR:0.0425874262 \tF1:0.9469092880 \t AUC:0.9565236748\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0921347673 \tAcc: 0.9670348059 \tTPR:0.9695551525 \tFPR:0.0369380728 \tF1:0.9631831744 \t AUC:0.9663085399\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0916325654 \tAcc: 0.9638554217 \tTPR:0.9661214470 \tFPR:0.0385177546 \tF1:0.9586689786 \t AUC:0.9638018462\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0802961867 \tAcc: 0.9672439759 \tTPR:0.9718964878 \tFPR:0.0364935210 \tF1:0.9616265423 \t AUC:0.9677014834\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2286671959 \tAcc: 0.9316666667 \tTPR:0.8887068803 \tFPR:0.0277613263 \tF1:0.9240786091 \tAUC:0.9304727770 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08770311630315876 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.21351894939487631175\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0516792683 \tAcc: 0.9821428571 \tTPR:0.9931114382 \tFPR:0.1527272727 \tF1:0.9902377515 \t AUC:0.9201630572\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0346788074 \tAcc: 0.9875000000 \tTPR:0.9961228360 \tFPR:0.1098214286 \tF1:0.9932311152 \t AUC:0.9432912514\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0316800428 \tAcc: 0.9868303571 \tTPR:0.9948784805 \tFPR:0.1443396226 \tF1:0.9929120246 \t AUC:0.9256050698\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0253834766 \tAcc: 0.9927083333 \tTPR:0.9982950192 \tFPR:0.0800595238 \tF1:0.9960196156 \t AUC:0.9590568555\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0207607424 \tAcc: 0.9920386905 \tTPR:0.9982744937 \tFPR:0.0803571429 \tF1:0.9956552983 \t AUC:0.9588970502\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3343264892 \tAcc: 0.9231250000 \tTPR:0.9835235073 \tFPR:0.1381175288 \tF1:0.9257970669 \tAUC:0.9227029892 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3059091683 \tAcc: 0.9181666667 \tTPR:0.8874189858 \tFPR:0.0524976229 \tF1:0.9096768068 \tAUC:0.9174606814\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 19:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.0795260338165225 \tALA epochs: 2\n",
      "Client 1: Local Initial ALA epochs: 2 Loss: 0.13412543079004321522\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0523525914 \tAcc: 0.9787554825 \tTPR:0.8940290541 \tFPR:0.0105978998 \tF1:0.8782179758 \t AUC:0.9402835373\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0497014383 \tAcc: 0.9795778509 \tTPR:0.9038359788 \tFPR:0.0104581555 \tF1:0.8874790337 \t AUC:0.9454634331\tTrain cost: 0:01:06\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0476441306 \tAcc: 0.9799890351 \tTPR:0.9034553978 \tFPR:0.0102411194 \tF1:0.8941056862 \t AUC:0.9453768107\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0449793539 \tAcc: 0.9814510234 \tTPR:0.9019928293 \tFPR:0.0091540696 \tF1:0.8939377673 \t AUC:0.9453954244\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0406643921 \tAcc: 0.9838724415 \tTPR:0.9181089297 \tFPR:0.0080116551 \tF1:0.9108279880 \t AUC:0.9538153381\tTrain cost: 0:01:08\n",
      "Client1 Test =>                 \tLoss: 0.4502803894 \tAcc: 0.8845833333 \tTPR:0.7799074017 \tFPR:0.0145282613 \tF1:0.8631636650 \tAUC:0.8826895702 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.09116058822988418 \tALA epochs: 5\n",
      "Client 7: Local Initial ALA epochs: 5 Loss: 0.30429049907252192497\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.1128021498 \tAcc: 0.9583333333 \tTPR:0.9740917898 \tFPR:0.0750488599 \tF1:0.9686872211 \t AUC:0.9495214650\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0954656614 \tAcc: 0.9654017857 \tTPR:0.9825474209 \tFPR:0.0653903072 \tF1:0.9734199516 \t AUC:0.9585785568\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0838886686 \tAcc: 0.9713541667 \tTPR:0.9866067935 \tFPR:0.0590912394 \tF1:0.9785876150 \t AUC:0.9637577770\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0813367953 \tAcc: 0.9702380952 \tTPR:0.9833521149 \tFPR:0.0561883057 \tF1:0.9773602546 \t AUC:0.9635819046\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0808081447 \tAcc: 0.9697420635 \tTPR:0.9833986491 \tFPR:0.0573487077 \tF1:0.9770116695 \t AUC:0.9630249707\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2126049470 \tAcc: 0.9385416667 \tTPR:0.9361386395 \tFPR:0.0603252015 \tF1:0.9354684318 \tAUC:0.9379067190 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.045525011383552624 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.10738171133866060425\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0966595327 \tAcc: 0.9636649408 \tTPR:0.9840059974 \tFPR:0.1003826375 \tF1:0.9760028207 \t AUC:0.9417879500\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0879696152 \tAcc: 0.9668084320 \tTPR:0.9858681610 \tFPR:0.0934802581 \tF1:0.9779878188 \t AUC:0.9461729843\tTrain cost: 0:00:32\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0827030779 \tAcc: 0.9688424556 \tTPR:0.9869432172 \tFPR:0.0929220384 \tF1:0.9795369290 \t AUC:0.9469912173\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0782341890 \tAcc: 0.9706915680 \tTPR:0.9886991621 \tFPR:0.0886208212 \tF1:0.9806203120 \t AUC:0.9500224036\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0716515479 \tAcc: 0.9733727811 \tTPR:0.9886506259 \tFPR:0.0780461790 \tF1:0.9824980516 \t AUC:0.9552853846\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1903565017 \tAcc: 0.9408333333 \tTPR:0.9659097827 \tFPR:0.0829286372 \tF1:0.9397675308 \tAUC:0.9414905727 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.042098426809787266 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.12036968313623219728\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1086075292 \tAcc: 0.9576221553 \tTPR:0.9643676526 \tFPR:0.0476908511 \tF1:0.9511106425 \t AUC:0.9583384008\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0958982182 \tAcc: 0.9642319277 \tTPR:0.9673135388 \tFPR:0.0392593868 \tF1:0.9563686152 \t AUC:0.9640270760\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0854874929 \tAcc: 0.9668674699 \tTPR:0.9710980799 \tFPR:0.0376076854 \tF1:0.9605400443 \t AUC:0.9667451973\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0796643100 \tAcc: 0.9700468541 \tTPR:0.9735679012 \tFPR:0.0322602343 \tF1:0.9644620985 \t AUC:0.9706538334\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0780544930 \tAcc: 0.9702560241 \tTPR:0.9731198906 \tFPR:0.0313297047 \tF1:0.9645396206 \t AUC:0.9708950930\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2421690497 \tAcc: 0.9347916667 \tTPR:0.8970480960 \tFPR:0.0271591790 \tF1:0.9297160735 \tAUC:0.9349444585 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08156628459161007 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.21889198124408720814\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1571907568 \tAcc: 0.9420955882 \tTPR:0.9660997648 \tFPR:0.1492090214 \tF1:0.9628545632 \t AUC:0.9089069142\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1255162833 \tAcc: 0.9533876050 \tTPR:0.9900177534 \tFPR:0.1587094453 \tF1:0.9695864834 \t AUC:0.9156541540\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1231265757 \tAcc: 0.9588366597 \tTPR:0.9793035067 \tFPR:0.1251417234 \tF1:0.9740204206 \t AUC:0.9270808916\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.1123297771 \tAcc: 0.9564732143 \tTPR:0.9894062974 \tFPR:0.1635031635 \tF1:0.9723065527 \t AUC:0.9129515670\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0944742226 \tAcc: 0.9633009454 \tTPR:0.9838976090 \tFPR:0.0977607710 \tF1:0.9765637660 \t AUC:0.9430684190\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1745706180 \tAcc: 0.9389583333 \tTPR:0.9742936683 \tFPR:0.0993455868 \tF1:0.9403824372 \tAUC:0.9374740407 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2539963012 \tAcc: 0.9275416667 \tTPR:0.9106595176 \tFPR:0.0568573731 \tF1:0.9216996277 \tAUC:0.9269010722\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 20:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.05915045234948777 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.12189194274667118634\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0582171782 \tAcc: 0.9761122881 \tTPR:0.9157918980 \tFPR:0.0140674583 \tF1:0.9095947948 \t AUC:0.9507429449\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0527832536 \tAcc: 0.9793432203 \tTPR:0.9358050847 \tFPR:0.0122466678 \tF1:0.9285981437 \t AUC:0.9616882808\tTrain cost: 0:00:34\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0433903053 \tAcc: 0.9823446328 \tTPR:0.9384887006 \tFPR:0.0105664927 \tF1:0.9297353662 \t AUC:0.9637863559\tTrain cost: 0:00:40\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0391172266 \tAcc: 0.9849046610 \tTPR:0.9545085643 \tFPR:0.0097865183 \tF1:0.9486775920 \t AUC:0.9722317859\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0377176578 \tAcc: 0.9837570621 \tTPR:0.9433996951 \tFPR:0.0095506817 \tF1:0.9374694957 \t AUC:0.9669245067\tTrain cost: 0:00:34\n",
      "Client5 Test =>                 \tLoss: 0.3802881188 \tAcc: 0.9127083333 \tTPR:0.8441759094 \tFPR:0.0187487985 \tF1:0.9028362791 \tAUC:0.9127135555 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.13550954440751367 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.34707267230207267117\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1675419802 \tAcc: 0.9478072479 \tTPR:0.9678829372 \tFPR:0.1329059829 \tF1:0.9669652563 \t AUC:0.9174884772\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1239454659 \tAcc: 0.9521402311 \tTPR:0.9797752942 \tFPR:0.1564342404 \tF1:0.9697543791 \t AUC:0.9116705269\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.1125573668 \tAcc: 0.9556197479 \tTPR:0.9781250047 \tFPR:0.1376017831 \tF1:0.9723224768 \t AUC:0.9202616108\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0953061238 \tAcc: 0.9666491597 \tTPR:0.9900511698 \tFPR:0.1101757370 \tF1:0.9786413418 \t AUC:0.9399377164\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0979165472 \tAcc: 0.9587053571 \tTPR:0.9814611355 \tFPR:0.1250000000 \tF1:0.9737026913 \t AUC:0.9282305677\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1769123812 \tAcc: 0.9356250000 \tTPR:0.9525384959 \tFPR:0.0840941983 \tF1:0.9359480866 \tAUC:0.9342221488 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.07821229605060283 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10706558213992552198\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0448680200 \tAcc: 0.9817708333 \tTPR:0.9945062084 \tFPR:0.1812121212 \tF1:0.9901845928 \t AUC:0.9069655076\tTrain cost: 0:00:07\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0313329107 \tAcc: 0.9901041667 \tTPR:0.9959055329 \tFPR:0.0696969697 \tF1:0.9943981828 \t AUC:0.9629181695\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0291748233 \tAcc: 0.9906250000 \tTPR:0.9977956989 \tFPR:0.1193452381 \tF1:0.9949646519 \t AUC:0.9391465054\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0237995486 \tAcc: 0.9932291667 \tTPR:0.9972401434 \tFPR:0.0575757576 \tF1:0.9963225768 \t AUC:0.9697067449\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0192676582 \tAcc: 0.9927083333 \tTPR:0.9988697318 \tFPR:0.1148484848 \tF1:0.9960555487 \t AUC:0.9419592476\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3037469967 \tAcc: 0.9325000000 \tTPR:0.9770789527 \tFPR:0.1137398036 \tF1:0.9351293786 \tAUC:0.9316695745 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09737999594997124 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09767584025305978135\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0660330811 \tAcc: 0.9768448795 \tTPR:0.9903025153 \tFPR:0.0833279003 \tF1:0.9855328296 \t AUC:0.9534873075\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0543999138 \tAcc: 0.9807040663 \tTPR:0.9922716314 \tFPR:0.0678886739 \tF1:0.9878253158 \t AUC:0.9621798044\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0507191546 \tAcc: 0.9823042169 \tTPR:0.9937270779 \tFPR:0.0638636798 \tF1:0.9888221281 \t AUC:0.9649316990\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0450983624 \tAcc: 0.9825865964 \tTPR:0.9929997772 \tFPR:0.0617003004 \tF1:0.9889870067 \t AUC:0.9656863695\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0429982802 \tAcc: 0.9835278614 \tTPR:0.9927173304 \tFPR:0.0525008375 \tF1:0.9895899886 \t AUC:0.9701082464\tTrain cost: 0:00:34\n",
      "Client2 Test =>                 \tLoss: 0.2243887607 \tAcc: 0.9435416667 \tTPR:0.9632454344 \tFPR:0.0779736240 \tF1:0.9443741824 \tAUC:0.9426359052 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09293368860137592 \tALA epochs: 2\n",
      "Client 4: Local Initial ALA epochs: 2 Loss: 0.13108871091440643664\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0994752069 \tAcc: 0.9613718171 \tTPR:0.9779958329 \tFPR:0.0691503078 \tF1:0.9694483521 \t AUC:0.9544227625\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0876040221 \tAcc: 0.9659066291 \tTPR:0.9822234774 \tFPR:0.0639548650 \tF1:0.9733106994 \t AUC:0.9591343062\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0842805000 \tAcc: 0.9668690008 \tTPR:0.9820581563 \tFPR:0.0599908234 \tF1:0.9738782553 \t AUC:0.9610336665\tTrain cost: 0:01:59\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0786410170 \tAcc: 0.9698061092 \tTPR:0.9845426966 \tFPR:0.0571151202 \tF1:0.9761701656 \t AUC:0.9637137882\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0757426543 \tAcc: 0.9706455806 \tTPR:0.9846230825 \tFPR:0.0542962788 \tF1:0.9769048698 \t AUC:0.9651634019\tTrain cost: 0:01:58\n",
      "Client4 Test =>                 \tLoss: 0.2048942579 \tAcc: 0.9393750000 \tTPR:0.9544919040 \tFPR:0.0757380327 \tF1:0.9382036895 \tAUC:0.9393769357 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2580461031 \tAcc: 0.9327500000 \tTPR:0.9383061393 \tFPR:0.0740588914 \tF1:0.9312983232 \tAUC:0.9321236239\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 21:  =============\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.08375428844544595 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.11556638102047145367\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0998576316 \tAcc: 0.9634789157 \tTPR:0.9641902628 \tFPR:0.0375016466 \tF1:0.9560924613 \t AUC:0.9633443081\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0817326754 \tAcc: 0.9728915663 \tTPR:0.9771688436 \tFPR:0.0304611035 \tF1:0.9688117131 \t AUC:0.9733538701\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0765156082 \tAcc: 0.9721385542 \tTPR:0.9742340454 \tFPR:0.0305857534 \tF1:0.9680376796 \t AUC:0.9718241460\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0730197694 \tAcc: 0.9740210843 \tTPR:0.9811392937 \tFPR:0.0330403113 \tF1:0.9708181980 \t AUC:0.9740494912\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0756400357 \tAcc: 0.9725150602 \tTPR:0.9782812136 \tFPR:0.0332485823 \tF1:0.9683852379 \t AUC:0.9725163157\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.1776075148 \tAcc: 0.9477083333 \tTPR:0.9396967463 \tFPR:0.0436509244 \tF1:0.9454212378 \tAUC:0.9480229109 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.09296088754448523 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.10325257641009309706\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0325233206 \tAcc: 0.9885416667 \tTPR:0.9948343888 \tFPR:0.1000000000 \tF1:0.9937308550 \t AUC:0.9471823939\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0261656640 \tAcc: 0.9901041667 \tTPR:0.9967168382 \tFPR:0.0875000000 \tF1:0.9945976844 \t AUC:0.9547701812\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0236038452 \tAcc: 0.9921875000 \tTPR:0.9977177022 \tFPR:0.0621794872 \tF1:0.9956810367 \t AUC:0.9675935461\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0218098121 \tAcc: 0.9921875000 \tTPR:0.9966065911 \tFPR:0.0773809524 \tF1:0.9957762168 \t AUC:0.9594916262\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0146040435 \tAcc: 0.9958333333 \tTPR:0.9988300493 \tFPR:0.0439393939 \tF1:0.9976978570 \t AUC:0.9773921481\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.2926571867 \tAcc: 0.9350000000 \tTPR:0.9858619522 \tFPR:0.1153900695 \tF1:0.9379219126 \tAUC:0.9352359414 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.34069305215836204 \tALA epochs: 11\n",
      "Client 5: Local Initial ALA epochs: 11 Loss: 0.69106970264443334795\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0528563327 \tAcc: 0.9789371469 \tTPR:0.9399647198 \tFPR:0.0137251089 \tF1:0.9286741447 \t AUC:0.9628632445\tTrain cost: 0:00:39\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0335487544 \tAcc: 0.9867584746 \tTPR:0.9634817709 \tFPR:0.0084165171 \tF1:0.9522397518 \t AUC:0.9773765661\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0311035645 \tAcc: 0.9869350282 \tTPR:0.9577089499 \tFPR:0.0084539612 \tF1:0.9498862487 \t AUC:0.9745675920\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0287819965 \tAcc: 0.9876412429 \tTPR:0.9587413685 \tFPR:0.0071173337 \tF1:0.9558741333 \t AUC:0.9756948054\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0283230494 \tAcc: 0.9881709040 \tTPR:0.9626814962 \tFPR:0.0077002395 \tF1:0.9536747371 \t AUC:0.9774906283\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4002852854 \tAcc: 0.9168750000 \tTPR:0.8546334974 \tFPR:0.0225930013 \tF1:0.9075998676 \tAUC:0.9160202480 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09953982183662563 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.21145228724684808630\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1174409906 \tAcc: 0.9535832519 \tTPR:0.9603267735 \tFPR:0.0517447431 \tF1:0.9507004626 \t AUC:0.9542910152\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1044831596 \tAcc: 0.9596238446 \tTPR:0.9665812077 \tFPR:0.0464829349 \tF1:0.9565783590 \t AUC:0.9600491364\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0953173506 \tAcc: 0.9620400818 \tTPR:0.9699105541 \tFPR:0.0444964034 \tF1:0.9595709089 \t AUC:0.9627070753\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0914259126 \tAcc: 0.9634259465 \tTPR:0.9686946164 \tFPR:0.0416431778 \tF1:0.9601856259 \t AUC:0.9635257193\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0881661944 \tAcc: 0.9667281372 \tTPR:0.9720163763 \tFPR:0.0385622145 \tF1:0.9638849510 \t AUC:0.9667270809\tTrain cost: 0:00:42\n",
      "Client6 Test =>                 \tLoss: 0.2071024334 \tAcc: 0.9427083333 \tTPR:0.9215334455 \tFPR:0.0372689583 \tF1:0.9382526542 \tAUC:0.9421322436 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09600785371430728 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.09911445440096861015\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0930779091 \tAcc: 0.9638360719 \tTPR:0.9808631898 \tFPR:0.0665569892 \tF1:0.9715605446 \t AUC:0.9571531003\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0843336580 \tAcc: 0.9676001533 \tTPR:0.9823145123 \tFPR:0.0589110469 \tF1:0.9743273203 \t AUC:0.9617017327\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0809618302 \tAcc: 0.9686416811 \tTPR:0.9838108316 \tFPR:0.0586665474 \tF1:0.9754368280 \t AUC:0.9625721421\tTrain cost: 0:02:01\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0747434913 \tAcc: 0.9710121984 \tTPR:0.9833478526 \tFPR:0.0516609547 \tF1:0.9770663462 \t AUC:0.9658434489\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0728041530 \tAcc: 0.9720141481 \tTPR:0.9844154952 \tFPR:0.0495836773 \tF1:0.9776038931 \t AUC:0.9674159090\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.2074482098 \tAcc: 0.9379166667 \tTPR:0.9443601272 \tFPR:0.0671355077 \tF1:0.9372531991 \tAUC:0.9386123098 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2570201260 \tAcc: 0.9360416667 \tTPR:0.9292171537 \tFPR:0.0572076922 \tF1:0.9332897742 \tAUC:0.9360047307\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 22:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.08019349592961487 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.11732917261542752385\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0881933420 \tAcc: 0.9672619048 \tTPR:0.9841003916 \tFPR:0.0673724735 \tF1:0.9747268886 \t AUC:0.9583639591\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0824579254 \tAcc: 0.9683779762 \tTPR:0.9851091828 \tFPR:0.0679894510 \tF1:0.9758416387 \t AUC:0.9585598659\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0696730516 \tAcc: 0.9748263889 \tTPR:0.9903734664 \tFPR:0.0554564483 \tF1:0.9813076384 \t AUC:0.9674585091\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0663423066 \tAcc: 0.9758184524 \tTPR:0.9870536313 \tFPR:0.0468294767 \tF1:0.9816045682 \t AUC:0.9701120773\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0574963645 \tAcc: 0.9773065476 \tTPR:0.9870484906 \tFPR:0.0442442809 \tF1:0.9832611940 \t AUC:0.9714021049\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2529696342 \tAcc: 0.9314583333 \tTPR:0.9303550515 \tFPR:0.0680419315 \tF1:0.9295951948 \tAUC:0.9311565600 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.06948382075438128 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.14797292942689224682\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1315666582 \tAcc: 0.9567358193 \tTPR:0.9792595911 \tFPR:0.1382253659 \tF1:0.9726437039 \t AUC:0.9205171126\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1057635753 \tAcc: 0.9575892857 \tTPR:0.9858282194 \tFPR:0.1505886970 \tF1:0.9730269186 \t AUC:0.9176197612\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0988130134 \tAcc: 0.9655330882 \tTPR:0.9839551659 \tFPR:0.1016749124 \tF1:0.9782165025 \t AUC:0.9411401268\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0964526089 \tAcc: 0.9642857143 \tTPR:0.9881322533 \tFPR:0.1126146671 \tF1:0.9773027235 \t AUC:0.9377587931\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0799243392 \tAcc: 0.9776785714 \tTPR:0.9916992267 \tFPR:0.0695745723 \tF1:0.9857419795 \t AUC:0.9610623272\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1687702082 \tAcc: 0.9437500000 \tTPR:0.9530559773 \tFPR:0.0662531617 \tF1:0.9441788826 \tAUC:0.9434014078 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.07789978205853393 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.09717272827401757240\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.0758897509 \tAcc: 0.9736445783 \tTPR:0.9738420517 \tFPR:0.0292071604 \tF1:0.9683483997 \t AUC:0.9723174457\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0703606433 \tAcc: 0.9740210843 \tTPR:0.9771116645 \tFPR:0.0289834299 \tF1:0.9703609065 \t AUC:0.9740641173\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0516954780 \tAcc: 0.9815512048 \tTPR:0.9828910071 \tFPR:0.0189715968 \tF1:0.9787355224 \t AUC:0.9819597051\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0544889134 \tAcc: 0.9789156627 \tTPR:0.9842706348 \tFPR:0.0258166335 \tF1:0.9763326814 \t AUC:0.9792270007\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0468932856 \tAcc: 0.9838102410 \tTPR:0.9873816061 \tFPR:0.0197649454 \tF1:0.9809812044 \t AUC:0.9838083304\tTrain cost: 0:00:08\n",
      "Client3 Test =>                 \tLoss: 0.2392791972 \tAcc: 0.9406250000 \tTPR:0.9119474407 \tFPR:0.0314666417 \tF1:0.9348240348 \tAUC:0.9402403995 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09623359638469646 \tALA epochs: 4\n",
      "Client 1: Local Initial ALA epochs: 4 Loss: 0.12892197924017689825\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0523253467 \tAcc: 0.9794864766 \tTPR:0.8908614128 \tFPR:0.0104510541 \tF1:0.8773038098 \t AUC:0.9391479501\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0455744692 \tAcc: 0.9815789474 \tTPR:0.9033851464 \tFPR:0.0090024362 \tF1:0.8945715961 \t AUC:0.9460342910\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0410083391 \tAcc: 0.9831871345 \tTPR:0.9208744715 \tFPR:0.0087494718 \tF1:0.9071441838 \t AUC:0.9549932360\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0377263171 \tAcc: 0.9852887427 \tTPR:0.9288214750 \tFPR:0.0073450125 \tF1:0.9190984686 \t AUC:0.9598857938\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0339914037 \tAcc: 0.9858826754 \tTPR:0.9319061543 \tFPR:0.0077513524 \tF1:0.9193112376 \t AUC:0.9611572138\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.5100913494 \tAcc: 0.8818750000 \tTPR:0.7743301226 \tFPR:0.0150751364 \tF1:0.8605271531 \tAUC:0.8796274931 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.07151453875265423 \tALA epochs: 9\n",
      "Client 6: Local Initial ALA epochs: 9 Loss: 0.27985608218302265859\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1124009520 \tAcc: 0.9555329053 \tTPR:0.9597182196 \tFPR:0.0484005468 \tF1:0.9515570639 \t AUC:0.9556588364\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.1008876111 \tAcc: 0.9601154239 \tTPR:0.9665595566 \tFPR:0.0458169530 \tF1:0.9570054899 \t AUC:0.9603713018\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0933187544 \tAcc: 0.9631121134 \tTPR:0.9685913771 \tFPR:0.0414483630 \tF1:0.9600037879 \t AUC:0.9635715070\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0878707616 \tAcc: 0.9659227248 \tTPR:0.9714394411 \tFPR:0.0389703586 \tF1:0.9627153764 \t AUC:0.9662345412\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0808540066 \tAcc: 0.9680001333 \tTPR:0.9750813433 \tFPR:0.0388468584 \tF1:0.9653831332 \t AUC:0.9681172424\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2062552351 \tAcc: 0.9414583333 \tTPR:0.9185145701 \tFPR:0.0358546322 \tF1:0.9378673178 \tAUC:0.9413299690 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2754731248 \tAcc: 0.9278333333 \tTPR:0.8976406324 \tFPR:0.0433383007 \tF1:0.9213985166 \tAUC:0.9271511659\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 23:  =============\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.02447313197481808 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.04232211294583976269\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0641627665 \tAcc: 0.9785466270 \tTPR:0.9896643717 \tFPR:0.0474203240 \tF1:0.9836823666 \t AUC:0.9711220239\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0537043114 \tAcc: 0.9806547619 \tTPR:0.9911609939 \tFPR:0.0410812169 \tF1:0.9852831733 \t AUC:0.9750398885\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0439536704 \tAcc: 0.9851190476 \tTPR:0.9924442695 \tFPR:0.0290338795 \tF1:0.9888977950 \t AUC:0.9817051950\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0463926092 \tAcc: 0.9884672619 \tTPR:0.9956574955 \tFPR:0.0275101766 \tF1:0.9914911300 \t AUC:0.9840736595\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0459615932 \tAcc: 0.9836309524 \tTPR:0.9917515315 \tFPR:0.0330515384 \tF1:0.9874683620 \t AUC:0.9793499966\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2712803221 \tAcc: 0.9335416667 \tTPR:0.9236605426 \tFPR:0.0581831503 \tF1:0.9304395934 \tAUC:0.9327386961 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.09233919087942162 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.07515970428446025475\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0634794728 \tAcc: 0.9757153614 \tTPR:0.9898431257 \tFPR:0.0788771971 \tF1:0.9846836510 \t AUC:0.9554829643\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0492909772 \tAcc: 0.9819277108 \tTPR:0.9930603420 \tFPR:0.0613411438 \tF1:0.9885992981 \t AUC:0.9658595991\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0470446721 \tAcc: 0.9818335843 \tTPR:0.9923432448 \tFPR:0.0601638154 \tF1:0.9885309699 \t AUC:0.9660897147\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0426705932 \tAcc: 0.9857868976 \tTPR:0.9947035954 \tFPR:0.0522235378 \tF1:0.9910307456 \t AUC:0.9712400288\tTrain cost: 0:00:35\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0367794949 \tAcc: 0.9861634036 \tTPR:0.9940219152 \tFPR:0.0453844599 \tF1:0.9912868919 \t AUC:0.9743187277\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.2391492295 \tAcc: 0.9414583333 \tTPR:0.9331446178 \tFPR:0.0518586274 \tF1:0.9389000719 \tAUC:0.9406429952 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07879446227485283 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.17179968059062958319\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1369516018 \tAcc: 0.9564732143 \tTPR:0.9770786914 \tFPR:0.1204081633 \tF1:0.9719454529 \t AUC:0.9283352641\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.1046052539 \tAcc: 0.9631696429 \tTPR:0.9874231563 \tFPR:0.1252409297 \tF1:0.9763535867 \t AUC:0.9310911133\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0878469739 \tAcc: 0.9676339286 \tTPR:0.9911140950 \tFPR:0.1237270666 \tF1:0.9792918727 \t AUC:0.9336935142\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0707852259 \tAcc: 0.9787946429 \tTPR:0.9929995045 \tFPR:0.0748441043 \tF1:0.9866670016 \t AUC:0.9590777001\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0615646465 \tAcc: 0.9766938025 \tTPR:0.9871452397 \tFPR:0.0589143991 \tF1:0.9845230961 \t AUC:0.9641154203\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1880105281 \tAcc: 0.9439583333 \tTPR:0.9617427183 \tFPR:0.0740427572 \tF1:0.9436827412 \tAUC:0.9438499805 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.09143391400927783 \tALA epochs: 3\n",
      "Client 6: Local Initial ALA epochs: 3 Loss: 0.16667824230979305655\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.1088119333 \tAcc: 0.9566688144 \tTPR:0.9624945405 \tFPR:0.0478085675 \tF1:0.9533156184 \t AUC:0.9573429865\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0939083644 \tAcc: 0.9616540393 \tTPR:0.9653659604 \tFPR:0.0415871549 \tF1:0.9586871125 \t AUC:0.9618894027\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0888891461 \tAcc: 0.9650284394 \tTPR:0.9713950423 \tFPR:0.0403712216 \tF1:0.9619777181 \t AUC:0.9655119104\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0817646995 \tAcc: 0.9689916237 \tTPR:0.9747629905 \tFPR:0.0367018768 \tF1:0.9659805662 \t AUC:0.9690305569\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0745960658 \tAcc: 0.9714884021 \tTPR:0.9770810163 \tFPR:0.0338096863 \tF1:0.9696981877 \t AUC:0.9716356650\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2027176061 \tAcc: 0.9441666667 \tTPR:0.9326613624 \tFPR:0.0434452779 \tF1:0.9419374105 \tAUC:0.9446080422 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.06966737183373592 \tALA epochs: 2\n",
      "Client 5: Local Initial ALA epochs: 2 Loss: 0.10990142934024334231\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0443811591 \tAcc: 0.9811970339 \tTPR:0.9346715745 \tFPR:0.0109653905 \tF1:0.9297643232 \t AUC:0.9615739107\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0343028016 \tAcc: 0.9863524011 \tTPR:0.9536263564 \tFPR:0.0075930203 \tF1:0.9497660983 \t AUC:0.9728849247\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0339453360 \tAcc: 0.9867584746 \tTPR:0.9610942965 \tFPR:0.0083732693 \tF1:0.9545482051 \t AUC:0.9763054063\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0328000591 \tAcc: 0.9859639831 \tTPR:0.9555732874 \tFPR:0.0089471810 \tF1:0.9481470099 \t AUC:0.9732501258\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0281623474 \tAcc: 0.9890536723 \tTPR:0.9655221505 \tFPR:0.0066125028 \tF1:0.9587531904 \t AUC:0.9794059884\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4221626387 \tAcc: 0.9106250000 \tTPR:0.8403884488 \tFPR:0.0185660959 \tF1:0.9006535628 \tAUC:0.9109111764 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2646640649 \tAcc: 0.9347500000 \tTPR:0.9183195380 \tFPR:0.0492191818 \tF1:0.9311226760 \tAUC:0.9345501781\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 24:  =============\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.09925542560371566 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.09915412424930504509\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0381340994 \tAcc: 0.9852048023 \tTPR:0.9571707796 \tFPR:0.0093730104 \tF1:0.9520200609 \t AUC:0.9737158538\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0311948034 \tAcc: 0.9875529661 \tTPR:0.9594923203 \tFPR:0.0070219567 \tF1:0.9561618530 \t AUC:0.9761778055\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0271467062 \tAcc: 0.9877295198 \tTPR:0.9579544435 \tFPR:0.0075323387 \tF1:0.9521354273 \t AUC:0.9751514978\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0239286312 \tAcc: 0.9908192090 \tTPR:0.9714016680 \tFPR:0.0057348887 \tF1:0.9654262889 \t AUC:0.9826285305\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0254896027 \tAcc: 0.9904131356 \tTPR:0.9680241682 \tFPR:0.0053231739 \tF1:0.9644210838 \t AUC:0.9811677781\tTrain cost: 0:00:37\n",
      "Client5 Test =>                 \tLoss: 0.4002349974 \tAcc: 0.9193750000 \tTPR:0.8580926237 \tFPR:0.0209566813 \tF1:0.9109455172 \tAUC:0.9185679712 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.13139539345876813 \tALA epochs: 11\n",
      "Client 0: Local Initial ALA epochs: 11 Loss: 0.34435545436360620597\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1372554699 \tAcc: 0.9564732143 \tTPR:0.9701359216 \tFPR:0.0916950113 \tF1:0.9711367220 \t AUC:0.9392204551\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0809694050 \tAcc: 0.9699973739 \tTPR:0.9848676984 \tFPR:0.0712481962 \tF1:0.9803274902 \t AUC:0.9568097511\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0830794637 \tAcc: 0.9654017857 \tTPR:0.9808092753 \tFPR:0.0952406720 \tF1:0.9774790732 \t AUC:0.9427843017\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0730903359 \tAcc: 0.9676339286 \tTPR:0.9841093232 \tFPR:0.0918521954 \tF1:0.9789574287 \t AUC:0.9461285639\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0689955867 \tAcc: 0.9722295168 \tTPR:0.9881572706 \tFPR:0.0865246856 \tF1:0.9828125269 \t AUC:0.9508162925\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1892220003 \tAcc: 0.9437500000 \tTPR:0.9588214760 \tFPR:0.0705789290 \tF1:0.9435986487 \tAUC:0.9441212735 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06274564790446248 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06301164836622774601\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0650470003 \tAcc: 0.9754464286 \tTPR:0.9867993661 \tFPR:0.0490704333 \tF1:0.9812553690 \t AUC:0.9688644664\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0482683429 \tAcc: 0.9828869048 \tTPR:0.9903011962 \tFPR:0.0336240479 \tF1:0.9871489537 \t AUC:0.9783385741\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0498238730 \tAcc: 0.9818948413 \tTPR:0.9881042939 \tFPR:0.0316112294 \tF1:0.9864426695 \t AUC:0.9782465322\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0383699120 \tAcc: 0.9848710317 \tTPR:0.9913728872 \tFPR:0.0277781742 \tF1:0.9882517891 \t AUC:0.9817973565\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0321814858 \tAcc: 0.9888392857 \tTPR:0.9929693766 \tFPR:0.0196336732 \tF1:0.9917274433 \t AUC:0.9866678517\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.3103306775 \tAcc: 0.9295833333 \tTPR:0.9173129656 \tFPR:0.0574646402 \tF1:0.9254781242 \tAUC:0.9299241627 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09154991669565725 \tALA epochs: 3\n",
      "Client 4: Local Initial ALA epochs: 3 Loss: 0.11790583495909442990\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0933162862 \tAcc: 0.9653650347 \tTPR:0.9804466249 \tFPR:0.0617274226 \tF1:0.9725644309 \t AUC:0.9593596012\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0850048035 \tAcc: 0.9675043328 \tTPR:0.9828264142 \tFPR:0.0607997782 \tF1:0.9743746553 \t AUC:0.9610133180\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0780098268 \tAcc: 0.9711871750 \tTPR:0.9855464095 \tFPR:0.0539470340 \tF1:0.9771608905 \t AUC:0.9657996877\tTrain cost: 0:01:54\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0737268741 \tAcc: 0.9712559159 \tTPR:0.9843338111 \tFPR:0.0535616134 \tF1:0.9774275116 \t AUC:0.9653860989\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0735835358 \tAcc: 0.9719995667 \tTPR:0.9856126322 \tFPR:0.0526425024 \tF1:0.9778128048 \t AUC:0.9664850649\tTrain cost: 0:01:55\n",
      "Client4 Test =>                 \tLoss: 0.2205568690 \tAcc: 0.9360416667 \tTPR:0.9240556728 \tFPR:0.0520739496 \tF1:0.9338309402 \tAUC:0.9359908616 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.09475119851649627 \tALA epochs: 3\n",
      "Client 1: Local Initial ALA epochs: 3 Loss: 0.13002420807734940689\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0533601216 \tAcc: 0.9782986111 \tTPR:0.8908810853 \tFPR:0.0114268945 \tF1:0.8762881849 \t AUC:0.9385037892\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0461186515 \tAcc: 0.9819535819 \tTPR:0.9083797457 \tFPR:0.0086487951 \tF1:0.9009173766 \t AUC:0.9485566145\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0411339151 \tAcc: 0.9828673246 \tTPR:0.9128277871 \tFPR:0.0083830549 \tF1:0.9041395795 \t AUC:0.9508418106\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0372451642 \tAcc: 0.9859649123 \tTPR:0.9356104381 \tFPR:0.0075350931 \tF1:0.9189246185 \t AUC:0.9630679502\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0330051354 \tAcc: 0.9864766082 \tTPR:0.9261881028 \tFPR:0.0065958610 \tF1:0.9202555716 \t AUC:0.9588554895\tTrain cost: 0:01:09\n",
      "Client1 Test =>                 \tLoss: 0.5490067755 \tAcc: 0.8754166667 \tTPR:0.7596901855 \tFPR:0.0112630314 \tF1:0.8529848074 \tAUC:0.8742135770 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3338702639 \tAcc: 0.9208333333 \tTPR:0.8835945847 \tFPR:0.0424674463 \tF1:0.9133676075 \tAUC:0.9205635692\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 25:  =============\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.06170028265485061 \tALA epochs: 4\n",
      "Client 6: Local Initial ALA epochs: 4 Loss: 0.10269640510343922002\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0941785276 \tAcc: 0.9629343672 \tTPR:0.9692535977 \tFPR:0.0428459654 \tF1:0.9601094471 \t AUC:0.9632038162\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0878598762 \tAcc: 0.9662365579 \tTPR:0.9703579931 \tFPR:0.0376090055 \tF1:0.9640487922 \t AUC:0.9663744938\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0756759774 \tAcc: 0.9718105670 \tTPR:0.9763003783 \tFPR:0.0318723655 \tF1:0.9689135177 \t AUC:0.9722140064\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0752360933 \tAcc: 0.9704330341 \tTPR:0.9752503009 \tFPR:0.0347013380 \tF1:0.9684220339 \t AUC:0.9702744815\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0733016430 \tAcc: 0.9717216939 \tTPR:0.9778301857 \tFPR:0.0330886885 \tF1:0.9695920982 \t AUC:0.9723707486\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2180777863 \tAcc: 0.9420833333 \tTPR:0.9273147727 \tFPR:0.0415991874 \tF1:0.9392238209 \tAUC:0.9428577927 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.04292696624159718 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.10116078900838536281\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0367854250 \tAcc: 0.9844632768 \tTPR:0.9476235315 \tFPR:0.0093098670 \tF1:0.9378716926 \t AUC:0.9690826446\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0289144387 \tAcc: 0.9881179379 \tTPR:0.9652161241 \tFPR:0.0075689641 \tF1:0.9499408374 \t AUC:0.9786248150\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0205176640 \tAcc: 0.9919668079 \tTPR:0.9765189221 \tFPR:0.0052321511 \tF1:0.9672712388 \t AUC:0.9856101262\tTrain cost: 0:00:40\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0224433717 \tAcc: 0.9919668079 \tTPR:0.9704578065 \tFPR:0.0049999805 \tF1:0.9650779980 \t AUC:0.9826449863\tTrain cost: 0:00:37\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0191321833 \tAcc: 0.9922669492 \tTPR:0.9769202314 \tFPR:0.0050272463 \tF1:0.9716083334 \t AUC:0.9859138016\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4254105210 \tAcc: 0.9204166667 \tTPR:0.8630172959 \tFPR:0.0224029618 \tF1:0.9123537526 \tAUC:0.9203071670 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.36673920576160446 \tALA epochs: 11\n",
      "Client 9: Local Initial ALA epochs: 11 Loss: 0.57497957471973637489\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0736606193 \tAcc: 0.9776041667 \tTPR:0.9834684966 \tFPR:0.0867673993 \tF1:0.9871886795 \t AUC:0.9479803369\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0270794321 \tAcc: 0.9901041667 \tTPR:0.9971994732 \tFPR:0.0892156863 \tF1:0.9945206454 \t AUC:0.9540511607\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0307467604 \tAcc: 0.9880208333 \tTPR:0.9954928757 \tFPR:0.1071428571 \tF1:0.9934122525 \t AUC:0.9440140405\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0253907729 \tAcc: 0.9906250000 \tTPR:0.9967359952 \tFPR:0.0721088435 \tF1:0.9948808064 \t AUC:0.9622660855\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0144429215 \tAcc: 0.9947916667 \tTPR:0.9994252874 \tFPR:0.0590909091 \tF1:0.9971605398 \t AUC:0.9701410658\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3269374256 \tAcc: 0.9304166667 \tTPR:0.9884971007 \tFPR:0.1306677431 \tF1:0.9333888822 \tAUC:0.9289146788 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.18991769571912825 \tALA epochs: 11\n",
      "Client 3: Local Initial ALA epochs: 11 Loss: 0.46362397555772488777\n",
      "Client3 Local Train => Local Epoch: 0 \tLoss: 0.1025296150 \tAcc: 0.9634789157 \tTPR:0.9727740144 \tFPR:0.0417801725 \tF1:0.9576354594 \t AUC:0.9654969210\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 1 \tLoss: 0.0829688272 \tAcc: 0.9696703481 \tTPR:0.9709193176 \tFPR:0.0302152828 \tF1:0.9636515096 \t AUC:0.9703520174\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 2 \tLoss: 0.0744105445 \tAcc: 0.9702560241 \tTPR:0.9766869300 \tFPR:0.0341859392 \tF1:0.9673323011 \t AUC:0.9712504954\tTrain cost: 0:00:08\n",
      "Client3 Local Train => Local Epoch: 3 \tLoss: 0.0619656491 \tAcc: 0.9781626506 \tTPR:0.9823397555 \tFPR:0.0239802308 \tF1:0.9750073987 \t AUC:0.9791797624\tTrain cost: 0:00:09\n",
      "Client3 Local Train => Local Epoch: 4 \tLoss: 0.0600572067 \tAcc: 0.9770331325 \tTPR:0.9836844902 \tFPR:0.0299491280 \tF1:0.9741759733 \t AUC:0.9768676811\tTrain cost: 0:00:09\n",
      "Client3 Test =>                 \tLoss: 0.2526761471 \tAcc: 0.9335416667 \tTPR:0.9000557367 \tFPR:0.0322482440 \tF1:0.9284272391 \tAUC:0.9339037464 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07888182512289013 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.17015594393014907282\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1039712219 \tAcc: 0.9598214286 \tTPR:0.9789528733 \tFPR:0.1173611111 \tF1:0.9742655570 \t AUC:0.9307958811\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0852806148 \tAcc: 0.9709821429 \tTPR:0.9929461015 \tFPR:0.1181264172 \tF1:0.9818899911 \t AUC:0.9374098421\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0701972059 \tAcc: 0.9744616597 \tTPR:0.9866193515 \tFPR:0.0968692022 \tF1:0.9827914545 \t AUC:0.9448750746\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0668577091 \tAcc: 0.9776785714 \tTPR:0.9943694970 \tFPR:0.0832766440 \tF1:0.9859200641 \t AUC:0.9555464265\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0625316950 \tAcc: 0.9744616597 \tTPR:0.9900550145 \tFPR:0.0888502371 \tF1:0.9837474428 \t AUC:0.9506023887\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.1945082895 \tAcc: 0.9458333333 \tTPR:0.9607485132 \tFPR:0.0696332194 \tF1:0.9464987988 \tAUC:0.9455576469 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2835220339 \tAcc: 0.9344583333 \tTPR:0.9279266838 \tFPR:0.0593102711 \tF1:0.9319784987 \tAUC:0.9343082064\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 26:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.04631527020279459 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.11915371802534713286\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0930114977 \tAcc: 0.9677329882 \tTPR:0.9868795914 \tFPR:0.0966206724 \tF1:0.9787448080 \t AUC:0.9451099930\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0775958929 \tAcc: 0.9711538462 \tTPR:0.9883146253 \tFPR:0.0865779456 \tF1:0.9810495818 \t AUC:0.9508510025\tTrain cost: 0:00:35\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0766155399 \tAcc: 0.9711538462 \tTPR:0.9877125104 \tFPR:0.0846856655 \tF1:0.9810795351 \t AUC:0.9514951918\tTrain cost: 0:00:39\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0705739168 \tAcc: 0.9746671598 \tTPR:0.9895308312 \tFPR:0.0752218846 \tF1:0.9832771065 \t AUC:0.9571698180\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0639793977 \tAcc: 0.9757766272 \tTPR:0.9896790558 \tFPR:0.0719041642 \tF1:0.9840196944 \t AUC:0.9588874458\tTrain cost: 0:00:35\n",
      "Client8 Test =>                 \tLoss: 0.1915154263 \tAcc: 0.9439583333 \tTPR:0.9673522661 \tFPR:0.0790235573 \tF1:0.9430143018 \tAUC:0.9441643544 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.07038006772411537 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.11909505873918532770\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.0958688975 \tAcc: 0.9554884454 \tTPR:0.9802574972 \tFPR:0.1391362606 \tF1:0.9714601045 \t AUC:0.9205606183\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0721098613 \tAcc: 0.9754464286 \tTPR:0.9888279703 \tFPR:0.0686507937 \tF1:0.9842878254 \t AUC:0.9600885883\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0649479596 \tAcc: 0.9743303571 \tTPR:0.9881803646 \tFPR:0.0909464543 \tF1:0.9834722125 \t AUC:0.9486169551\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0543283348 \tAcc: 0.9765625000 \tTPR:0.9959662751 \tFPR:0.0962043908 \tF1:0.9850706791 \t AUC:0.9498809421\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0520484560 \tAcc: 0.9833902311 \tTPR:0.9945054945 \tFPR:0.0609126984 \tF1:0.9895981658 \t AUC:0.9667963980\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2048416762 \tAcc: 0.9427083333 \tTPR:0.9575945726 \tFPR:0.0756090185 \tF1:0.9429689723 \tAUC:0.9409927770 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.04807678231286651 \tALA epochs: 2\n",
      "Client 7: Local Initial ALA epochs: 2 Loss: 0.07319752377952681854\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0652237660 \tAcc: 0.9780505952 \tTPR:0.9865938823 \tFPR:0.0396042168 \tF1:0.9832971880 \t AUC:0.9734948328\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0574173304 \tAcc: 0.9796626984 \tTPR:0.9872071760 \tFPR:0.0357018691 \tF1:0.9845547739 \t AUC:0.9757526534\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0496064535 \tAcc: 0.9804067460 \tTPR:0.9886648020 \tFPR:0.0359646306 \tF1:0.9852893146 \t AUC:0.9763500857\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0434312573 \tAcc: 0.9843750000 \tTPR:0.9914114789 \tFPR:0.0287249396 \tF1:0.9881475272 \t AUC:0.9813432697\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0370681081 \tAcc: 0.9866071429 \tTPR:0.9913078185 \tFPR:0.0207984806 \tF1:0.9898127822 \t AUC:0.9852546689\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2648895171 \tAcc: 0.9368750000 \tTPR:0.9367104066 \tFPR:0.0647382546 \tF1:0.9353457503 \tAUC:0.9359860760 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.08083448070583901 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.12167426617211335449\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0833098318 \tAcc: 0.9679362558 \tTPR:0.9722202878 \tFPR:0.0363747172 \tF1:0.9648863803 \t AUC:0.9679227853\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0713013189 \tAcc: 0.9726965206 \tTPR:0.9782332641 \tFPR:0.0325657526 \tF1:0.9702668073 \t AUC:0.9728337558\tTrain cost: 0:00:41\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0702329310 \tAcc: 0.9730908950 \tTPR:0.9761620337 \tFPR:0.0295847878 \tF1:0.9703025606 \t AUC:0.9732886229\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0633771880 \tAcc: 0.9759987113 \tTPR:0.9787137555 \tFPR:0.0264459195 \tF1:0.9734586034 \t AUC:0.9761339180\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0600721819 \tAcc: 0.9770374156 \tTPR:0.9802415205 \tFPR:0.0261449349 \tF1:0.9752100262 \t AUC:0.9770482928\tTrain cost: 0:00:40\n",
      "Client6 Test =>                 \tLoss: 0.2518137071 \tAcc: 0.9372916667 \tTPR:0.9138727695 \tFPR:0.0414514585 \tF1:0.9328487568 \tAUC:0.9362106555 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.0749806711109555 \tALA epochs: 8\n",
      "Client 1: Local Initial ALA epochs: 8 Loss: 0.13866952733927545571\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0509656214 \tAcc: 0.9795321637 \tTPR:0.8962817924 \tFPR:0.0099056254 \tF1:0.8830873023 \t AUC:0.9416260623\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0443011627 \tAcc: 0.9814053363 \tTPR:0.9059790680 \tFPR:0.0094455048 \tF1:0.8896455319 \t AUC:0.9469962285\tTrain cost: 0:01:12\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0389802506 \tAcc: 0.9845577485 \tTPR:0.9253637566 \tFPR:0.0075385611 \tF1:0.9209412935 \t AUC:0.9576724185\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0348094242 \tAcc: 0.9861567982 \tTPR:0.9338577926 \tFPR:0.0073722078 \tF1:0.9240614407 \t AUC:0.9625517544\tTrain cost: 0:01:13\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0311521655 \tAcc: 0.9874360380 \tTPR:0.9413794904 \tFPR:0.0064991841 \tF1:0.9318615176 \t AUC:0.9668722943\tTrain cost: 0:01:11\n",
      "Client1 Test =>                 \tLoss: 0.5226840570 \tAcc: 0.8812500000 \tTPR:0.7724482364 \tFPR:0.0126821045 \tF1:0.8605249891 \tAUC:0.8798830660 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2871488767 \tAcc: 0.9284166667 \tTPR:0.9095956502 \tFPR:0.0547008787 \tF1:0.9229405540 \tAUC:0.9274473858\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 27:  =============\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.07995206544306854 \tALA epochs: 1\n",
      "Client 1: Local Initial ALA epochs: 1 Loss: 0.12762378594582995950\n",
      "Client1 Local Train => Local Epoch: 0 \tLoss: 0.0451717014 \tAcc: 0.9807200292 \tTPR:0.9082521118 \tFPR:0.0100537117 \tF1:0.8972613820 \t AUC:0.9480004229\tTrain cost: 0:01:10\n",
      "Client1 Local Train => Local Epoch: 1 \tLoss: 0.0390653959 \tAcc: 0.9847861842 \tTPR:0.9216762972 \tFPR:0.0073532423 \tF1:0.9147734847 \t AUC:0.9561633993\tTrain cost: 0:01:09\n",
      "Client1 Local Train => Local Epoch: 2 \tLoss: 0.0355110493 \tAcc: 0.9851973684 \tTPR:0.9293424534 \tFPR:0.0077706289 \tF1:0.9109774109 \t AUC:0.9592779768\tTrain cost: 0:01:14\n",
      "Client1 Local Train => Local Epoch: 3 \tLoss: 0.0317753385 \tAcc: 0.9867507310 \tTPR:0.9322838346 \tFPR:0.0063548458 \tF1:0.9271582115 \t AUC:0.9620494111\tTrain cost: 0:01:11\n",
      "Client1 Local Train => Local Epoch: 4 \tLoss: 0.0310991619 \tAcc: 0.9882584064 \tTPR:0.9464761441 \tFPR:0.0063520739 \tF1:0.9348304192 \t AUC:0.9692559529\tTrain cost: 0:01:10\n",
      "Client1 Test =>                 \tLoss: 0.4154654355 \tAcc: 0.8985416667 \tTPR:0.8156319913 \tFPR:0.0202185153 \tF1:0.8849224815 \tAUC:0.8977067380 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.09605034474147182 \tALA epochs: 5\n",
      "Client 4: Local Initial ALA epochs: 5 Loss: 0.28691789691376945459\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0893831905 \tAcc: 0.9655275130 \tTPR:0.9812377195 \tFPR:0.0620176337 \tF1:0.9728677966 \t AUC:0.9596100429\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0816029960 \tAcc: 0.9683438042 \tTPR:0.9827306136 \tFPR:0.0570089623 \tF1:0.9750917920 \t AUC:0.9628608256\tTrain cost: 0:02:02\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0742831453 \tAcc: 0.9722703640 \tTPR:0.9854796381 \tFPR:0.0516000648 \tF1:0.9781344159 \t AUC:0.9669397867\tTrain cost: 0:01:55\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0705125467 \tAcc: 0.9736243501 \tTPR:0.9860385705 \tFPR:0.0482650071 \tF1:0.9791312590 \t AUC:0.9688867817\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0676364672 \tAcc: 0.9735160312 \tTPR:0.9860264628 \tFPR:0.0489386808 \tF1:0.9791462672 \t AUC:0.9685438910\tTrain cost: 0:02:00\n",
      "Client4 Test =>                 \tLoss: 0.2266018207 \tAcc: 0.9408333333 \tTPR:0.9304298112 \tFPR:0.0496292252 \tF1:0.9385068787 \tAUC:0.9404002930 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.06943115059984668 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06639616165193729103\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0626098402 \tAcc: 0.9747023810 \tTPR:0.9870546514 \tFPR:0.0465330635 \tF1:0.9809906602 \t AUC:0.9702607940\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0544503892 \tAcc: 0.9802827381 \tTPR:0.9910154905 \tFPR:0.0449141632 \tF1:0.9851381688 \t AUC:0.9730506637\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0496093948 \tAcc: 0.9832589286 \tTPR:0.9920725553 \tFPR:0.0346181266 \tF1:0.9874896016 \t AUC:0.9787272144\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0434608436 \tAcc: 0.9862351190 \tTPR:0.9913661092 \tFPR:0.0258170615 \tF1:0.9894142903 \t AUC:0.9827745238\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0399901697 \tAcc: 0.9866071429 \tTPR:0.9931882590 \tFPR:0.0269301135 \tF1:0.9900815443 \t AUC:0.9831290727\tTrain cost: 0:00:09\n",
      "Client7 Test =>                 \tLoss: 0.2681036088 \tAcc: 0.9368750000 \tTPR:0.9385823367 \tFPR:0.0664516659 \tF1:0.9351832718 \tAUC:0.9360653354 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.07280661110313982 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.09254378566666590644\n",
      "Client2 Local Train => Local Epoch: 0 \tLoss: 0.0616113887 \tAcc: 0.9769390060 \tTPR:0.9905253478 \tFPR:0.0769306809 \tF1:0.9854318868 \t AUC:0.9567830213\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 1 \tLoss: 0.0523269105 \tAcc: 0.9806099398 \tTPR:0.9925691315 \tFPR:0.0689538039 \tF1:0.9877712535 \t AUC:0.9618076638\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 2 \tLoss: 0.0452443292 \tAcc: 0.9828689759 \tTPR:0.9926697733 \tFPR:0.0578175506 \tF1:0.9892553919 \t AUC:0.9674261113\tTrain cost: 0:00:34\n",
      "Client2 Local Train => Local Epoch: 3 \tLoss: 0.0379314995 \tAcc: 0.9861634036 \tTPR:0.9939613681 \tFPR:0.0428077027 \tF1:0.9911527892 \t AUC:0.9755768327\tTrain cost: 0:00:33\n",
      "Client2 Local Train => Local Epoch: 4 \tLoss: 0.0353915980 \tAcc: 0.9866340361 \tTPR:0.9934069927 \tFPR:0.0397691415 \tF1:0.9914869758 \t AUC:0.9768189256\tTrain cost: 0:00:33\n",
      "Client2 Test =>                 \tLoss: 0.2287033776 \tAcc: 0.9437500000 \tTPR:0.9627308220 \tFPR:0.0754702419 \tF1:0.9428220755 \tAUC:0.9436302901 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08572878721846275 \tALA epochs: 8\n",
      "Client 5: Local Initial ALA epochs: 8 Loss: 0.28345301099543573908\n",
      "Client5 Local Train => Local Epoch: 0 \tLoss: 0.0435449598 \tAcc: 0.9822033898 \tTPR:0.9448502376 \tFPR:0.0104291312 \tF1:0.9370391283 \t AUC:0.9672105532\tTrain cost: 0:00:36\n",
      "Client5 Local Train => Local Epoch: 1 \tLoss: 0.0306580229 \tAcc: 0.9859639831 \tTPR:0.9522687529 \tFPR:0.0080350667 \tF1:0.9449110313 \t AUC:0.9718440931\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 2 \tLoss: 0.0268306866 \tAcc: 0.9903248588 \tTPR:0.9615840609 \tFPR:0.0047916102 \tF1:0.9609445588 \t AUC:0.9783962254\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 3 \tLoss: 0.0217267389 \tAcc: 0.9915254237 \tTPR:0.9716156725 \tFPR:0.0045007301 \tF1:0.9653836541 \t AUC:0.9835172668\tTrain cost: 0:00:35\n",
      "Client5 Local Train => Local Epoch: 4 \tLoss: 0.0186799557 \tAcc: 0.9926730226 \tTPR:0.9775647924 \tFPR:0.0044816082 \tF1:0.9703873972 \t AUC:0.9864778557\tTrain cost: 0:00:36\n",
      "Client5 Test =>                 \tLoss: 0.4821223704 \tAcc: 0.9075000000 \tTPR:0.8290232810 \tFPR:0.0152612138 \tF1:0.8950156118 \tAUC:0.9068810336 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.3241993226 \tAcc: 0.9255000000 \tTPR:0.8952796484 \tFPR:0.0454061724 \tF1:0.9192900639 \tAUC:0.9249367380\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 28:  =============\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.08296711498514754 \tALA epochs: 2\n",
      "Client 8: Local Initial ALA epochs: 2 Loss: 0.14452220359295883667\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0726188526 \tAcc: 0.9741124260 \tTPR:0.9895700695 \tFPR:0.0756339276 \tF1:0.9830159045 \t AUC:0.9569525963\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0653542697 \tAcc: 0.9760539941 \tTPR:0.9900456858 \tFPR:0.0713958602 \tF1:0.9842311149 \t AUC:0.9593565088\tTrain cost: 0:00:33\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0583178486 \tAcc: 0.9781804734 \tTPR:0.9909634481 \tFPR:0.0640996697 \tF1:0.9854465966 \t AUC:0.9634184819\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0559548820 \tAcc: 0.9789201183 \tTPR:0.9905518716 \tFPR:0.0628275247 \tF1:0.9860980982 \t AUC:0.9638340540\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0496860398 \tAcc: 0.9810465976 \tTPR:0.9918334135 \tFPR:0.0534379657 \tF1:0.9874110653 \t AUC:0.9691977239\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.1990159273 \tAcc: 0.9452083333 \tTPR:0.9631226542 \tFPR:0.0713744262 \tF1:0.9430414747 \tAUC:0.9458741140 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.05341080926059075 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.07616468745425505893\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0737371499 \tAcc: 0.9715267131 \tTPR:0.9840997957 \tFPR:0.0506494249 \tF1:0.9774405695 \t AUC:0.9667251854\tTrain cost: 0:01:54\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0675305154 \tAcc: 0.9753845321 \tTPR:0.9871351643 \tFPR:0.0460916222 \tF1:0.9806025226 \t AUC:0.9705217711\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0620489645 \tAcc: 0.9766031196 \tTPR:0.9869462042 \tFPR:0.0429832414 \tF1:0.9814103979 \t AUC:0.9719814814\tTrain cost: 0:01:51\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0611204459 \tAcc: 0.9773759332 \tTPR:0.9880879091 \tFPR:0.0418131662 \tF1:0.9819715640 \t AUC:0.9731373714\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0572280429 \tAcc: 0.9784445407 \tTPR:0.9881168600 \tFPR:0.0396983029 \tF1:0.9829710913 \t AUC:0.9742092786\tTrain cost: 0:01:57\n",
      "Client4 Test =>                 \tLoss: 0.2437408839 \tAcc: 0.9400000000 \tTPR:0.9446159867 \tFPR:0.0677171294 \tF1:0.9373874876 \tAUC:0.9384494287 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.08188166197722699 \tALA epochs: 1\n",
      "Client 9: Local Initial ALA epochs: 1 Loss: 0.05956873881884596628\n",
      "Client9 Local Train => Local Epoch: 0 \tLoss: 0.0367938033 \tAcc: 0.9901041667 \tTPR:0.9954712302 \tFPR:0.0597484277 \tF1:0.9945076038 \t AUC:0.9678571429\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 1 \tLoss: 0.0259215962 \tAcc: 0.9885416667 \tTPR:0.9966796275 \tFPR:0.1191823899 \tF1:0.9938145787 \t AUC:0.9388241602\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 2 \tLoss: 0.0190629049 \tAcc: 0.9927083333 \tTPR:0.9983092159 \tFPR:0.0698717949 \tF1:0.9959594340 \t AUC:0.9643891310\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 3 \tLoss: 0.0200718901 \tAcc: 0.9942708333 \tTPR:0.9972904307 \tFPR:0.0503144654 \tF1:0.9969552284 \t AUC:0.9738986715\tTrain cost: 0:00:06\n",
      "Client9 Local Train => Local Epoch: 4 \tLoss: 0.0154355696 \tAcc: 0.9958333333 \tTPR:0.9989236111 \tFPR:0.0351851852 \tF1:0.9977036582 \t AUC:0.9820987654\tTrain cost: 0:00:06\n",
      "Client9 Test =>                 \tLoss: 0.3027656693 \tAcc: 0.9372916667 \tTPR:0.9871135617 \tFPR:0.1108927583 \tF1:0.9383281338 \tAUC:0.9381104017 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.1742651163118249 \tALA epochs: 11\n",
      "Client 6: Local Initial ALA epochs: 11 Loss: 0.35136849157566618640\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0950680774 \tAcc: 0.9647951475 \tTPR:0.9740575936 \tFPR:0.0423475833 \tF1:0.9625231297 \t AUC:0.9658550051\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0819471183 \tAcc: 0.9684278351 \tTPR:0.9718283834 \tFPR:0.0353036173 \tF1:0.9664040352 \t AUC:0.9682623831\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0728633319 \tAcc: 0.9719716495 \tTPR:0.9774755556 \tFPR:0.0323969535 \tF1:0.9695823484 \t AUC:0.9725393011\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0695661885 \tAcc: 0.9722938144 \tTPR:0.9779362334 \tFPR:0.0328024866 \tF1:0.9698419498 \t AUC:0.9725668734\tTrain cost: 0:00:38\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0638251307 \tAcc: 0.9742990135 \tTPR:0.9798741196 \tFPR:0.0308414981 \tF1:0.9723620841 \t AUC:0.9745163108\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2277479680 \tAcc: 0.9408333333 \tTPR:0.9189496637 \tFPR:0.0377866399 \tF1:0.9364629108 \tAUC:0.9405815119 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0458381000987852 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.08062475320184603333\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0620634118 \tAcc: 0.9761904762 \tTPR:0.9866762077 \tFPR:0.0479821766 \tF1:0.9822699532 \t AUC:0.9693470156\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0532795002 \tAcc: 0.9792906746 \tTPR:0.9874985753 \tFPR:0.0392815518 \tF1:0.9844685850 \t AUC:0.9741085118\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0388515698 \tAcc: 0.9869791667 \tTPR:0.9933932233 \tFPR:0.0262918959 \tF1:0.9900856012 \t AUC:0.9835506637\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0409105095 \tAcc: 0.9849950397 \tTPR:0.9931980302 \tFPR:0.0283924739 \tF1:0.9881357732 \t AUC:0.9824027781\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0418393755 \tAcc: 0.9863591270 \tTPR:0.9903663034 \tFPR:0.0228875010 \tF1:0.9897823547 \t AUC:0.9837394012\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2757154066 \tAcc: 0.9393750000 \tTPR:0.9462732024 \tFPR:0.0682904166 \tF1:0.9381210253 \tAUC:0.9389913929 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2497971710 \tAcc: 0.9405416667 \tTPR:0.9520150138 \tFPR:0.0712122741 \tF1:0.9386682064 \tAUC:0.9404013698\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "============== Round 29:  =============\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.07005692333049528 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.05669036321038298937\n",
      "Client4 Local Train => Local Epoch: 0 \tLoss: 0.0571976416 \tAcc: 0.9780925043 \tTPR:0.9882964967 \tFPR:0.0390131755 \tF1:0.9826197252 \t AUC:0.9746416606\tTrain cost: 0:02:00\n",
      "Client4 Local Train => Local Epoch: 1 \tLoss: 0.0558458226 \tAcc: 0.9786757599 \tTPR:0.9890095737 \tFPR:0.0402323355 \tF1:0.9832405328 \t AUC:0.9743886191\tTrain cost: 0:01:57\n",
      "Client4 Local Train => Local Epoch: 2 \tLoss: 0.0512374464 \tAcc: 0.9807067391 \tTPR:0.9893536013 \tFPR:0.0357462400 \tF1:0.9847651413 \t AUC:0.9768036806\tTrain cost: 0:01:58\n",
      "Client4 Local Train => Local Epoch: 3 \tLoss: 0.0511203493 \tAcc: 0.9808817158 \tTPR:0.9904951134 \tFPR:0.0358321877 \tF1:0.9850004106 \t AUC:0.9773314628\tTrain cost: 0:01:56\n",
      "Client4 Local Train => Local Epoch: 4 \tLoss: 0.0474498143 \tAcc: 0.9821003033 \tTPR:0.9908273315 \tFPR:0.0337755769 \tF1:0.9859047137 \t AUC:0.9785258773\tTrain cost: 0:02:01\n",
      "Client4 Test =>                 \tLoss: 0.2379328376 \tAcc: 0.9435416667 \tTPR:0.9431809693 \tFPR:0.0540034593 \tF1:0.9414862921 \tAUC:0.9445887550 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.05726560071373371 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.06593831194913946092\n",
      "Client7 Local Train => Local Epoch: 0 \tLoss: 0.0661691630 \tAcc: 0.9747023810 \tTPR:0.9845615681 \tFPR:0.0485190900 \tF1:0.9807217669 \t AUC:0.9680212390\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 1 \tLoss: 0.0515293302 \tAcc: 0.9817708333 \tTPR:0.9915018430 \tFPR:0.0385337760 \tF1:0.9865049890 \t AUC:0.9764840335\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 2 \tLoss: 0.0442478220 \tAcc: 0.9847470238 \tTPR:0.9915596669 \tFPR:0.0282387751 \tF1:0.9882696154 \t AUC:0.9816604459\tTrain cost: 0:00:09\n",
      "Client7 Local Train => Local Epoch: 3 \tLoss: 0.0358988243 \tAcc: 0.9884672619 \tTPR:0.9950961043 \tFPR:0.0242810430 \tF1:0.9913213909 \t AUC:0.9854075306\tTrain cost: 0:00:08\n",
      "Client7 Local Train => Local Epoch: 4 \tLoss: 0.0341070086 \tAcc: 0.9869791667 \tTPR:0.9929282699 \tFPR:0.0261947378 \tF1:0.9904698328 \t AUC:0.9833667660\tTrain cost: 0:00:08\n",
      "Client7 Test =>                 \tLoss: 0.2866033992 \tAcc: 0.9381250000 \tTPR:0.9366788142 \tFPR:0.0587790714 \tF1:0.9360221884 \tAUC:0.9389498714 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05915812811796083 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.10148736802549646052\n",
      "Client6 Local Train => Local Epoch: 0 \tLoss: 0.0873210959 \tAcc: 0.9667364691 \tTPR:0.9704286926 \tFPR:0.0361019527 \tF1:0.9639193077 \t AUC:0.9671633699\tTrain cost: 0:00:43\n",
      "Client6 Local Train => Local Epoch: 1 \tLoss: 0.0731998754 \tAcc: 0.9704330341 \tTPR:0.9748966397 \tFPR:0.0341670892 \tF1:0.9684216155 \t AUC:0.9703647753\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 2 \tLoss: 0.0658737696 \tAcc: 0.9755960052 \tTPR:0.9798362645 \tFPR:0.0278774316 \tF1:0.9732025670 \t AUC:0.9759794164\tTrain cost: 0:00:39\n",
      "Client6 Local Train => Local Epoch: 3 \tLoss: 0.0612735617 \tAcc: 0.9762320032 \tTPR:0.9798566790 \tFPR:0.0269453679 \tF1:0.9744431172 \t AUC:0.9764556556\tTrain cost: 0:00:40\n",
      "Client6 Local Train => Local Epoch: 4 \tLoss: 0.0607319246 \tAcc: 0.9768763331 \tTPR:0.9804306048 \tFPR:0.0263972972 \tF1:0.9745148209 \t AUC:0.9770166538\tTrain cost: 0:00:39\n",
      "Client6 Test =>                 \tLoss: 0.2371477429 \tAcc: 0.9433333333 \tTPR:0.9245459537 \tFPR:0.0405347963 \tF1:0.9400640551 \tAUC:0.9420055787 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.08727434882327502 \tALA epochs: 4\n",
      "Client 0: Local Initial ALA epochs: 4 Loss: 0.17714951595989986144\n",
      "Client0 Local Train => Local Epoch: 0 \tLoss: 0.1187466836 \tAcc: 0.9587053571 \tTPR:0.9756905040 \tFPR:0.1229733560 \tF1:0.9734984852 \t AUC:0.9263585740\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 1 \tLoss: 0.0774882012 \tAcc: 0.9709821429 \tTPR:0.9899036692 \tFPR:0.0976332200 \tF1:0.9813745803 \t AUC:0.9461352246\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 2 \tLoss: 0.0685730280 \tAcc: 0.9743303571 \tTPR:0.9863575115 \tFPR:0.0630836425 \tF1:0.9826213968 \t AUC:0.9616369345\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 3 \tLoss: 0.0619508509 \tAcc: 0.9720982143 \tTPR:0.9891235699 \tFPR:0.0893298060 \tF1:0.9821133037 \t AUC:0.9502741703\tTrain cost: 0:00:03\n",
      "Client0 Local Train => Local Epoch: 4 \tLoss: 0.0552371134 \tAcc: 0.9789259454 \tTPR:0.9926218967 \tFPR:0.0651515152 \tF1:0.9860663313 \t AUC:0.9637351908\tTrain cost: 0:00:03\n",
      "Client0 Test =>                 \tLoss: 0.2025586838 \tAcc: 0.9437500000 \tTPR:0.9733966101 \tFPR:0.0850024360 \tF1:0.9440222871 \tAUC:0.9441970870 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.050836807855570404 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06140627450337494270\n",
      "Client8 Local Train => Local Epoch: 0 \tLoss: 0.0678488340 \tAcc: 0.9764238166 \tTPR:0.9909943618 \tFPR:0.0735227022 \tF1:0.9844812920 \t AUC:0.9587224683\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 1 \tLoss: 0.0569060358 \tAcc: 0.9784578402 \tTPR:0.9916569902 \tFPR:0.0674479576 \tF1:0.9857643758 \t AUC:0.9620921380\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 2 \tLoss: 0.0514156304 \tAcc: 0.9813239645 \tTPR:0.9921953598 \tFPR:0.0560302945 \tF1:0.9876882753 \t AUC:0.9680825326\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 3 \tLoss: 0.0474627941 \tAcc: 0.9828032544 \tTPR:0.9927668406 \tFPR:0.0495275599 \tF1:0.9886579109 \t AUC:0.9716196404\tTrain cost: 0:00:34\n",
      "Client8 Local Train => Local Epoch: 4 \tLoss: 0.0423053402 \tAcc: 0.9845599112 \tTPR:0.9932051165 \tFPR:0.0465923460 \tF1:0.9898734005 \t AUC:0.9732963038\tTrain cost: 0:00:34\n",
      "Client8 Test =>                 \tLoss: 0.2275379565 \tAcc: 0.9383333333 \tTPR:0.9722783417 \tFPR:0.0944477126 \tF1:0.9371211536 \tAUC:0.9389153146 \tVal cost: 0:00:05\n",
      "Test =>                 \tLoss: 0.2383561240 \tAcc: 0.9414166667 \tTPR:0.9500161378 \tFPR:0.0665534951 \tF1:0.9397431952 \tAUC:0.9417313213\n",
      "-----------------------------------------------------------\n",
      "-------------- FedServer: Federation process  -------------\n",
      "-----------------------------------------------------------\n",
      "Training and Evaluation completed! total time cost: 8:51:37\n"
     ]
    }
   ],
   "source": [
    "print(\"Train and Test Begin!\")\n",
    "net_glob.train()\n",
    "w_net_glob = net_glob.state_dict()\n",
    "t0 = time.time()\n",
    "net_local = [copy.deepcopy(net_glob) for i in range(num_users)]\n",
    "\n",
    "lr = 2e-6\n",
    "\n",
    "local_test[\"loss\"] = []\n",
    "local_test[\"acc\"] = []\n",
    "local_test[\"tpr\"] = []\n",
    "local_test[\"fpr\"] = []\n",
    "local_test[\"f1\"] = []\n",
    "local_test[\"auc\"] = []\n",
    "\n",
    "local_testing[\"loss\"] = []\n",
    "local_testing[\"acc\"] = []\n",
    "local_testing[\"tpr\"] = []\n",
    "local_testing[\"fpr\"] = []\n",
    "local_testing[\"f1\"] = []\n",
    "local_testing[\"auc\"] = []\n",
    "\n",
    "for iter in range(epochs):\n",
    "    print(\"============== Round {}:  =============\".format(iter))\n",
    "    idx_collect = []\n",
    "    m = max(int(frac * num_users) ,1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace = False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    f1_list = []\n",
    "    auc_list = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "        local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "        w_client, client_loss, client_acc = local.train(net = copy.deepcopy(net_local[idx]).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "        loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_glob).to(device), ell=iter)\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        f1_list.append(f1)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    local_testing[\"loss\"].append(sum(loss_list)/len(loss_list))\n",
    "    local_testing[\"acc\"].append(sum(acc_list)/len(acc_list))\n",
    "    local_testing[\"tpr\"].append(sum(tpr_list)/len(tpr_list))\n",
    "    local_testing[\"fpr\"].append(sum(fpr_list)/len(fpr_list))\n",
    "    local_testing[\"f1\"].append(sum(f1_list)/len(f1_list))\n",
    "    local_testing[\"auc\"].append(sum(auc_list)/len(auc_list))\n",
    "    print(\"Test =>                 \\tLoss: {:.10f} \\tAcc: {:.10f} \\tTPR:{:.10f} \\tFPR:{:.10f} \\tF1:{:.10f} \\tAUC:{:.10f}\".format(sum(loss_list)/len(loss_list), sum(acc_list)/len(acc_list), sum(tpr_list)/len(tpr_list), sum(fpr_list)/len(fpr_list), sum(f1_list)/len(f1_list), sum(auc_list)/len(auc_list)  ))\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"-------------- FedServer: Federation process  -------------\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    w_net_glob = FedAvg(w_locals_client)\n",
    "    net_glob.load_state_dict(w_net_glob)\n",
    "elapsed = format_time(time.time()-t0)\n",
    "print(\"Training and Test completed! total time cost: {:}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Final Result =============\n",
      "local_initialization!\n",
      "Client: 0 \tStd: 0.026850251642570065 \tALA epochs: 1\n",
      "Client 0: Local Initial ALA epochs: 1 Loss: 0.02836157269775867532\n",
      "Client0 Test =>                 \tLoss: 0.1971009134 \tAcc: 0.9500000000 \tTPR:0.9522314099 \tFPR:0.0534716299 \tF1:0.9497142165 \tAUC:0.9493798900 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 1 \tStd: 0.0993864861328681 \tALA epochs: 6\n",
      "Client 1: Local Initial ALA epochs: 6 Loss: 0.18544188152736751363\n",
      "Client1 Test =>                 \tLoss: 0.2159872939 \tAcc: 0.9487500000 \tTPR:0.9461497630 \tFPR:0.0514951208 \tF1:0.9448570736 \tAUC:0.9473273211 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 2 \tStd: 0.03563470283891863 \tALA epochs: 1\n",
      "Client 2: Local Initial ALA epochs: 1 Loss: 0.05152883277994326633\n",
      "Client2 Test =>                 \tLoss: 0.2126936665 \tAcc: 0.9456250000 \tTPR:0.9546251588 \tFPR:0.0635646367 \tF1:0.9442100739 \tAUC:0.9455302610 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 3 \tStd: 0.056422502825538026 \tALA epochs: 1\n",
      "Client 3: Local Initial ALA epochs: 1 Loss: 0.08024817687692120671\n",
      "Client3 Test =>                 \tLoss: 0.2024397558 \tAcc: 0.9510416667 \tTPR:0.9535781493 \tFPR:0.0530361138 \tF1:0.9479279505 \tAUC:0.9502710178 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 4 \tStd: 0.04700505187416635 \tALA epochs: 1\n",
      "Client 4: Local Initial ALA epochs: 1 Loss: 0.04516713067271706239\n",
      "Client4 Test =>                 \tLoss: 0.2270658374 \tAcc: 0.9445833333 \tTPR:0.9492646478 \tFPR:0.0609196709 \tF1:0.9425186804 \tAUC:0.9441724885 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 5 \tStd: 0.08544888563860302 \tALA epochs: 1\n",
      "Client 5: Local Initial ALA epochs: 1 Loss: 0.15174595745879093656\n",
      "Client5 Test =>                 \tLoss: 0.2043542955 \tAcc: 0.9510416667 \tTPR:0.9553638566 \tFPR:0.0548848631 \tF1:0.9486258549 \tAUC:0.9502394967 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 6 \tStd: 0.05057129902338865 \tALA epochs: 1\n",
      "Client 6: Local Initial ALA epochs: 1 Loss: 0.08773531476882370783\n",
      "Client6 Test =>                 \tLoss: 0.2107179047 \tAcc: 0.9464583333 \tTPR:0.9466310668 \tFPR:0.0530611786 \tF1:0.9443050255 \tAUC:0.9467849441 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 7 \tStd: 0.0740882461530571 \tALA epochs: 1\n",
      "Client 7: Local Initial ALA epochs: 1 Loss: 0.03736827873217407614\n",
      "Client7 Test =>                 \tLoss: 0.2448137090 \tAcc: 0.9391666667 \tTPR:0.9478215508 \tFPR:0.0694896105 \tF1:0.9372682136 \tAUC:0.9391659702 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 8 \tStd: 0.07140973957431723 \tALA epochs: 1\n",
      "Client 8: Local Initial ALA epochs: 1 Loss: 0.06454628882860180550\n",
      "Client8 Test =>                 \tLoss: 0.2090685160 \tAcc: 0.9479166667 \tTPR:0.9571712412 \tFPR:0.0587741260 \tF1:0.9443318785 \tAUC:0.9491985576 \tVal cost: 0:00:05\n",
      "local_initialization!\n",
      "Client: 9 \tStd: 0.033443212428493255 \tALA epochs: 2\n",
      "Client 9: Local Initial ALA epochs: 2 Loss: 0.05937032838648354655\n",
      "Client9 Test =>                 \tLoss: 0.2002014183 \tAcc: 0.9493750000 \tTPR:0.9573942808 \tFPR:0.0598516946 \tF1:0.9499407276 \tAUC:0.9487712931 \tVal cost: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "idx_collect = [i for i in range(num_users)]\n",
    "print(\"============= Final Result =============\")\n",
    "for idx in idx_collect:\n",
    "    loss_test_collect[idx] = []\n",
    "    acc_test_collect[idx] = []\n",
    "    TPR_test_collect[idx] = []\n",
    "    FPR_test_collect[idx] = []\n",
    "    f1_test_collect[idx] = []\n",
    "    AUC_test_collect[idx] = []\n",
    "    local = Client(device, idx, lr, local_epochs, batch_size, train_dataset, test_dataset, dict_user_train[idx], dict_user_test[idx])\n",
    "    local.local_initialization(net = copy.deepcopy(net_glob).to(device))\n",
    "    loss, acc, tpr, fpr, f1, auc = local.evaluate(net = copy.deepcopy(net_local[idx]).to(device), ell=0)\n",
    "    loss_test_collect[idx].append(loss)\n",
    "    acc_test_collect[idx].append(acc)\n",
    "    TPR_test_collect[idx].append(tpr)\n",
    "    FPR_test_collect[idx].append(fpr)\n",
    "    f1_test_collect[idx].append(f1)\n",
    "    AUC_test_collect[idx].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(loss_collect)):\n",
    "    sheet1.write(i+1,0,loss_collect[i]) #写入数据参数对应 行, 列, 值\n",
    "for i in range(len(acc_collect)):\n",
    "    sheet1.write(i+1,1,acc_collect[i])\n",
    "for i in range(len(TPR_collect)):\n",
    "    sheet1.write(i+1,2,TPR_collect[i])\n",
    "for i in range(len(FPR_collect)):\n",
    "    sheet1.write(i+1,3,FPR_collect[i])\n",
    "for i in range(len(F1_collect)):\n",
    "    sheet1.write(i+1,4,F1_collect[i])\n",
    "for i in range(len(AUC_collect)):\n",
    "    sheet1.write(i+1,5,AUC_collect[i])\n",
    "\n",
    "f.save('result.xls')#保存.xls到当前工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_train_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_train_collect[i][j])\n",
    "    for j in range(len(acc_train_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_train_collect[i][j])\n",
    "    for j in range(len(TPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_train_collect[i][j])\n",
    "    for j in range(len(FPR_train_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_train_collect[i][j])\n",
    "    for j in range(len(f1_train_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_train_collect[i][j])\n",
    "    for j in range(len(AUC_train_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_train_collect[i][j])\n",
    "\n",
    "    f.save('result_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(num_users):\n",
    "    f = xlwt.Workbook('encoding = utf-8')\n",
    "    sheet1 = f.add_sheet('sheet1', cell_overwrite_ok=True)\n",
    "    for j in range(len(loss_test_collect[i])):\n",
    "        sheet1.write(j+1, 0, loss_test_collect[i][j])\n",
    "    for j in range(len(acc_test_collect[i])):\n",
    "        sheet1.write(j+1, 1, acc_test_collect[i][j])\n",
    "    for j in range(len(TPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 2, TPR_test_collect[i][j])\n",
    "    for j in range(len(FPR_test_collect[i])):\n",
    "        sheet1.write(j+1, 3, FPR_test_collect[i][j])\n",
    "    for j in range(len(f1_test_collect[i])):\n",
    "        sheet1.write(j+1, 4, f1_test_collect[i][j])\n",
    "    for j in range(len(AUC_test_collect[i])):\n",
    "        sheet1.write(j+1, 5, AUC_test_collect[i][j])\n",
    "\n",
    "    f.save('result_test_client{:}.xls'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_test[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_test[\"loss\"][i])\n",
    "for i in range(len(local_test[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_test[\"acc\"][i])\n",
    "for i in range(len(local_test[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_test[\"tpr\"][i])\n",
    "for i in range(len(local_test[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_test[\"fpr\"][i])\n",
    "for i in range(len(local_test[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_test[\"f1\"][i])\n",
    "for i in range(len(local_test[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_test[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Test.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import xlwt\n",
    "f = xlwt.Workbook('encoding = utf-8')\n",
    "sheet1 = f.add_sheet('sheet1',cell_overwrite_ok=True)\n",
    "for i in range(len(local_testing[\"loss\"])):\n",
    "    sheet1.write(i+1,0,local_testing[\"loss\"][i])\n",
    "for i in range(len(local_testing[\"acc\"])):\n",
    "    sheet1.write(i+1,1,local_testing[\"acc\"][i])\n",
    "for i in range(len(local_testing[\"tpr\"])):\n",
    "    sheet1.write(i+1,2,local_testing[\"tpr\"][i])\n",
    "for i in range(len(local_testing[\"fpr\"])):\n",
    "    sheet1.write(i+1,3,local_testing[\"fpr\"][i])\n",
    "for i in range(len(local_testing[\"f1\"])):\n",
    "    sheet1.write(i+1,4,local_testing[\"f1\"][i])\n",
    "for i in range(len(local_testing[\"auc\"])):\n",
    "    sheet1.write(i+1,5,local_testing[\"auc\"][i])\n",
    "\n",
    "f.save('Local_Testing.xls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
